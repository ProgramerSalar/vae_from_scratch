2025-11-14 08:12:50,231 [INFO] Starting new training run...
2025-11-14 08:12:57,637 [INFO] ------------------------------------------- Epoch: [0]
2025-11-14 08:13:01,521 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:13:01,558 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:13:04,605 [INFO] rec_loss: 5.921844005584717, rec_log: {'train/total_loss': tensor(5.9218, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(47.8281, device='cuda:0'), 'train/nll_loss': tensor(5.8554, device='cuda:0'), 'train/rec_loss': tensor(0.5046, device='cuda:0'), 'train/perception_loss': tensor(0.8091, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.1857, device='cuda:0')}
2025-11-14 08:13:13,782 [INFO] gan_loss : 1.430620551109314,  gan_log: {'train/disc_loss': tensor(1.4306, device='cuda:0'), 'train/logits_real': tensor(-0.3275, device='cuda:0'), 'train/logits_fake': tensor(-0.1857, device='cuda:0')}
2025-11-14 08:13:17,602 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:13:17,630 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:13:20,197 [INFO] rec_loss: 9.71354866027832, rec_log: {'train/total_loss': tensor(9.7135, device='cuda:0'), 'train/logvar': tensor(1.0000e-04, device='cuda:0'), 'train/kl_loss': tensor(1522.8940, device='cuda:0'), 'train/nll_loss': tensor(9.2030, device='cuda:0'), 'train/rec_loss': tensor(0.8409, device='cuda:0'), 'train/perception_loss': tensor(0.7952, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-10.1231, device='cuda:0')}
2025-11-14 08:13:31,511 [INFO] gan_loss : 6.583719253540039,  gan_log: {'train/disc_loss': tensor(6.5837, device='cuda:0'), 'train/logits_real': tensor(14.7463, device='cuda:0'), 'train/logits_fake': tensor(10.1231, device='cuda:0')}
2025-11-14 08:13:35,245 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:13:35,268 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:13:37,887 [INFO] rec_loss: 5.791781902313232, rec_log: {'train/total_loss': tensor(5.7918, device='cuda:0'), 'train/logvar': tensor(0.0002, device='cuda:0'), 'train/kl_loss': tensor(409.2958, device='cuda:0'), 'train/nll_loss': tensor(5.2966, device='cuda:0'), 'train/rec_loss': tensor(0.4450, device='cuda:0'), 'train/perception_loss': tensor(0.8474, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8588, device='cuda:0')}
2025-11-14 08:13:51,065 [INFO] gan_loss : 3.070676803588867,  gan_log: {'train/disc_loss': tensor(3.0707, device='cuda:0'), 'train/logits_real': tensor(5.0362, device='cuda:0'), 'train/logits_fake': tensor(-0.8588, device='cuda:0')}
2025-11-14 08:13:54,665 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:13:54,688 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:13:57,264 [INFO] rec_loss: 3.6426186561584473, rec_log: {'train/total_loss': tensor(3.6426, device='cuda:0'), 'train/logvar': tensor(0.0003, device='cuda:0'), 'train/kl_loss': tensor(69.5943, device='cuda:0'), 'train/nll_loss': tensor(5.5420, device='cuda:0'), 'train/rec_loss': tensor(0.4705, device='cuda:0'), 'train/perception_loss': tensor(0.8379, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-19.6895, device='cuda:0')}
2025-11-14 08:14:10,431 [INFO] gan_loss : 11.624055862426758,  gan_log: {'train/disc_loss': tensor(11.6241, device='cuda:0'), 'train/logits_real': tensor(6.4853, device='cuda:0'), 'train/logits_fake': tensor(19.6895, device='cuda:0')}
2025-11-14 08:14:13,811 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:14:13,840 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:14:16,448 [INFO] rec_loss: 3.9967756271362305, rec_log: {'train/total_loss': tensor(3.9968, device='cuda:0'), 'train/logvar': tensor(0.0004, device='cuda:0'), 'train/kl_loss': tensor(51.3412, device='cuda:0'), 'train/nll_loss': tensor(5.1045, device='cuda:0'), 'train/rec_loss': tensor(0.4279, device='cuda:0'), 'train/perception_loss': tensor(0.8271, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-11.5906, device='cuda:0')}
2025-11-14 08:14:29,632 [INFO] gan_loss : 8.860015869140625,  gan_log: {'train/disc_loss': tensor(8.8600, device='cuda:0'), 'train/logits_real': tensor(5.4992, device='cuda:0'), 'train/logits_fake': tensor(11.5906, device='cuda:0')}
2025-11-14 08:14:33,034 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:14:33,057 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:14:35,638 [INFO] rec_loss: 3.925839424133301, rec_log: {'train/total_loss': tensor(3.9258, device='cuda:0'), 'train/logvar': tensor(0.0005, device='cuda:0'), 'train/kl_loss': tensor(53.4704, device='cuda:0'), 'train/nll_loss': tensor(4.6556, device='cuda:0'), 'train/rec_loss': tensor(0.3837, device='cuda:0'), 'train/perception_loss': tensor(0.8203, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-7.8327, device='cuda:0')}
2025-11-14 08:14:48,820 [INFO] gan_loss : 5.971113204956055,  gan_log: {'train/disc_loss': tensor(5.9711, device='cuda:0'), 'train/logits_real': tensor(1.8481, device='cuda:0'), 'train/logits_fake': tensor(7.8327, device='cuda:0')}
2025-11-14 08:14:52,688 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:14:52,717 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:14:55,312 [INFO] rec_loss: 4.894693374633789, rec_log: {'train/total_loss': tensor(4.8947, device='cuda:0'), 'train/logvar': tensor(0.0006, device='cuda:0'), 'train/kl_loss': tensor(33.8368, device='cuda:0'), 'train/nll_loss': tensor(4.6080, device='cuda:0'), 'train/rec_loss': tensor(0.3775, device='cuda:0'), 'train/perception_loss': tensor(0.8353, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.5286, device='cuda:0')}
2025-11-14 08:15:08,480 [INFO] gan_loss : 1.552333116531372,  gan_log: {'train/disc_loss': tensor(1.5523, device='cuda:0'), 'train/logits_real': tensor(-0.1591, device='cuda:0'), 'train/logits_fake': tensor(-2.5286, device='cuda:0')}
2025-11-14 08:15:12,166 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:15:12,190 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:15:14,795 [INFO] rec_loss: 5.045888900756836, rec_log: {'train/total_loss': tensor(5.0459, device='cuda:0'), 'train/logvar': tensor(0.0007, device='cuda:0'), 'train/kl_loss': tensor(12.1913, device='cuda:0'), 'train/nll_loss': tensor(4.1405, device='cuda:0'), 'train/rec_loss': tensor(0.3331, device='cuda:0'), 'train/perception_loss': tensor(0.8120, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(8.9320, device='cuda:0')}
2025-11-14 08:15:27,945 [INFO] gan_loss : 1.9583139419555664,  gan_log: {'train/disc_loss': tensor(1.9583, device='cuda:0'), 'train/logits_real': tensor(-1.5261, device='cuda:0'), 'train/logits_fake': tensor(-8.9320, device='cuda:0')}
2025-11-14 08:15:31,458 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:15:31,486 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:15:34,051 [INFO] rec_loss: 5.561327934265137, rec_log: {'train/total_loss': tensor(5.5613, device='cuda:0'), 'train/logvar': tensor(0.0008, device='cuda:0'), 'train/kl_loss': tensor(8.1998, device='cuda:0'), 'train/nll_loss': tensor(4.5734, device='cuda:0'), 'train/rec_loss': tensor(0.3765, device='cuda:0'), 'train/perception_loss': tensor(0.8115, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(9.7973, device='cuda:0')}
2025-11-14 08:15:47,226 [INFO] gan_loss : 1.9797375202178955,  gan_log: {'train/disc_loss': tensor(1.9797, device='cuda:0'), 'train/logits_real': tensor(-0.8763, device='cuda:0'), 'train/logits_fake': tensor(-9.7973, device='cuda:0')}
2025-11-14 08:15:50,899 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:15:50,927 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:15:53,555 [INFO] rec_loss: 5.246650695800781, rec_log: {'train/total_loss': tensor(5.2467, device='cuda:0'), 'train/logvar': tensor(0.0008, device='cuda:0'), 'train/kl_loss': tensor(8.6240, device='cuda:0'), 'train/nll_loss': tensor(4.1483, device='cuda:0'), 'train/rec_loss': tensor(0.3332, device='cuda:0'), 'train/perception_loss': tensor(0.8188, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(10.8973, device='cuda:0')}
2025-11-14 08:16:06,716 [INFO] gan_loss : 0.8275859951972961,  gan_log: {'train/disc_loss': tensor(0.8276, device='cuda:0'), 'train/logits_real': tensor(0.6795, device='cuda:0'), 'train/logits_fake': tensor(-10.8973, device='cuda:0')}
2025-11-14 08:16:10,273 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:16:10,296 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:16:12,906 [INFO] rec_loss: 4.6768693923950195, rec_log: {'train/total_loss': tensor(4.6769, device='cuda:0'), 'train/logvar': tensor(0.0009, device='cuda:0'), 'train/kl_loss': tensor(7.2537, device='cuda:0'), 'train/nll_loss': tensor(3.9911, device='cuda:0'), 'train/rec_loss': tensor(0.3192, device='cuda:0'), 'train/perception_loss': tensor(0.8022, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(6.7848, device='cuda:0')}
2025-11-14 08:16:26,067 [INFO] gan_loss : 0.406271755695343,  gan_log: {'train/disc_loss': tensor(0.4063, device='cuda:0'), 'train/logits_real': tensor(2.9117, device='cuda:0'), 'train/logits_fake': tensor(-6.7848, device='cuda:0')}
2025-11-14 08:16:29,546 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:16:29,575 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:16:32,184 [INFO] rec_loss: 3.1846001148223877, rec_log: {'train/total_loss': tensor(3.1846, device='cuda:0'), 'train/logvar': tensor(0.0010, device='cuda:0'), 'train/kl_loss': tensor(6.1479, device='cuda:0'), 'train/nll_loss': tensor(3.9489, device='cuda:0'), 'train/rec_loss': tensor(0.3162, device='cuda:0'), 'train/perception_loss': tensor(0.7903, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-7.7042, device='cuda:0')}
2025-11-14 08:16:45,370 [INFO] gan_loss : 4.367602348327637,  gan_log: {'train/disc_loss': tensor(4.3676, device='cuda:0'), 'train/logits_real': tensor(7.2297, device='cuda:0'), 'train/logits_fake': tensor(7.7042, device='cuda:0')}
2025-11-14 08:16:48,817 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:16:48,846 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:16:51,438 [INFO] rec_loss: 4.392453193664551, rec_log: {'train/total_loss': tensor(4.3925, device='cuda:0'), 'train/logvar': tensor(0.0011, device='cuda:0'), 'train/kl_loss': tensor(6.0569, device='cuda:0'), 'train/nll_loss': tensor(5.4392, device='cuda:0'), 'train/rec_loss': tensor(0.4620, device='cuda:0'), 'train/perception_loss': tensor(0.8240, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-10.5278, device='cuda:0')}
2025-11-14 08:23:49,635 [INFO] gan_loss : 1.9139432907104492,  gan_log: {'train/disc_loss': tensor(1.9139, device='cuda:0'), 'train/logits_real': tensor(-2.0486, device='cuda:0'), 'train/logits_fake': tensor(-2.4798, device='cuda:0')}
2025-11-14 08:23:52,984 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:23:53,013 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:23:55,596 [INFO] rec_loss: 4.0265960693359375, rec_log: {'train/total_loss': tensor(4.0266, device='cuda:0'), 'train/logvar': tensor(0.0031, device='cuda:0'), 'train/kl_loss': tensor(6.6262, device='cuda:0'), 'train/nll_loss': tensor(3.7485, device='cuda:0'), 'train/rec_loss': tensor(0.2918, device='cuda:0'), 'train/perception_loss': tensor(0.8389, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.7143, device='cuda:0')}
2025-11-14 08:24:08,782 [INFO] gan_loss : 2.1070635318756104,  gan_log: {'train/disc_loss': tensor(2.1071, device='cuda:0'), 'train/logits_real': tensor(-2.3977, device='cuda:0'), 'train/logits_fake': tensor(-2.7143, device='cuda:0')}
2025-11-14 08:24:12,353 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:24:12,382 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:24:14,962 [INFO] rec_loss: 4.4636993408203125, rec_log: {'train/total_loss': tensor(4.4637, device='cuda:0'), 'train/logvar': tensor(0.0032, device='cuda:0'), 'train/kl_loss': tensor(6.7193, device='cuda:0'), 'train/nll_loss': tensor(4.2646, device='cuda:0'), 'train/rec_loss': tensor(0.3420, device='cuda:0'), 'train/perception_loss': tensor(0.8551, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.9238, device='cuda:0')}
2025-11-14 08:24:28,146 [INFO] gan_loss : 1.879363775253296,  gan_log: {'train/disc_loss': tensor(1.8794, device='cuda:0'), 'train/logits_real': tensor(-1.4869, device='cuda:0'), 'train/logits_fake': tensor(-1.9238, device='cuda:0')}
2025-11-14 08:24:31,192 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:24:31,221 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:24:33,793 [INFO] rec_loss: 4.072897434234619, rec_log: {'train/total_loss': tensor(4.0729, device='cuda:0'), 'train/logvar': tensor(0.0033, device='cuda:0'), 'train/kl_loss': tensor(8.1328, device='cuda:0'), 'train/nll_loss': tensor(4.0687, device='cuda:0'), 'train/rec_loss': tensor(0.3205, device='cuda:0'), 'train/perception_loss': tensor(0.8741, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.0398, device='cuda:0')}
2025-11-14 08:24:46,958 [INFO] gan_loss : 1.7178833484649658,  gan_log: {'train/disc_loss': tensor(1.7179, device='cuda:0'), 'train/logits_real': tensor(0.2241, device='cuda:0'), 'train/logits_fake': tensor(0.0398, device='cuda:0')}
2025-11-14 08:24:50,311 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:24:50,340 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:24:52,920 [INFO] rec_loss: 4.983097076416016, rec_log: {'train/total_loss': tensor(4.9831, device='cuda:0'), 'train/logvar': tensor(0.0033, device='cuda:0'), 'train/kl_loss': tensor(8.0420, device='cuda:0'), 'train/nll_loss': tensor(5.1055, device='cuda:0'), 'train/rec_loss': tensor(0.4266, device='cuda:0'), 'train/perception_loss': tensor(0.8535, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-1.3042, device='cuda:0')}
2025-11-14 08:25:06,103 [INFO] gan_loss : 1.54728102684021,  gan_log: {'train/disc_loss': tensor(1.5473, device='cuda:0'), 'train/logits_real': tensor(1.8045, device='cuda:0'), 'train/logits_fake': tensor(1.3042, device='cuda:0')}
2025-11-14 08:25:10,243 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:25:10,271 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:25:12,876 [INFO] rec_loss: 4.226520538330078, rec_log: {'train/total_loss': tensor(4.2265, device='cuda:0'), 'train/logvar': tensor(0.0034, device='cuda:0'), 'train/kl_loss': tensor(10.4807, device='cuda:0'), 'train/nll_loss': tensor(4.3472, device='cuda:0'), 'train/rec_loss': tensor(0.3492, device='cuda:0'), 'train/perception_loss': tensor(0.8668, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-1.3112, device='cuda:0')}
2025-11-14 08:25:26,052 [INFO] gan_loss : 1.450915813446045,  gan_log: {'train/disc_loss': tensor(1.4509, device='cuda:0'), 'train/logits_real': tensor(2.3648, device='cuda:0'), 'train/logits_fake': tensor(1.3112, device='cuda:0')}
2025-11-14 08:25:30,088 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:25:30,117 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:25:32,697 [INFO] rec_loss: 5.94898796081543, rec_log: {'train/total_loss': tensor(5.9490, device='cuda:0'), 'train/logvar': tensor(0.0035, device='cuda:0'), 'train/kl_loss': tensor(21.3349, device='cuda:0'), 'train/nll_loss': tensor(5.9727, device='cuda:0'), 'train/rec_loss': tensor(0.5140, device='cuda:0'), 'train/perception_loss': tensor(0.8505, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.4500, device='cuda:0')}
2025-11-14 08:25:45,842 [INFO] gan_loss : 1.477813720703125,  gan_log: {'train/disc_loss': tensor(1.4778, device='cuda:0'), 'train/logits_real': tensor(2.1718, device='cuda:0'), 'train/logits_fake': tensor(0.4500, device='cuda:0')}
2025-11-14 08:25:49,185 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:25:49,215 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:25:51,780 [INFO] rec_loss: 3.835635185241699, rec_log: {'train/total_loss': tensor(3.8356, device='cuda:0'), 'train/logvar': tensor(0.0036, device='cuda:0'), 'train/kl_loss': tensor(18.6227, device='cuda:0'), 'train/nll_loss': tensor(3.7740, device='cuda:0'), 'train/rec_loss': tensor(0.2973, device='cuda:0'), 'train/perception_loss': tensor(0.8107, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.4299, device='cuda:0')}
2025-11-14 08:26:04,950 [INFO] gan_loss : 1.8044934272766113,  gan_log: {'train/disc_loss': tensor(1.8045, device='cuda:0'), 'train/logits_real': tensor(0.6708, device='cuda:0'), 'train/logits_fake': tensor(-0.4299, device='cuda:0')}
2025-11-14 08:26:07,618 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:26:07,646 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:26:10,228 [INFO] rec_loss: 4.3394775390625, rec_log: {'train/total_loss': tensor(4.3395, device='cuda:0'), 'train/logvar': tensor(0.0037, device='cuda:0'), 'train/kl_loss': tensor(25.3446, device='cuda:0'), 'train/nll_loss': tensor(4.2703, device='cuda:0'), 'train/rec_loss': tensor(0.3425, device='cuda:0'), 'train/perception_loss': tensor(0.8570, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.4387, device='cuda:0')}
2025-11-14 08:26:23,384 [INFO] gan_loss : 1.7465468645095825,  gan_log: {'train/disc_loss': tensor(1.7465, device='cuda:0'), 'train/logits_real': tensor(0.2753, device='cuda:0'), 'train/logits_fake': tensor(-0.4387, device='cuda:0')}
2025-11-14 08:26:26,229 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:26:26,257 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:26:28,883 [INFO] rec_loss: 4.941470623016357, rec_log: {'train/total_loss': tensor(4.9415, device='cuda:0'), 'train/logvar': tensor(0.0038, device='cuda:0'), 'train/kl_loss': tensor(34.1417, device='cuda:0'), 'train/nll_loss': tensor(4.9806, device='cuda:0'), 'train/rec_loss': tensor(0.4186, device='cuda:0'), 'train/perception_loss': tensor(0.8096, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.7328, device='cuda:0')}
2025-11-14 08:26:42,053 [INFO] gan_loss : 2.309196949005127,  gan_log: {'train/disc_loss': tensor(2.3092, device='cuda:0'), 'train/logits_real': tensor(-0.6164, device='cuda:0'), 'train/logits_fake': tensor(0.7328, device='cuda:0')}
2025-11-14 08:26:46,086 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:26:46,115 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:26:48,713 [INFO] rec_loss: 4.060269355773926, rec_log: {'train/total_loss': tensor(4.0603, device='cuda:0'), 'train/logvar': tensor(0.0039, device='cuda:0'), 'train/kl_loss': tensor(35.6139, device='cuda:0'), 'train/nll_loss': tensor(4.0090, device='cuda:0'), 'train/rec_loss': tensor(0.3146, device='cuda:0'), 'train/perception_loss': tensor(0.8742, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.1570, device='cuda:0')}
2025-11-14 08:27:01,904 [INFO] gan_loss : 2.1967544555664062,  gan_log: {'train/disc_loss': tensor(2.1968, device='cuda:0'), 'train/logits_real': tensor(-0.9714, device='cuda:0'), 'train/logits_fake': tensor(-0.1570, device='cuda:0')}
2025-11-14 08:27:05,151 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:27:05,180 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:27:07,809 [INFO] rec_loss: 4.150231838226318, rec_log: {'train/total_loss': tensor(4.1502, device='cuda:0'), 'train/logvar': tensor(0.0040, device='cuda:0'), 'train/kl_loss': tensor(52.7011, device='cuda:0'), 'train/nll_loss': tensor(4.0537, device='cuda:0'), 'train/rec_loss': tensor(0.3225, device='cuda:0'), 'train/perception_loss': tensor(0.8406, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.4379, device='cuda:0')}
2025-11-14 08:27:20,996 [INFO] gan_loss : 2.2405200004577637,  gan_log: {'train/disc_loss': tensor(2.2405, device='cuda:0'), 'train/logits_real': tensor(-1.8041, device='cuda:0'), 'train/logits_fake': tensor(-0.4379, device='cuda:0')}
2025-11-14 08:27:24,606 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:27:24,634 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:27:27,251 [INFO] rec_loss: 4.671759128570557, rec_log: {'train/total_loss': tensor(4.6718, device='cuda:0'), 'train/logvar': tensor(0.0041, device='cuda:0'), 'train/kl_loss': tensor(45.1333, device='cuda:0'), 'train/nll_loss': tensor(4.5862, device='cuda:0'), 'train/rec_loss': tensor(0.3767, device='cuda:0'), 'train/perception_loss': tensor(0.8342, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.4044, device='cuda:0')}
2025-11-14 08:27:40,425 [INFO] gan_loss : 1.7073700428009033,  gan_log: {'train/disc_loss': tensor(1.7074, device='cuda:0'), 'train/logits_real': tensor(-1.2187, device='cuda:0'), 'train/logits_fake': tensor(-0.4044, device='cuda:0')}
2025-11-14 08:27:43,979 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:27:44,002 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:27:46,618 [INFO] rec_loss: 4.368124485015869, rec_log: {'train/total_loss': tensor(4.3681, device='cuda:0'), 'train/logvar': tensor(0.0042, device='cuda:0'), 'train/kl_loss': tensor(37.4745, device='cuda:0'), 'train/nll_loss': tensor(4.3276, device='cuda:0'), 'train/rec_loss': tensor(0.3469, device='cuda:0'), 'train/perception_loss': tensor(0.8721, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0304, device='cuda:0')}
2025-11-14 08:27:59,787 [INFO] gan_loss : 1.6256182193756104,  gan_log: {'train/disc_loss': tensor(1.6256, device='cuda:0'), 'train/logits_real': tensor(-0.3299, device='cuda:0'), 'train/logits_fake': tensor(-0.0304, device='cuda:0')}
2025-11-14 08:28:02,795 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:28:02,818 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:28:05,450 [INFO] rec_loss: 3.814260244369507, rec_log: {'train/total_loss': tensor(3.8143, device='cuda:0'), 'train/logvar': tensor(0.0043, device='cuda:0'), 'train/kl_loss': tensor(33.0805, device='cuda:0'), 'train/nll_loss': tensor(3.8132, device='cuda:0'), 'train/rec_loss': tensor(0.3021, device='cuda:0'), 'train/perception_loss': tensor(0.8045, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.3204, device='cuda:0')}
2025-11-14 08:28:18,638 [INFO] gan_loss : 1.8375422954559326,  gan_log: {'train/disc_loss': tensor(1.8375, device='cuda:0'), 'train/logits_real': tensor(0.2320, device='cuda:0'), 'train/logits_fake': tensor(0.3204, device='cuda:0')}
2025-11-14 08:28:22,472 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:28:22,500 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:28:25,083 [INFO] rec_loss: 4.236705780029297, rec_log: {'train/total_loss': tensor(4.2367, device='cuda:0'), 'train/logvar': tensor(0.0043, device='cuda:0'), 'train/kl_loss': tensor(23.3694, device='cuda:0'), 'train/nll_loss': tensor(4.2658, device='cuda:0'), 'train/rec_loss': tensor(0.3452, device='cuda:0'), 'train/perception_loss': tensor(0.8277, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.5242, device='cuda:0')}
2025-11-14 08:28:38,272 [INFO] gan_loss : 1.6253457069396973,  gan_log: {'train/disc_loss': tensor(1.6253, device='cuda:0'), 'train/logits_real': tensor(0.7632, device='cuda:0'), 'train/logits_fake': tensor(0.5242, device='cuda:0')}
2025-11-14 08:28:41,418 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:28:41,446 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:28:44,053 [INFO] rec_loss: 3.7086405754089355, rec_log: {'train/total_loss': tensor(3.7086, device='cuda:0'), 'train/logvar': tensor(0.0044, device='cuda:0'), 'train/kl_loss': tensor(16.6370, device='cuda:0'), 'train/nll_loss': tensor(3.7244, device='cuda:0'), 'train/rec_loss': tensor(0.2940, device='cuda:0'), 'train/perception_loss': tensor(0.7968, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.3238, device='cuda:0')}
2025-11-14 08:28:57,233 [INFO] gan_loss : 1.3396254777908325,  gan_log: {'train/disc_loss': tensor(1.3396, device='cuda:0'), 'train/logits_real': tensor(0.5316, device='cuda:0'), 'train/logits_fake': tensor(0.3238, device='cuda:0')}
2025-11-14 08:29:00,426 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:29:00,449 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:29:03,027 [INFO] rec_loss: 3.9040684700012207, rec_log: {'train/total_loss': tensor(3.9041, device='cuda:0'), 'train/logvar': tensor(0.0045, device='cuda:0'), 'train/kl_loss': tensor(24.6095, device='cuda:0'), 'train/nll_loss': tensor(3.8777, device='cuda:0'), 'train/rec_loss': tensor(0.3062, device='cuda:0'), 'train/perception_loss': tensor(0.8287, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0179, device='cuda:0')}
2025-11-14 08:29:16,203 [INFO] gan_loss : 1.3087866306304932,  gan_log: {'train/disc_loss': tensor(1.3088, device='cuda:0'), 'train/logits_real': tensor(0.3701, device='cuda:0'), 'train/logits_fake': tensor(-0.0179, device='cuda:0')}
2025-11-14 08:29:19,119 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:29:19,148 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:29:21,757 [INFO] rec_loss: 4.997228145599365, rec_log: {'train/total_loss': tensor(4.9972, device='cuda:0'), 'train/logvar': tensor(0.0046, device='cuda:0'), 'train/kl_loss': tensor(28.2281, device='cuda:0'), 'train/nll_loss': tensor(4.9564, device='cuda:0'), 'train/rec_loss': tensor(0.4128, device='cuda:0'), 'train/perception_loss': tensor(0.8466, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.1258, device='cuda:0')}
2025-11-14 08:29:34,945 [INFO] gan_loss : 1.2936880588531494,  gan_log: {'train/disc_loss': tensor(1.2937, device='cuda:0'), 'train/logits_real': tensor(0.1691, device='cuda:0'), 'train/logits_fake': tensor(-0.1258, device='cuda:0')}
2025-11-14 08:29:38,761 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:29:38,784 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:29:41,392 [INFO] rec_loss: 4.073262691497803, rec_log: {'train/total_loss': tensor(4.0733, device='cuda:0'), 'train/logvar': tensor(0.0047, device='cuda:0'), 'train/kl_loss': tensor(39.7410, device='cuda:0'), 'train/nll_loss': tensor(4.0323, device='cuda:0'), 'train/rec_loss': tensor(0.3217, device='cuda:0'), 'train/perception_loss': tensor(0.8296, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0121, device='cuda:0')}
2025-11-14 08:29:54,585 [INFO] gan_loss : 0.952747642993927,  gan_log: {'train/disc_loss': tensor(0.9527, device='cuda:0'), 'train/logits_real': tensor(0.4612, device='cuda:0'), 'train/logits_fake': tensor(-0.0121, device='cuda:0')}
2025-11-14 08:29:58,008 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:29:58,035 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:30:00,653 [INFO] rec_loss: 4.209234714508057, rec_log: {'train/total_loss': tensor(4.2092, device='cuda:0'), 'train/logvar': tensor(0.0048, device='cuda:0'), 'train/kl_loss': tensor(71.5146, device='cuda:0'), 'train/nll_loss': tensor(4.0951, device='cuda:0'), 'train/rec_loss': tensor(0.3315, device='cuda:0'), 'train/perception_loss': tensor(0.7949, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.4262, device='cuda:0')}
2025-11-14 08:30:13,845 [INFO] gan_loss : 1.4136505126953125,  gan_log: {'train/disc_loss': tensor(1.4137, device='cuda:0'), 'train/logits_real': tensor(0.1606, device='cuda:0'), 'train/logits_fake': tensor(-0.4262, device='cuda:0')}
2025-11-14 08:30:17,468 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:30:17,496 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:30:20,101 [INFO] rec_loss: 3.617286205291748, rec_log: {'train/total_loss': tensor(3.6173, device='cuda:0'), 'train/logvar': tensor(0.0049, device='cuda:0'), 'train/kl_loss': tensor(96.4919, device='cuda:0'), 'train/nll_loss': tensor(3.4373, device='cuda:0'), 'train/rec_loss': tensor(0.2613, device='cuda:0'), 'train/perception_loss': tensor(0.8362, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8347, device='cuda:0')}
2025-11-14 08:30:33,250 [INFO] gan_loss : 1.6778249740600586,  gan_log: {'train/disc_loss': tensor(1.6778, device='cuda:0'), 'train/logits_real': tensor(-0.2440, device='cuda:0'), 'train/logits_fake': tensor(-0.8347, device='cuda:0')}
2025-11-14 08:30:36,803 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:30:36,831 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:30:39,438 [INFO] rec_loss: 3.4138565063476562, rec_log: {'train/total_loss': tensor(3.4139, device='cuda:0'), 'train/logvar': tensor(0.0050, device='cuda:0'), 'train/kl_loss': tensor(95.9448, device='cuda:0'), 'train/nll_loss': tensor(3.1853, device='cuda:0'), 'train/rec_loss': tensor(0.2410, device='cuda:0'), 'train/perception_loss': tensor(0.7860, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3266, device='cuda:0')}
2025-11-14 08:30:52,626 [INFO] gan_loss : 1.6342835426330566,  gan_log: {'train/disc_loss': tensor(1.6343, device='cuda:0'), 'train/logits_real': tensor(-1.1772, device='cuda:0'), 'train/logits_fake': tensor(-1.3266, device='cuda:0')}
2025-11-14 08:30:56,184 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:30:56,213 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:30:58,818 [INFO] rec_loss: 3.2590866088867188, rec_log: {'train/total_loss': tensor(3.2591, device='cuda:0'), 'train/logvar': tensor(0.0051, device='cuda:0'), 'train/kl_loss': tensor(67.8574, device='cuda:0'), 'train/nll_loss': tensor(3.0608, device='cuda:0'), 'train/rec_loss': tensor(0.2279, device='cuda:0'), 'train/perception_loss': tensor(0.7922, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3041, device='cuda:0')}
2025-11-14 08:31:12,017 [INFO] gan_loss : 1.304202914237976,  gan_log: {'train/disc_loss': tensor(1.3042, device='cuda:0'), 'train/logits_real': tensor(-0.9580, device='cuda:0'), 'train/logits_fake': tensor(-1.3041, device='cuda:0')}
2025-11-14 08:31:15,692 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:31:15,720 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:31:18,330 [INFO] rec_loss: 3.588481903076172, rec_log: {'train/total_loss': tensor(3.5885, device='cuda:0'), 'train/logvar': tensor(0.0051, device='cuda:0'), 'train/kl_loss': tensor(41.0542, device='cuda:0'), 'train/nll_loss': tensor(3.4746, device='cuda:0'), 'train/rec_loss': tensor(0.2684, device='cuda:0'), 'train/perception_loss': tensor(0.8031, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7278, device='cuda:0')}
2025-11-14 08:31:31,514 [INFO] gan_loss : 1.3839572668075562,  gan_log: {'train/disc_loss': tensor(1.3840, device='cuda:0'), 'train/logits_real': tensor(-0.4145, device='cuda:0'), 'train/logits_fake': tensor(-0.7278, device='cuda:0')}
2025-11-14 08:31:34,980 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:31:35,008 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:31:37,637 [INFO] rec_loss: 3.0352203845977783, rec_log: {'train/total_loss': tensor(3.0352, device='cuda:0'), 'train/logvar': tensor(0.0052, device='cuda:0'), 'train/kl_loss': tensor(35.1573, device='cuda:0'), 'train/nll_loss': tensor(3.0533, device='cuda:0'), 'train/rec_loss': tensor(0.2298, device='cuda:0'), 'train/perception_loss': tensor(0.7656, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.5321, device='cuda:0')}
2025-11-14 08:31:50,827 [INFO] gan_loss : 1.4183087348937988,  gan_log: {'train/disc_loss': tensor(1.4183, device='cuda:0'), 'train/logits_real': tensor(0.6520, device='cuda:0'), 'train/logits_fake': tensor(0.5321, device='cuda:0')}
2025-11-14 08:31:54,929 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:31:54,957 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:31:57,572 [INFO] rec_loss: 3.4725747108459473, rec_log: {'train/total_loss': tensor(3.4726, device='cuda:0'), 'train/logvar': tensor(0.0053, device='cuda:0'), 'train/kl_loss': tensor(66.0600, device='cuda:0'), 'train/nll_loss': tensor(3.4912, device='cuda:0'), 'train/rec_loss': tensor(0.2728, device='cuda:0'), 'train/perception_loss': tensor(0.7766, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.8470, device='cuda:0')}
2025-11-14 08:32:10,759 [INFO] gan_loss : 1.371082067489624,  gan_log: {'train/disc_loss': tensor(1.3711, device='cuda:0'), 'train/logits_real': tensor(0.4688, device='cuda:0'), 'train/logits_fake': tensor(0.8470, device='cuda:0')}
2025-11-14 08:32:14,547 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:32:14,575 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:32:17,180 [INFO] rec_loss: 4.646524429321289, rec_log: {'train/total_loss': tensor(4.6465, device='cuda:0'), 'train/logvar': tensor(0.0054, device='cuda:0'), 'train/kl_loss': tensor(33.5092, device='cuda:0'), 'train/nll_loss': tensor(4.6282, device='cuda:0'), 'train/rec_loss': tensor(0.3875, device='cuda:0'), 'train/perception_loss': tensor(0.7731, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.1516, device='cuda:0')}
2025-11-14 08:32:30,376 [INFO] gan_loss : 1.2031017541885376,  gan_log: {'train/disc_loss': tensor(1.2031, device='cuda:0'), 'train/logits_real': tensor(1.1633, device='cuda:0'), 'train/logits_fake': tensor(0.1516, device='cuda:0')}
2025-11-14 08:32:33,574 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:32:33,603 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:32:36,229 [INFO] rec_loss: 3.1773650646209717, rec_log: {'train/total_loss': tensor(3.1774, device='cuda:0'), 'train/logvar': tensor(0.0055, device='cuda:0'), 'train/kl_loss': tensor(54.6907, device='cuda:0'), 'train/nll_loss': tensor(3.0660, device='cuda:0'), 'train/rec_loss': tensor(0.2311, device='cuda:0'), 'train/perception_loss': tensor(0.7662, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5668, device='cuda:0')}
2025-11-14 08:32:49,413 [INFO] gan_loss : 1.3334870338439941,  gan_log: {'train/disc_loss': tensor(1.3335, device='cuda:0'), 'train/logits_real': tensor(-0.2366, device='cuda:0'), 'train/logits_fake': tensor(-0.5668, device='cuda:0')}
2025-11-14 08:32:52,361 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:32:52,390 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:32:55,012 [INFO] rec_loss: 3.601271152496338, rec_log: {'train/total_loss': tensor(3.6013, device='cuda:0'), 'train/logvar': tensor(0.0055, device='cuda:0'), 'train/kl_loss': tensor(61.4371, device='cuda:0'), 'train/nll_loss': tensor(3.4220, device='cuda:0'), 'train/rec_loss': tensor(0.2680, device='cuda:0'), 'train/perception_loss': tensor(0.7552, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.1786, device='cuda:0')}
2025-11-14 08:33:08,206 [INFO] gan_loss : 1.1686053276062012,  gan_log: {'train/disc_loss': tensor(1.1686, device='cuda:0'), 'train/logits_real': tensor(-0.6939, device='cuda:0'), 'train/logits_fake': tensor(-1.1786, device='cuda:0')}
2025-11-14 08:33:12,059 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:33:12,087 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:33:14,696 [INFO] rec_loss: 3.651212215423584, rec_log: {'train/total_loss': tensor(3.6512, device='cuda:0'), 'train/logvar': tensor(0.0056, device='cuda:0'), 'train/kl_loss': tensor(52.5555, device='cuda:0'), 'train/nll_loss': tensor(3.5216, device='cuda:0'), 'train/rec_loss': tensor(0.2781, device='cuda:0'), 'train/perception_loss': tensor(0.7546, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7707, device='cuda:0')}
2025-11-14 08:33:27,888 [INFO] gan_loss : 1.304648995399475,  gan_log: {'train/disc_loss': tensor(1.3046, device='cuda:0'), 'train/logits_real': tensor(-0.4527, device='cuda:0'), 'train/logits_fake': tensor(-0.7707, device='cuda:0')}
2025-11-14 08:33:31,864 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:33:31,892 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:33:34,522 [INFO] rec_loss: 3.52519154548645, rec_log: {'train/total_loss': tensor(3.5252, device='cuda:0'), 'train/logvar': tensor(0.0057, device='cuda:0'), 'train/kl_loss': tensor(54.1837, device='cuda:0'), 'train/nll_loss': tensor(3.4548, device='cuda:0'), 'train/rec_loss': tensor(0.2700, device='cuda:0'), 'train/perception_loss': tensor(0.7689, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.1621, device='cuda:0')}
2025-11-14 08:33:47,703 [INFO] gan_loss : 1.079420804977417,  gan_log: {'train/disc_loss': tensor(1.0794, device='cuda:0'), 'train/logits_real': tensor(0.3141, device='cuda:0'), 'train/logits_fake': tensor(-0.1621, device='cuda:0')}
2025-11-14 08:33:50,282 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:33:50,306 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:33:52,923 [INFO] rec_loss: 3.7195491790771484, rec_log: {'train/total_loss': tensor(3.7195, device='cuda:0'), 'train/logvar': tensor(0.0058, device='cuda:0'), 'train/kl_loss': tensor(56.0309, device='cuda:0'), 'train/nll_loss': tensor(3.7117, device='cuda:0'), 'train/rec_loss': tensor(0.2997, device='cuda:0'), 'train/perception_loss': tensor(0.7304, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.4816, device='cuda:0')}
2025-11-14 08:34:06,114 [INFO] gan_loss : 1.1112358570098877,  gan_log: {'train/disc_loss': tensor(1.1112, device='cuda:0'), 'train/logits_real': tensor(0.5631, device='cuda:0'), 'train/logits_fake': tensor(0.4816, device='cuda:0')}
2025-11-14 08:34:09,538 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:34:09,566 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:34:12,177 [INFO] rec_loss: 3.3195505142211914, rec_log: {'train/total_loss': tensor(3.3196, device='cuda:0'), 'train/logvar': tensor(0.0059, device='cuda:0'), 'train/kl_loss': tensor(42.0693, device='cuda:0'), 'train/nll_loss': tensor(3.2978, device='cuda:0'), 'train/rec_loss': tensor(0.2543, device='cuda:0'), 'train/perception_loss': tensor(0.7679, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.2033, device='cuda:0')}
2025-11-14 08:34:25,365 [INFO] gan_loss : 1.2151942253112793,  gan_log: {'train/disc_loss': tensor(1.2152, device='cuda:0'), 'train/logits_real': tensor(0.2199, device='cuda:0'), 'train/logits_fake': tensor(0.2033, device='cuda:0')}
2025-11-14 08:34:28,998 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:34:29,026 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:34:31,634 [INFO] rec_loss: 2.954130172729492, rec_log: {'train/total_loss': tensor(2.9541, device='cuda:0'), 'train/logvar': tensor(0.0059, device='cuda:0'), 'train/kl_loss': tensor(36.3202, device='cuda:0'), 'train/nll_loss': tensor(2.9044, device='cuda:0'), 'train/rec_loss': tensor(0.2145, device='cuda:0'), 'train/perception_loss': tensor(0.7712, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.1342, device='cuda:0')}
2025-11-14 08:34:44,805 [INFO] gan_loss : 1.3319817781448364,  gan_log: {'train/disc_loss': tensor(1.3320, device='cuda:0'), 'train/logits_real': tensor(-0.7146, device='cuda:0'), 'train/logits_fake': tensor(-0.1342, device='cuda:0')}
2025-11-14 08:34:48,303 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:34:48,331 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:34:50,933 [INFO] rec_loss: 3.5759170055389404, rec_log: {'train/total_loss': tensor(3.5759, device='cuda:0'), 'train/logvar': tensor(0.0060, device='cuda:0'), 'train/kl_loss': tensor(38.0493, device='cuda:0'), 'train/nll_loss': tensor(3.4498, device='cuda:0'), 'train/rec_loss': tensor(0.2672, device='cuda:0'), 'train/perception_loss': tensor(0.7930, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8811, device='cuda:0')}
2025-11-14 08:35:04,123 [INFO] gan_loss : 1.6964284181594849,  gan_log: {'train/disc_loss': tensor(1.6964, device='cuda:0'), 'train/logits_real': tensor(-1.4708, device='cuda:0'), 'train/logits_fake': tensor(-0.8811, device='cuda:0')}
2025-11-14 08:35:07,554 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:35:07,582 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:35:10,160 [INFO] rec_loss: 3.7036080360412598, rec_log: {'train/total_loss': tensor(3.7036, device='cuda:0'), 'train/logvar': tensor(0.0061, device='cuda:0'), 'train/kl_loss': tensor(49.5308, device='cuda:0'), 'train/nll_loss': tensor(3.5851, device='cuda:0'), 'train/rec_loss': tensor(0.2812, device='cuda:0'), 'train/perception_loss': tensor(0.7887, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6898, device='cuda:0')}
2025-11-14 08:35:23,307 [INFO] gan_loss : 1.7146978378295898,  gan_log: {'train/disc_loss': tensor(1.7147, device='cuda:0'), 'train/logits_real': tensor(-1.3451, device='cuda:0'), 'train/logits_fake': tensor(-0.6898, device='cuda:0')}
2025-11-14 08:35:26,424 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:35:26,453 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:35:29,086 [INFO] rec_loss: 3.3586435317993164, rec_log: {'train/total_loss': tensor(3.3586, device='cuda:0'), 'train/logvar': tensor(0.0062, device='cuda:0'), 'train/kl_loss': tensor(74.9422, device='cuda:0'), 'train/nll_loss': tensor(3.2612, device='cuda:0'), 'train/rec_loss': tensor(0.2468, device='cuda:0'), 'train/perception_loss': tensor(0.8071, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2247, device='cuda:0')}
2025-11-14 08:35:42,234 [INFO] gan_loss : 1.457540512084961,  gan_log: {'train/disc_loss': tensor(1.4575, device='cuda:0'), 'train/logits_real': tensor(-0.8996, device='cuda:0'), 'train/logits_fake': tensor(-0.2247, device='cuda:0')}
2025-11-14 08:35:46,286 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:35:46,314 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:35:48,877 [INFO] rec_loss: 2.927730083465576, rec_log: {'train/total_loss': tensor(2.9277, device='cuda:0'), 'train/logvar': tensor(0.0062, device='cuda:0'), 'train/kl_loss': tensor(103.0327, device='cuda:0'), 'train/nll_loss': tensor(2.9236, device='cuda:0'), 'train/rec_loss': tensor(0.2147, device='cuda:0'), 'train/perception_loss': tensor(0.7890, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.9891, device='cuda:0')}
2025-11-14 08:36:02,045 [INFO] gan_loss : 1.7106446027755737,  gan_log: {'train/disc_loss': tensor(1.7106, device='cuda:0'), 'train/logits_real': tensor(0.2392, device='cuda:0'), 'train/logits_fake': tensor(0.9891, device='cuda:0')}
2025-11-14 08:36:04,951 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:36:04,980 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:36:07,593 [INFO] rec_loss: 3.6310160160064697, rec_log: {'train/total_loss': tensor(3.6310, device='cuda:0'), 'train/logvar': tensor(0.0063, device='cuda:0'), 'train/kl_loss': tensor(138.2093, device='cuda:0'), 'train/nll_loss': tensor(3.6435, device='cuda:0'), 'train/rec_loss': tensor(0.2877, device='cuda:0'), 'train/perception_loss': tensor(0.7833, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-1.5073, device='cuda:0')}
2025-11-14 08:36:20,761 [INFO] gan_loss : 1.9054694175720215,  gan_log: {'train/disc_loss': tensor(1.9055, device='cuda:0'), 'train/logits_real': tensor(0.6246, device='cuda:0'), 'train/logits_fake': tensor(1.5073, device='cuda:0')}
2025-11-14 08:36:23,267 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:36:23,296 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:36:25,943 [INFO] rec_loss: 3.8183107376098633, rec_log: {'train/total_loss': tensor(3.8183, device='cuda:0'), 'train/logvar': tensor(0.0064, device='cuda:0'), 'train/kl_loss': tensor(157.3038, device='cuda:0'), 'train/nll_loss': tensor(3.7592, device='cuda:0'), 'train/rec_loss': tensor(0.2971, device='cuda:0'), 'train/perception_loss': tensor(0.8058, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.9821, device='cuda:0')}
2025-11-14 08:36:39,100 [INFO] gan_loss : 1.4393465518951416,  gan_log: {'train/disc_loss': tensor(1.4393, device='cuda:0'), 'train/logits_real': tensor(0.6034, device='cuda:0'), 'train/logits_fake': tensor(0.9821, device='cuda:0')}
2025-11-14 08:36:42,281 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:36:42,310 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:36:44,920 [INFO] rec_loss: 4.737356662750244, rec_log: {'train/total_loss': tensor(4.7374, device='cuda:0'), 'train/logvar': tensor(0.0065, device='cuda:0'), 'train/kl_loss': tensor(158.7961, device='cuda:0'), 'train/nll_loss': tensor(4.5931, device='cuda:0'), 'train/rec_loss': tensor(0.3806, device='cuda:0'), 'train/perception_loss': tensor(0.8099, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.1455, device='cuda:0')}
2025-11-14 08:36:58,095 [INFO] gan_loss : 1.3964924812316895,  gan_log: {'train/disc_loss': tensor(1.3965, device='cuda:0'), 'train/logits_real': tensor(-0.3125, device='cuda:0'), 'train/logits_fake': tensor(0.1455, device='cuda:0')}
2025-11-14 08:37:01,517 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:37:01,547 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:37:04,174 [INFO] rec_loss: 4.3274760246276855, rec_log: {'train/total_loss': tensor(4.3275, device='cuda:0'), 'train/logvar': tensor(0.0065, device='cuda:0'), 'train/kl_loss': tensor(127.4838, device='cuda:0'), 'train/nll_loss': tensor(4.1466, device='cuda:0'), 'train/rec_loss': tensor(0.3380, device='cuda:0'), 'train/perception_loss': tensor(0.7875, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5341, device='cuda:0')}
2025-11-14 08:37:17,320 [INFO] gan_loss : 1.4152175188064575,  gan_log: {'train/disc_loss': tensor(1.4152, device='cuda:0'), 'train/logits_real': tensor(-0.6671, device='cuda:0'), 'train/logits_fake': tensor(-0.5341, device='cuda:0')}
2025-11-14 08:37:21,276 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:37:21,304 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:37:23,929 [INFO] rec_loss: 3.4119720458984375, rec_log: {'train/total_loss': tensor(3.4120, device='cuda:0'), 'train/logvar': tensor(0.0066, device='cuda:0'), 'train/kl_loss': tensor(109.2934, device='cuda:0'), 'train/nll_loss': tensor(3.2190, device='cuda:0'), 'train/rec_loss': tensor(0.2451, device='cuda:0'), 'train/perception_loss': tensor(0.7823, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8368, device='cuda:0')}
2025-11-14 08:37:37,118 [INFO] gan_loss : 1.0891473293304443,  gan_log: {'train/disc_loss': tensor(1.0891, device='cuda:0'), 'train/logits_real': tensor(-0.6504, device='cuda:0'), 'train/logits_fake': tensor(-0.8368, device='cuda:0')}
2025-11-14 08:37:40,539 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:37:40,566 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:37:43,181 [INFO] rec_loss: 3.778157949447632, rec_log: {'train/total_loss': tensor(3.7782, device='cuda:0'), 'train/logvar': tensor(0.0067, device='cuda:0'), 'train/kl_loss': tensor(74.6129, device='cuda:0'), 'train/nll_loss': tensor(3.6791, device='cuda:0'), 'train/rec_loss': tensor(0.2950, device='cuda:0'), 'train/perception_loss': tensor(0.7476, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2443, device='cuda:0')}
2025-11-14 08:37:56,368 [INFO] gan_loss : 1.2653241157531738,  gan_log: {'train/disc_loss': tensor(1.2653, device='cuda:0'), 'train/logits_real': tensor(-0.2450, device='cuda:0'), 'train/logits_fake': tensor(-0.2443, device='cuda:0')}
2025-11-14 08:37:59,842 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:37:59,870 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:38:02,487 [INFO] rec_loss: 3.6419925689697266, rec_log: {'train/total_loss': tensor(3.6420, device='cuda:0'), 'train/logvar': tensor(0.0068, device='cuda:0'), 'train/kl_loss': tensor(63.1197, device='cuda:0'), 'train/nll_loss': tensor(3.6243, device='cuda:0'), 'train/rec_loss': tensor(0.2877, device='cuda:0'), 'train/perception_loss': tensor(0.7653, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.4542, device='cuda:0')}
2025-11-14 08:38:15,679 [INFO] gan_loss : 1.3082189559936523,  gan_log: {'train/disc_loss': tensor(1.3082, device='cuda:0'), 'train/logits_real': tensor(0.5099, device='cuda:0'), 'train/logits_fake': tensor(0.4542, device='cuda:0')}
2025-11-14 08:38:19,243 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:38:19,271 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:38:21,838 [INFO] rec_loss: 3.3106486797332764, rec_log: {'train/total_loss': tensor(3.3106, device='cuda:0'), 'train/logvar': tensor(0.0069, device='cuda:0'), 'train/kl_loss': tensor(72.5873, device='cuda:0'), 'train/nll_loss': tensor(3.2784, device='cuda:0'), 'train/rec_loss': tensor(0.2526, device='cuda:0'), 'train/perception_loss': tensor(0.7679, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.4037, device='cuda:0')}
2025-11-14 08:38:34,977 [INFO] gan_loss : 1.0573810338974,  gan_log: {'train/disc_loss': tensor(1.0574, device='cuda:0'), 'train/logits_real': tensor(0.5188, device='cuda:0'), 'train/logits_fake': tensor(0.4037, device='cuda:0')}
2025-11-14 08:38:38,121 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:38:38,149 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:38:40,764 [INFO] rec_loss: 3.556772470474243, rec_log: {'train/total_loss': tensor(3.5568, device='cuda:0'), 'train/logvar': tensor(0.0069, device='cuda:0'), 'train/kl_loss': tensor(64.9335, device='cuda:0'), 'train/nll_loss': tensor(3.4637, device='cuda:0'), 'train/rec_loss': tensor(0.2710, device='cuda:0'), 'train/perception_loss': tensor(0.7706, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2816, device='cuda:0')}
2025-11-14 08:38:53,915 [INFO] gan_loss : 1.1886422634124756,  gan_log: {'train/disc_loss': tensor(1.1886, device='cuda:0'), 'train/logits_real': tensor(0.0196, device='cuda:0'), 'train/logits_fake': tensor(-0.2816, device='cuda:0')}
2025-11-14 08:38:57,117 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:38:57,139 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:38:59,717 [INFO] rec_loss: 3.4764413833618164, rec_log: {'train/total_loss': tensor(3.4764, device='cuda:0'), 'train/logvar': tensor(0.0070, device='cuda:0'), 'train/kl_loss': tensor(57.0627, device='cuda:0'), 'train/nll_loss': tensor(3.3396, device='cuda:0'), 'train/rec_loss': tensor(0.2563, device='cuda:0'), 'train/perception_loss': tensor(0.7931, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7982, device='cuda:0')}
2025-11-14 08:39:12,903 [INFO] gan_loss : 1.2554821968078613,  gan_log: {'train/disc_loss': tensor(1.2555, device='cuda:0'), 'train/logits_real': tensor(-0.4631, device='cuda:0'), 'train/logits_fake': tensor(-0.7982, device='cuda:0')}
2025-11-14 08:39:16,629 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:39:16,657 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:39:19,262 [INFO] rec_loss: 3.4218759536743164, rec_log: {'train/total_loss': tensor(3.4219, device='cuda:0'), 'train/logvar': tensor(0.0071, device='cuda:0'), 'train/kl_loss': tensor(45.4718, device='cuda:0'), 'train/nll_loss': tensor(3.2565, device='cuda:0'), 'train/rec_loss': tensor(0.2522, device='cuda:0'), 'train/perception_loss': tensor(0.7506, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.1992, device='cuda:0')}
2025-11-14 08:39:32,451 [INFO] gan_loss : 1.1090424060821533,  gan_log: {'train/disc_loss': tensor(1.1090, device='cuda:0'), 'train/logits_real': tensor(-0.9094, device='cuda:0'), 'train/logits_fake': tensor(-1.1992, device='cuda:0')}
2025-11-14 08:39:36,201 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:39:36,230 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:39:38,889 [INFO] rec_loss: 3.5998635292053223, rec_log: {'train/total_loss': tensor(3.5999, device='cuda:0'), 'train/logvar': tensor(0.0072, device='cuda:0'), 'train/kl_loss': tensor(59.2789, device='cuda:0'), 'train/nll_loss': tensor(3.4809, device='cuda:0'), 'train/rec_loss': tensor(0.2738, device='cuda:0'), 'train/perception_loss': tensor(0.7611, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5973, device='cuda:0')}
2025-11-14 08:39:52,089 [INFO] gan_loss : 1.1049482822418213,  gan_log: {'train/disc_loss': tensor(1.1049, device='cuda:0'), 'train/logits_real': tensor(-0.2688, device='cuda:0'), 'train/logits_fake': tensor(-0.5973, device='cuda:0')}
2025-11-14 08:39:55,740 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:39:55,768 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:39:58,398 [INFO] rec_loss: 2.8192784786224365, rec_log: {'train/total_loss': tensor(2.8193, device='cuda:0'), 'train/logvar': tensor(0.0072, device='cuda:0'), 'train/kl_loss': tensor(74.7564, device='cuda:0'), 'train/nll_loss': tensor(2.7441, device='cuda:0'), 'train/rec_loss': tensor(0.2011, device='cuda:0'), 'train/perception_loss': tensor(0.7457, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0040, device='cuda:0')}
2025-11-14 08:40:11,570 [INFO] gan_loss : 1.1614136695861816,  gan_log: {'train/disc_loss': tensor(1.1614, device='cuda:0'), 'train/logits_real': tensor(0.3480, device='cuda:0'), 'train/logits_fake': tensor(-0.0040, device='cuda:0')}
2025-11-14 08:41:09,904 [INFO] gan_loss : 0.9627445936203003,  gan_log: {'train/disc_loss': tensor(0.9627, device='cuda:0'), 'train/logits_real': tensor(-0.0592, device='cuda:0'), 'train/logits_fake': tensor(-0.5792, device='cuda:0')}
2025-11-14 08:41:13,319 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:41:13,343 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:41:15,919 [INFO] rec_loss: 3.506997585296631, rec_log: {'train/total_loss': tensor(3.5070, device='cuda:0'), 'train/logvar': tensor(0.0075, device='cuda:0'), 'train/kl_loss': tensor(71.4711, device='cuda:0'), 'train/nll_loss': tensor(3.3272, device='cuda:0'), 'train/rec_loss': tensor(0.2539, device='cuda:0'), 'train/perception_loss': tensor(0.8058, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.0836, device='cuda:0')}
2025-11-14 08:41:29,102 [INFO] gan_loss : 0.9478858709335327,  gan_log: {'train/disc_loss': tensor(0.9479, device='cuda:0'), 'train/logits_real': tensor(-0.5279, device='cuda:0'), 'train/logits_fake': tensor(-1.0836, device='cuda:0')}
2025-11-14 08:41:31,648 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:41:31,677 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:41:34,287 [INFO] rec_loss: 3.0147697925567627, rec_log: {'train/total_loss': tensor(3.0148, device='cuda:0'), 'train/logvar': tensor(0.0076, device='cuda:0'), 'train/kl_loss': tensor(71.5501, device='cuda:0'), 'train/nll_loss': tensor(2.8821, device='cuda:0'), 'train/rec_loss': tensor(0.2151, device='cuda:0'), 'train/perception_loss': tensor(0.7450, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6113, device='cuda:0')}
2025-11-14 08:41:47,481 [INFO] gan_loss : 0.9772443771362305,  gan_log: {'train/disc_loss': tensor(0.9772, device='cuda:0'), 'train/logits_real': tensor(-0.1501, device='cuda:0'), 'train/logits_fake': tensor(-0.6113, device='cuda:0')}
2025-11-14 08:41:50,009 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:41:50,040 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:41:52,652 [INFO] rec_loss: 3.430837631225586, rec_log: {'train/total_loss': tensor(3.4308, device='cuda:0'), 'train/logvar': tensor(0.0077, device='cuda:0'), 'train/kl_loss': tensor(61.9100, device='cuda:0'), 'train/nll_loss': tensor(3.3864, device='cuda:0'), 'train/rec_loss': tensor(0.2666, device='cuda:0'), 'train/perception_loss': tensor(0.7384, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.1743, device='cuda:0')}
2025-11-14 08:42:05,839 [INFO] gan_loss : 0.8227384686470032,  gan_log: {'train/disc_loss': tensor(0.8227, device='cuda:0'), 'train/logits_real': tensor(0.6574, device='cuda:0'), 'train/logits_fake': tensor(0.1743, device='cuda:0')}
2025-11-14 08:42:09,763 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:42:09,791 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:42:12,404 [INFO] rec_loss: 3.908457040786743, rec_log: {'train/total_loss': tensor(3.9085, device='cuda:0'), 'train/logvar': tensor(0.0077, device='cuda:0'), 'train/kl_loss': tensor(59.8722, device='cuda:0'), 'train/nll_loss': tensor(3.8354, device='cuda:0'), 'train/rec_loss': tensor(0.3093, device='cuda:0'), 'train/perception_loss': tensor(0.7649, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.1321, device='cuda:0')}
2025-11-14 08:42:25,602 [INFO] gan_loss : 1.043982744216919,  gan_log: {'train/disc_loss': tensor(1.0440, device='cuda:0'), 'train/logits_real': tensor(0.3420, device='cuda:0'), 'train/logits_fake': tensor(-0.1321, device='cuda:0')}
2025-11-14 08:42:29,715 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:42:29,744 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:42:32,326 [INFO] rec_loss: 2.9629862308502197, rec_log: {'train/total_loss': tensor(2.9630, device='cuda:0'), 'train/logvar': tensor(0.0078, device='cuda:0'), 'train/kl_loss': tensor(56.2477, device='cuda:0'), 'train/nll_loss': tensor(2.8310, device='cuda:0'), 'train/rec_loss': tensor(0.2058, device='cuda:0'), 'train/perception_loss': tensor(0.7871, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7571, device='cuda:0')}
2025-11-14 08:42:45,487 [INFO] gan_loss : 1.0112215280532837,  gan_log: {'train/disc_loss': tensor(1.0112, device='cuda:0'), 'train/logits_real': tensor(-0.1708, device='cuda:0'), 'train/logits_fake': tensor(-0.7571, device='cuda:0')}
2025-11-14 08:42:49,454 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:42:49,483 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:42:52,051 [INFO] rec_loss: 3.6631104946136475, rec_log: {'train/total_loss': tensor(3.6631, device='cuda:0'), 'train/logvar': tensor(0.0079, device='cuda:0'), 'train/kl_loss': tensor(56.9014, device='cuda:0'), 'train/nll_loss': tensor(3.5339, device='cuda:0'), 'train/rec_loss': tensor(0.2777, device='cuda:0'), 'train/perception_loss': tensor(0.7769, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7227, device='cuda:0')}
2025-11-14 08:43:05,198 [INFO] gan_loss : 0.832798182964325,  gan_log: {'train/disc_loss': tensor(0.8328, device='cuda:0'), 'train/logits_real': tensor(-0.1737, device='cuda:0'), 'train/logits_fake': tensor(-0.7227, device='cuda:0')}
2025-11-14 08:43:08,770 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:43:08,798 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:43:11,402 [INFO] rec_loss: 3.0422356128692627, rec_log: {'train/total_loss': tensor(3.0422, device='cuda:0'), 'train/logvar': tensor(0.0080, device='cuda:0'), 'train/kl_loss': tensor(59.2464, device='cuda:0'), 'train/nll_loss': tensor(2.9836, device='cuda:0'), 'train/rec_loss': tensor(0.2238, device='cuda:0'), 'train/perception_loss': tensor(0.7612, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.0059, device='cuda:0')}
2025-11-14 08:43:24,582 [INFO] gan_loss : 0.9389029741287231,  gan_log: {'train/disc_loss': tensor(0.9389, device='cuda:0'), 'train/logits_real': tensor(0.4788, device='cuda:0'), 'train/logits_fake': tensor(0.0059, device='cuda:0')}
2025-11-14 08:43:28,451 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:43:28,480 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:43:31,101 [INFO] rec_loss: 2.7615795135498047, rec_log: {'train/total_loss': tensor(2.7616, device='cuda:0'), 'train/logvar': tensor(0.0080, device='cuda:0'), 'train/kl_loss': tensor(56.5815, device='cuda:0'), 'train/nll_loss': tensor(2.7385, device='cuda:0'), 'train/rec_loss': tensor(0.1999, device='cuda:0'), 'train/perception_loss': tensor(0.7538, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.3349, device='cuda:0')}
2025-11-14 08:43:44,255 [INFO] gan_loss : 0.8515792489051819,  gan_log: {'train/disc_loss': tensor(0.8516, device='cuda:0'), 'train/logits_real': tensor(0.8726, device='cuda:0'), 'train/logits_fake': tensor(0.3349, device='cuda:0')}
2025-11-14 08:43:48,139 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:43:48,166 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:43:50,774 [INFO] rec_loss: 3.6993062496185303, rec_log: {'train/total_loss': tensor(3.6993, device='cuda:0'), 'train/logvar': tensor(0.0081, device='cuda:0'), 'train/kl_loss': tensor(68.3677, device='cuda:0'), 'train/nll_loss': tensor(3.6045, device='cuda:0'), 'train/rec_loss': tensor(0.2883, device='cuda:0'), 'train/perception_loss': tensor(0.7430, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2649, device='cuda:0')}
2025-11-14 08:44:03,956 [INFO] gan_loss : 0.8174224495887756,  gan_log: {'train/disc_loss': tensor(0.8174, device='cuda:0'), 'train/logits_real': tensor(0.4004, device='cuda:0'), 'train/logits_fake': tensor(-0.2649, device='cuda:0')}
2025-11-14 08:44:07,613 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:44:07,641 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:44:10,237 [INFO] rec_loss: 3.0193424224853516, rec_log: {'train/total_loss': tensor(3.0193, device='cuda:0'), 'train/logvar': tensor(0.0082, device='cuda:0'), 'train/kl_loss': tensor(62.9959, device='cuda:0'), 'train/nll_loss': tensor(2.8465, device='cuda:0'), 'train/rec_loss': tensor(0.2110, device='cuda:0'), 'train/perception_loss': tensor(0.7519, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.0989, device='cuda:0')}
2025-11-14 08:44:23,427 [INFO] gan_loss : 0.889163076877594,  gan_log: {'train/disc_loss': tensor(0.8892, device='cuda:0'), 'train/logits_real': tensor(-0.4626, device='cuda:0'), 'train/logits_fake': tensor(-1.0989, device='cuda:0')}
2025-11-14 08:44:26,839 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:44:26,867 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:44:29,484 [INFO] rec_loss: 3.4026410579681396, rec_log: {'train/total_loss': tensor(3.4026, device='cuda:0'), 'train/logvar': tensor(0.0083, device='cuda:0'), 'train/kl_loss': tensor(75.5284, device='cuda:0'), 'train/nll_loss': tensor(3.2485, device='cuda:0'), 'train/rec_loss': tensor(0.2528, device='cuda:0'), 'train/perception_loss': tensor(0.7391, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7858, device='cuda:0')}
2025-11-14 08:44:42,632 [INFO] gan_loss : 0.8260952234268188,  gan_log: {'train/disc_loss': tensor(0.8261, device='cuda:0'), 'train/logits_real': tensor(-0.0383, device='cuda:0'), 'train/logits_fake': tensor(-0.7858, device='cuda:0')}
2025-11-14 08:44:46,578 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:44:46,607 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:44:49,182 [INFO] rec_loss: 3.531276226043701, rec_log: {'train/total_loss': tensor(3.5313, device='cuda:0'), 'train/logvar': tensor(0.0083, device='cuda:0'), 'train/kl_loss': tensor(69.9967, device='cuda:0'), 'train/nll_loss': tensor(3.4248, device='cuda:0'), 'train/rec_loss': tensor(0.2661, device='cuda:0'), 'train/perception_loss': tensor(0.7841, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.3647, device='cuda:0')}
2025-11-14 08:45:02,326 [INFO] gan_loss : 0.7503935694694519,  gan_log: {'train/disc_loss': tensor(0.7504, device='cuda:0'), 'train/logits_real': tensor(0.2657, device='cuda:0'), 'train/logits_fake': tensor(-0.3647, device='cuda:0')}
2025-11-14 08:45:05,717 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:45:05,745 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:45:08,310 [INFO] rec_loss: 2.9541540145874023, rec_log: {'train/total_loss': tensor(2.9542, device='cuda:0'), 'train/logvar': tensor(0.0084, device='cuda:0'), 'train/kl_loss': tensor(75.4621, device='cuda:0'), 'train/nll_loss': tensor(2.8774, device='cuda:0'), 'train/rec_loss': tensor(0.2141, device='cuda:0'), 'train/perception_loss': tensor(0.7519, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0134, device='cuda:0')}
2025-11-14 08:45:21,498 [INFO] gan_loss : 0.9895073175430298,  gan_log: {'train/disc_loss': tensor(0.9895, device='cuda:0'), 'train/logits_real': tensor(0.5874, device='cuda:0'), 'train/logits_fake': tensor(-0.0134, device='cuda:0')}
2025-11-14 08:45:25,134 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:45:25,157 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:45:27,721 [INFO] rec_loss: 3.3747546672821045, rec_log: {'train/total_loss': tensor(3.3748, device='cuda:0'), 'train/logvar': tensor(0.0085, device='cuda:0'), 'train/kl_loss': tensor(66.8138, device='cuda:0'), 'train/nll_loss': tensor(3.3418, device='cuda:0'), 'train/rec_loss': tensor(0.2600, device='cuda:0'), 'train/perception_loss': tensor(0.7617, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.3382, device='cuda:0')}
2025-11-14 08:45:40,874 [INFO] gan_loss : 1.0465354919433594,  gan_log: {'train/disc_loss': tensor(1.0465, device='cuda:0'), 'train/logits_real': tensor(1.0494, device='cuda:0'), 'train/logits_fake': tensor(0.3382, device='cuda:0')}
2025-11-14 08:45:44,697 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:45:44,726 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:45:47,297 [INFO] rec_loss: 2.7858026027679443, rec_log: {'train/total_loss': tensor(2.7858, device='cuda:0'), 'train/logvar': tensor(0.0085, device='cuda:0'), 'train/kl_loss': tensor(118.1098, device='cuda:0'), 'train/nll_loss': tensor(2.6747, device='cuda:0'), 'train/rec_loss': tensor(0.1936, device='cuda:0'), 'train/perception_loss': tensor(0.7525, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.0698, device='cuda:0')}
2025-11-14 08:46:00,482 [INFO] gan_loss : 0.7657426595687866,  gan_log: {'train/disc_loss': tensor(0.7657, device='cuda:0'), 'train/logits_real': tensor(0.7763, device='cuda:0'), 'train/logits_fake': tensor(0.0698, device='cuda:0')}
2025-11-14 08:46:03,676 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:46:03,704 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:46:06,302 [INFO] rec_loss: 3.0890963077545166, rec_log: {'train/total_loss': tensor(3.0891, device='cuda:0'), 'train/logvar': tensor(0.0086, device='cuda:0'), 'train/kl_loss': tensor(155.5933, device='cuda:0'), 'train/nll_loss': tensor(2.8327, device='cuda:0'), 'train/rec_loss': tensor(0.2082, device='cuda:0'), 'train/perception_loss': tensor(0.7661, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.0080, device='cuda:0')}
2025-11-14 08:46:19,494 [INFO] gan_loss : 0.8717354536056519,  gan_log: {'train/disc_loss': tensor(0.8717, device='cuda:0'), 'train/logits_real': tensor(-0.0485, device='cuda:0'), 'train/logits_fake': tensor(-1.0080, device='cuda:0')}
2025-11-14 08:46:23,056 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:46:23,085 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:46:25,708 [INFO] rec_loss: 3.0833916664123535, rec_log: {'train/total_loss': tensor(3.0834, device='cuda:0'), 'train/logvar': tensor(0.0087, device='cuda:0'), 'train/kl_loss': tensor(128.1224, device='cuda:0'), 'train/nll_loss': tensor(2.7693, device='cuda:0'), 'train/rec_loss': tensor(0.2027, device='cuda:0'), 'train/perception_loss': tensor(0.7579, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.8598, device='cuda:0')}
2025-11-14 08:46:38,901 [INFO] gan_loss : 0.9839445352554321,  gan_log: {'train/disc_loss': tensor(0.9839, device='cuda:0'), 'train/logits_real': tensor(-0.8076, device='cuda:0'), 'train/logits_fake': tensor(-1.8598, device='cuda:0')}
2025-11-14 08:46:41,825 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:46:41,848 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:46:44,426 [INFO] rec_loss: 3.6317906379699707, rec_log: {'train/total_loss': tensor(3.6318, device='cuda:0'), 'train/logvar': tensor(0.0087, device='cuda:0'), 'train/kl_loss': tensor(114.5006, device='cuda:0'), 'train/nll_loss': tensor(3.3493, device='cuda:0'), 'train/rec_loss': tensor(0.2609, device='cuda:0'), 'train/perception_loss': tensor(0.7611, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.6802, device='cuda:0')}
2025-11-14 08:46:57,594 [INFO] gan_loss : 0.8314304947853088,  gan_log: {'train/disc_loss': tensor(0.8314, device='cuda:0'), 'train/logits_real': tensor(-0.6112, device='cuda:0'), 'train/logits_fake': tensor(-1.6802, device='cuda:0')}
2025-11-14 08:47:01,369 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:47:01,398 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:47:04,024 [INFO] rec_loss: 3.3920092582702637, rec_log: {'train/total_loss': tensor(3.3920, device='cuda:0'), 'train/logvar': tensor(0.0088, device='cuda:0'), 'train/kl_loss': tensor(84.8099, device='cuda:0'), 'train/nll_loss': tensor(3.2459, device='cuda:0'), 'train/rec_loss': tensor(0.2517, device='cuda:0'), 'train/perception_loss': tensor(0.7490, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6132, device='cuda:0')}
2025-11-14 08:47:17,184 [INFO] gan_loss : 0.6770079135894775,  gan_log: {'train/disc_loss': tensor(0.6770, device='cuda:0'), 'train/logits_real': tensor(0.4105, device='cuda:0'), 'train/logits_fake': tensor(-0.6132, device='cuda:0')}
2025-11-14 08:47:20,385 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:47:20,413 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:47:23,028 [INFO] rec_loss: 3.9865713119506836, rec_log: {'train/total_loss': tensor(3.9866, device='cuda:0'), 'train/logvar': tensor(0.0089, device='cuda:0'), 'train/kl_loss': tensor(57.3677, device='cuda:0'), 'train/nll_loss': tensor(3.9777, device='cuda:0'), 'train/rec_loss': tensor(0.3264, device='cuda:0'), 'train/perception_loss': tensor(0.7401, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.4846, device='cuda:0')}
2025-11-14 08:47:36,184 [INFO] gan_loss : 0.846580445766449,  gan_log: {'train/disc_loss': tensor(0.8466, device='cuda:0'), 'train/logits_real': tensor(1.3228, device='cuda:0'), 'train/logits_fake': tensor(0.4846, device='cuda:0')}
2025-11-14 08:47:40,065 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:47:40,093 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:47:42,678 [INFO] rec_loss: 2.964536190032959, rec_log: {'train/total_loss': tensor(2.9645, device='cuda:0'), 'train/logvar': tensor(0.0090, device='cuda:0'), 'train/kl_loss': tensor(73.1159, device='cuda:0'), 'train/nll_loss': tensor(2.9103, device='cuda:0'), 'train/rec_loss': tensor(0.2170, device='cuda:0'), 'train/perception_loss': tensor(0.7570, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.1886, device='cuda:0')}
2025-11-14 08:47:55,816 [INFO] gan_loss : 0.7174744606018066,  gan_log: {'train/disc_loss': tensor(0.7175, device='cuda:0'), 'train/logits_real': tensor(1.2706, device='cuda:0'), 'train/logits_fake': tensor(0.1886, device='cuda:0')}
2025-11-14 08:47:59,328 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:47:59,352 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:48:01,921 [INFO] rec_loss: 3.4184141159057617, rec_log: {'train/total_loss': tensor(3.4184, device='cuda:0'), 'train/logvar': tensor(0.0090, device='cuda:0'), 'train/kl_loss': tensor(92.0488, device='cuda:0'), 'train/nll_loss': tensor(3.2384, device='cuda:0'), 'train/rec_loss': tensor(0.2491, device='cuda:0'), 'train/perception_loss': tensor(0.7679, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8796, device='cuda:0')}
2025-11-14 08:48:15,120 [INFO] gan_loss : 0.5842000246047974,  gan_log: {'train/disc_loss': tensor(0.5842, device='cuda:0'), 'train/logits_real': tensor(0.4432, device='cuda:0'), 'train/logits_fake': tensor(-0.8796, device='cuda:0')}
2025-11-14 08:48:18,446 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:48:18,475 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:48:21,076 [INFO] rec_loss: 2.8807790279388428, rec_log: {'train/total_loss': tensor(2.8808, device='cuda:0'), 'train/logvar': tensor(0.0091, device='cuda:0'), 'train/kl_loss': tensor(99.5651, device='cuda:0'), 'train/nll_loss': tensor(2.6052, device='cuda:0'), 'train/rec_loss': tensor(0.1873, device='cuda:0'), 'train/perception_loss': tensor(0.7466, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.7597, device='cuda:0')}
2025-11-14 08:48:34,261 [INFO] gan_loss : 0.857697606086731,  gan_log: {'train/disc_loss': tensor(0.8577, device='cuda:0'), 'train/logits_real': tensor(-0.4906, device='cuda:0'), 'train/logits_fake': tensor(-1.7597, device='cuda:0')}
2025-11-14 08:48:38,165 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:48:38,193 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:48:40,772 [INFO] rec_loss: 3.1336798667907715, rec_log: {'train/total_loss': tensor(3.1337, device='cuda:0'), 'train/logvar': tensor(0.0092, device='cuda:0'), 'train/kl_loss': tensor(178.7068, device='cuda:0'), 'train/nll_loss': tensor(2.7945, device='cuda:0'), 'train/rec_loss': tensor(0.2068, device='cuda:0'), 'train/perception_loss': tensor(0.7426, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.6045, device='cuda:0')}
2025-11-14 08:48:53,957 [INFO] gan_loss : 0.9079023599624634,  gan_log: {'train/disc_loss': tensor(0.9079, device='cuda:0'), 'train/logits_real': tensor(-0.4274, device='cuda:0'), 'train/logits_fake': tensor(-1.6045, device='cuda:0')}
2025-11-14 08:48:57,329 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:48:57,352 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:48:59,975 [INFO] rec_loss: 3.2029244899749756, rec_log: {'train/total_loss': tensor(3.2029, device='cuda:0'), 'train/logvar': tensor(0.0092, device='cuda:0'), 'train/kl_loss': tensor(101.3602, device='cuda:0'), 'train/nll_loss': tensor(3.0050, device='cuda:0'), 'train/rec_loss': tensor(0.2302, device='cuda:0'), 'train/perception_loss': tensor(0.7219, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.9657, device='cuda:0')}
2025-11-14 08:49:13,153 [INFO] gan_loss : 0.5994514226913452,  gan_log: {'train/disc_loss': tensor(0.5995, device='cuda:0'), 'train/logits_real': tensor(0.1786, device='cuda:0'), 'train/logits_fake': tensor(-0.9657, device='cuda:0')}
2025-11-14 08:49:16,144 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:49:16,167 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:49:18,736 [INFO] rec_loss: 3.463305950164795, rec_log: {'train/total_loss': tensor(3.4633, device='cuda:0'), 'train/logvar': tensor(0.0093, device='cuda:0'), 'train/kl_loss': tensor(75.7951, device='cuda:0'), 'train/nll_loss': tensor(3.4136, device='cuda:0'), 'train/rec_loss': tensor(0.2640, device='cuda:0'), 'train/perception_loss': tensor(0.7958, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.2610, device='cuda:0')}
2025-11-14 08:49:31,919 [INFO] gan_loss : 1.0102975368499756,  gan_log: {'train/disc_loss': tensor(1.0103, device='cuda:0'), 'train/logits_real': tensor(1.5143, device='cuda:0'), 'train/logits_fake': tensor(0.2610, device='cuda:0')}
2025-11-14 08:49:35,974 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:49:36,002 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:49:38,594 [INFO] rec_loss: 3.6950814723968506, rec_log: {'train/total_loss': tensor(3.6951, device='cuda:0'), 'train/logvar': tensor(0.0094, device='cuda:0'), 'train/kl_loss': tensor(72.1466, device='cuda:0'), 'train/nll_loss': tensor(3.6946, device='cuda:0'), 'train/rec_loss': tensor(0.2945, device='cuda:0'), 'train/perception_loss': tensor(0.7747, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.7164, device='cuda:0')}
2025-11-14 08:49:51,762 [INFO] gan_loss : 1.1394716501235962,  gan_log: {'train/disc_loss': tensor(1.1395, device='cuda:0'), 'train/logits_real': tensor(2.1404, device='cuda:0'), 'train/logits_fake': tensor(0.7164, device='cuda:0')}
2025-11-14 08:49:55,634 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:49:55,663 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:49:58,304 [INFO] rec_loss: 2.40523362159729, rec_log: {'train/total_loss': tensor(2.4052, device='cuda:0'), 'train/logvar': tensor(0.0094, device='cuda:0'), 'train/kl_loss': tensor(61.4864, device='cuda:0'), 'train/nll_loss': tensor(2.3978, device='cuda:0'), 'train/rec_loss': tensor(0.1674, device='cuda:0'), 'train/perception_loss': tensor(0.7373, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.5403, device='cuda:0')}
2025-11-14 08:50:11,458 [INFO] gan_loss : 0.8335109949111938,  gan_log: {'train/disc_loss': tensor(0.8335, device='cuda:0'), 'train/logits_real': tensor(2.2301, device='cuda:0'), 'train/logits_fake': tensor(0.5403, device='cuda:0')}
2025-11-14 08:50:15,011 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:50:15,034 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:50:17,613 [INFO] rec_loss: 2.796074867248535, rec_log: {'train/total_loss': tensor(2.7961, device='cuda:0'), 'train/logvar': tensor(0.0095, device='cuda:0'), 'train/kl_loss': tensor(84.2237, device='cuda:0'), 'train/nll_loss': tensor(2.6863, device='cuda:0'), 'train/rec_loss': tensor(0.1964, device='cuda:0'), 'train/perception_loss': tensor(0.7385, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2555, device='cuda:0')}
2025-11-14 08:50:30,800 [INFO] gan_loss : 0.5959184169769287,  gan_log: {'train/disc_loss': tensor(0.5959, device='cuda:0'), 'train/logits_real': tensor(1.3085, device='cuda:0'), 'train/logits_fake': tensor(-0.2555, device='cuda:0')}
2025-11-14 08:50:34,402 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:50:34,426 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:50:37,033 [INFO] rec_loss: 2.5394699573516846, rec_log: {'train/total_loss': tensor(2.5395, device='cuda:0'), 'train/logvar': tensor(0.0096, device='cuda:0'), 'train/kl_loss': tensor(68.8673, device='cuda:0'), 'train/nll_loss': tensor(2.2906, device='cuda:0'), 'train/rec_loss': tensor(0.1561, device='cuda:0'), 'train/perception_loss': tensor(0.7422, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.7996, device='cuda:0')}
2025-11-14 08:50:50,204 [INFO] gan_loss : 0.6566201448440552,  gan_log: {'train/disc_loss': tensor(0.6566, device='cuda:0'), 'train/logits_real': tensor(0.0187, device='cuda:0'), 'train/logits_fake': tensor(-1.7996, device='cuda:0')}
2025-11-14 08:50:53,382 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:50:53,409 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:50:56,029 [INFO] rec_loss: 3.281546115875244, rec_log: {'train/total_loss': tensor(3.2815, device='cuda:0'), 'train/logvar': tensor(0.0097, device='cuda:0'), 'train/kl_loss': tensor(75.7224, device='cuda:0'), 'train/nll_loss': tensor(2.9928, device='cuda:0'), 'train/rec_loss': tensor(0.2266, device='cuda:0'), 'train/perception_loss': tensor(0.7461, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.1305, device='cuda:0')}
2025-11-14 08:51:09,170 [INFO] gan_loss : 0.746573805809021,  gan_log: {'train/disc_loss': tensor(0.7466, device='cuda:0'), 'train/logits_real': tensor(-0.4011, device='cuda:0'), 'train/logits_fake': tensor(-2.1305, device='cuda:0')}
2025-11-14 08:51:13,399 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:51:13,428 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:51:16,052 [INFO] rec_loss: 4.310424327850342, rec_log: {'train/total_loss': tensor(4.3104, device='cuda:0'), 'train/logvar': tensor(0.0097, device='cuda:0'), 'train/kl_loss': tensor(119.7066, device='cuda:0'), 'train/nll_loss': tensor(4.0565, device='cuda:0'), 'train/rec_loss': tensor(0.3343, device='cuda:0'), 'train/perception_loss': tensor(0.7434, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3422, device='cuda:0')}
2025-11-14 08:51:29,237 [INFO] gan_loss : 0.9595714211463928,  gan_log: {'train/disc_loss': tensor(0.9596, device='cuda:0'), 'train/logits_real': tensor(-0.2850, device='cuda:0'), 'train/logits_fake': tensor(-1.3422, device='cuda:0')}
2025-11-14 08:51:32,229 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:51:32,253 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:51:34,866 [INFO] rec_loss: 2.4603261947631836, rec_log: {'train/total_loss': tensor(2.4603, device='cuda:0'), 'train/logvar': tensor(0.0098, device='cuda:0'), 'train/kl_loss': tensor(107.2879, device='cuda:0'), 'train/nll_loss': tensor(2.3525, device='cuda:0'), 'train/rec_loss': tensor(0.1632, device='cuda:0'), 'train/perception_loss': tensor(0.7339, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0055, device='cuda:0')}
2025-11-14 08:51:48,055 [INFO] gan_loss : 0.9048600196838379,  gan_log: {'train/disc_loss': tensor(0.9049, device='cuda:0'), 'train/logits_real': tensor(0.7235, device='cuda:0'), 'train/logits_fake': tensor(-0.0055, device='cuda:0')}
2025-11-14 08:51:51,605 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:51:51,634 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:51:54,248 [INFO] rec_loss: 2.690922975540161, rec_log: {'train/total_loss': tensor(2.6909, device='cuda:0'), 'train/logvar': tensor(0.0099, device='cuda:0'), 'train/kl_loss': tensor(111.5989, device='cuda:0'), 'train/nll_loss': tensor(2.6505, device='cuda:0'), 'train/rec_loss': tensor(0.1927, device='cuda:0'), 'train/perception_loss': tensor(0.7397, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.7115, device='cuda:0')}
2025-11-14 08:52:07,429 [INFO] gan_loss : 1.1702632904052734,  gan_log: {'train/disc_loss': tensor(1.1703, device='cuda:0'), 'train/logits_real': tensor(1.0758, device='cuda:0'), 'train/logits_fake': tensor(0.7115, device='cuda:0')}
2025-11-14 08:52:10,352 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:52:10,375 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:52:12,990 [INFO] rec_loss: 3.7094969749450684, rec_log: {'train/total_loss': tensor(3.7095, device='cuda:0'), 'train/logvar': tensor(0.0099, device='cuda:0'), 'train/kl_loss': tensor(115.2480, device='cuda:0'), 'train/nll_loss': tensor(3.6857, device='cuda:0'), 'train/rec_loss': tensor(0.2958, device='cuda:0'), 'train/perception_loss': tensor(0.7544, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.9149, device='cuda:0')}
2025-11-14 08:52:26,159 [INFO] gan_loss : 1.2773828506469727,  gan_log: {'train/disc_loss': tensor(1.2774, device='cuda:0'), 'train/logits_real': tensor(1.1112, device='cuda:0'), 'train/logits_fake': tensor(0.9149, device='cuda:0')}
2025-11-14 08:52:30,089 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:52:30,118 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:52:32,697 [INFO] rec_loss: 2.9204299449920654, rec_log: {'train/total_loss': tensor(2.9204, device='cuda:0'), 'train/logvar': tensor(0.0100, device='cuda:0'), 'train/kl_loss': tensor(96.0812, device='cuda:0'), 'train/nll_loss': tensor(2.7987, device='cuda:0'), 'train/rec_loss': tensor(0.2046, device='cuda:0'), 'train/perception_loss': tensor(0.7709, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2565, device='cuda:0')}
2025-11-14 08:52:45,894 [INFO] gan_loss : 1.0145143270492554,  gan_log: {'train/disc_loss': tensor(1.0145, device='cuda:0'), 'train/logits_real': tensor(0.3166, device='cuda:0'), 'train/logits_fake': tensor(-0.2565, device='cuda:0')}
2025-11-14 08:52:49,383 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:52:49,412 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:52:52,043 [INFO] rec_loss: 3.654294490814209, rec_log: {'train/total_loss': tensor(3.6543, device='cuda:0'), 'train/logvar': tensor(0.0101, device='cuda:0'), 'train/kl_loss': tensor(98.7648, device='cuda:0'), 'train/nll_loss': tensor(3.4242, device='cuda:0'), 'train/rec_loss': tensor(0.2657, device='cuda:0'), 'train/perception_loss': tensor(0.7912, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3136, device='cuda:0')}
2025-11-14 08:53:05,223 [INFO] gan_loss : 0.9681893587112427,  gan_log: {'train/disc_loss': tensor(0.9682, device='cuda:0'), 'train/logits_real': tensor(-0.5983, device='cuda:0'), 'train/logits_fake': tensor(-1.3136, device='cuda:0')}
2025-11-14 08:53:08,871 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:53:08,899 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:53:11,519 [INFO] rec_loss: 4.213171482086182, rec_log: {'train/total_loss': tensor(4.2132, device='cuda:0'), 'train/logvar': tensor(0.0101, device='cuda:0'), 'train/kl_loss': tensor(101.4385, device='cuda:0'), 'train/nll_loss': tensor(3.9269, device='cuda:0'), 'train/rec_loss': tensor(0.3195, device='cuda:0'), 'train/perception_loss': tensor(0.7611, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.8486, device='cuda:0')}
2025-11-14 08:53:24,665 [INFO] gan_loss : 0.8183542490005493,  gan_log: {'train/disc_loss': tensor(0.8184, device='cuda:0'), 'train/logits_real': tensor(-0.3751, device='cuda:0'), 'train/logits_fake': tensor(-1.8486, device='cuda:0')}
2025-11-14 08:53:27,647 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:53:27,677 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:53:30,296 [INFO] rec_loss: 3.494302988052368, rec_log: {'train/total_loss': tensor(3.4943, device='cuda:0'), 'train/logvar': tensor(0.0102, device='cuda:0'), 'train/kl_loss': tensor(73.3045, device='cuda:0'), 'train/nll_loss': tensor(3.3388, device='cuda:0'), 'train/rec_loss': tensor(0.2600, device='cuda:0'), 'train/perception_loss': tensor(0.7629, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8219, device='cuda:0')}
2025-11-14 08:53:43,490 [INFO] gan_loss : 0.8059735298156738,  gan_log: {'train/disc_loss': tensor(0.8060, device='cuda:0'), 'train/logits_real': tensor(0.3625, device='cuda:0'), 'train/logits_fake': tensor(-0.8219, device='cuda:0')}
2025-11-14 08:53:46,689 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:53:46,717 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:53:49,328 [INFO] rec_loss: 3.0694785118103027, rec_log: {'train/total_loss': tensor(3.0695, device='cuda:0'), 'train/logvar': tensor(0.0103, device='cuda:0'), 'train/kl_loss': tensor(78.8383, device='cuda:0'), 'train/nll_loss': tensor(2.9824, device='cuda:0'), 'train/rec_loss': tensor(0.2239, device='cuda:0'), 'train/perception_loss': tensor(0.7641, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0823, device='cuda:0')}
2025-11-14 08:54:02,540 [INFO] gan_loss : 0.750670313835144,  gan_log: {'train/disc_loss': tensor(0.7507, device='cuda:0'), 'train/logits_real': tensor(0.9205, device='cuda:0'), 'train/logits_fake': tensor(-0.0823, device='cuda:0')}
2025-11-14 08:54:06,205 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:54:06,233 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:54:08,851 [INFO] rec_loss: 3.2257790565490723, rec_log: {'train/total_loss': tensor(3.2258, device='cuda:0'), 'train/logvar': tensor(0.0104, device='cuda:0'), 'train/kl_loss': tensor(106.1837, device='cuda:0'), 'train/nll_loss': tensor(3.1301, device='cuda:0'), 'train/rec_loss': tensor(0.2415, device='cuda:0'), 'train/perception_loss': tensor(0.7375, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.1050, device='cuda:0')}
2025-11-14 08:54:22,044 [INFO] gan_loss : 0.7256381511688232,  gan_log: {'train/disc_loss': tensor(0.7256, device='cuda:0'), 'train/logits_real': tensor(1.3829, device='cuda:0'), 'train/logits_fake': tensor(0.1050, device='cuda:0')}
2025-11-14 08:54:25,144 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:54:25,172 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:54:27,791 [INFO] rec_loss: 3.160360336303711, rec_log: {'train/total_loss': tensor(3.1604, device='cuda:0'), 'train/logvar': tensor(0.0104, device='cuda:0'), 'train/kl_loss': tensor(132.2619, device='cuda:0'), 'train/nll_loss': tensor(2.9472, device='cuda:0'), 'train/rec_loss': tensor(0.2211, device='cuda:0'), 'train/perception_loss': tensor(0.7561, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8093, device='cuda:0')}
2025-11-14 08:54:40,996 [INFO] gan_loss : 0.5293980240821838,  gan_log: {'train/disc_loss': tensor(0.5294, device='cuda:0'), 'train/logits_real': tensor(0.5055, device='cuda:0'), 'train/logits_fake': tensor(-0.8093, device='cuda:0')}
2025-11-14 08:54:45,025 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:54:45,052 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:54:47,633 [INFO] rec_loss: 2.7918403148651123, rec_log: {'train/total_loss': tensor(2.7918, device='cuda:0'), 'train/logvar': tensor(0.0105, device='cuda:0'), 'train/kl_loss': tensor(159.0003, device='cuda:0'), 'train/nll_loss': tensor(2.5018, device='cuda:0'), 'train/rec_loss': tensor(0.1769, device='cuda:0'), 'train/perception_loss': tensor(0.7483, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3100, device='cuda:0')}
2025-11-14 08:55:00,787 [INFO] gan_loss : 0.6352946162223816,  gan_log: {'train/disc_loss': tensor(0.6353, device='cuda:0'), 'train/logits_real': tensor(0.4253, device='cuda:0'), 'train/logits_fake': tensor(-1.3100, device='cuda:0')}
2025-11-14 08:55:04,256 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:55:04,284 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:55:06,898 [INFO] rec_loss: 3.2578818798065186, rec_log: {'train/total_loss': tensor(3.2579, device='cuda:0'), 'train/logvar': tensor(0.0106, device='cuda:0'), 'train/kl_loss': tensor(161.3265, device='cuda:0'), 'train/nll_loss': tensor(2.9043, device='cuda:0'), 'train/rec_loss': tensor(0.2190, device='cuda:0'), 'train/perception_loss': tensor(0.7343, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.9230, device='cuda:0')}
2025-11-14 08:55:20,079 [INFO] gan_loss : 0.8164838552474976,  gan_log: {'train/disc_loss': tensor(0.8165, device='cuda:0'), 'train/logits_real': tensor(-0.3581, device='cuda:0'), 'train/logits_fake': tensor(-1.9230, device='cuda:0')}
2025-11-14 08:55:23,723 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:55:23,751 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:55:26,389 [INFO] rec_loss: 3.786015748977661, rec_log: {'train/total_loss': tensor(3.7860, device='cuda:0'), 'train/logvar': tensor(0.0106, device='cuda:0'), 'train/kl_loss': tensor(191.9820, device='cuda:0'), 'train/nll_loss': tensor(3.5072, device='cuda:0'), 'train/rec_loss': tensor(0.2736, device='cuda:0'), 'train/perception_loss': tensor(0.7982, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8682, device='cuda:0')}
2025-11-14 08:55:39,543 [INFO] gan_loss : 0.44458794593811035,  gan_log: {'train/disc_loss': tensor(0.4446, device='cuda:0'), 'train/logits_real': tensor(0.7386, device='cuda:0'), 'train/logits_fake': tensor(-0.8682, device='cuda:0')}
2025-11-14 08:55:43,346 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:55:43,369 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:55:45,988 [INFO] rec_loss: 2.7704567909240723, rec_log: {'train/total_loss': tensor(2.7705, device='cuda:0'), 'train/logvar': tensor(0.0107, device='cuda:0'), 'train/kl_loss': tensor(165.8259, device='cuda:0'), 'train/nll_loss': tensor(2.5156, device='cuda:0'), 'train/rec_loss': tensor(0.1829, device='cuda:0'), 'train/perception_loss': tensor(0.7027, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8901, device='cuda:0')}
2025-11-14 08:55:59,139 [INFO] gan_loss : 0.8281583786010742,  gan_log: {'train/disc_loss': tensor(0.8282, device='cuda:0'), 'train/logits_real': tensor(0.6953, device='cuda:0'), 'train/logits_fake': tensor(-0.8901, device='cuda:0')}
2025-11-14 08:56:02,827 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:56:02,855 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:56:05,431 [INFO] rec_loss: 2.5002260208129883, rec_log: {'train/total_loss': tensor(2.5002, device='cuda:0'), 'train/logvar': tensor(0.0108, device='cuda:0'), 'train/kl_loss': tensor(168.4073, device='cuda:0'), 'train/nll_loss': tensor(2.2521, device='cuda:0'), 'train/rec_loss': tensor(0.1501, device='cuda:0'), 'train/perception_loss': tensor(0.7643, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7970, device='cuda:0')}
2025-11-14 08:56:18,578 [INFO] gan_loss : 0.7224684953689575,  gan_log: {'train/disc_loss': tensor(0.7225, device='cuda:0'), 'train/logits_real': tensor(0.9191, device='cuda:0'), 'train/logits_fake': tensor(-0.7970, device='cuda:0')}
2025-11-14 08:56:22,176 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:56:22,204 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:56:24,788 [INFO] rec_loss: 2.996511459350586, rec_log: {'train/total_loss': tensor(2.9965, device='cuda:0'), 'train/logvar': tensor(0.0109, device='cuda:0'), 'train/kl_loss': tensor(135.2886, device='cuda:0'), 'train/nll_loss': tensor(2.7988, device='cuda:0'), 'train/rec_loss': tensor(0.2042, device='cuda:0'), 'train/perception_loss': tensor(0.7764, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6238, device='cuda:0')}
2025-11-14 08:56:37,968 [INFO] gan_loss : 0.5225600004196167,  gan_log: {'train/disc_loss': tensor(0.5226, device='cuda:0'), 'train/logits_real': tensor(1.3875, device='cuda:0'), 'train/logits_fake': tensor(-0.6238, device='cuda:0')}
2025-11-14 08:56:41,374 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:56:41,403 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:56:44,018 [INFO] rec_loss: 3.136138677597046, rec_log: {'train/total_loss': tensor(3.1361, device='cuda:0'), 'train/logvar': tensor(0.0109, device='cuda:0'), 'train/kl_loss': tensor(117.2580, device='cuda:0'), 'train/nll_loss': tensor(2.8774, device='cuda:0'), 'train/rec_loss': tensor(0.2152, device='cuda:0'), 'train/perception_loss': tensor(0.7455, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.4148, device='cuda:0')}
2025-11-14 08:56:57,197 [INFO] gan_loss : 0.7123848795890808,  gan_log: {'train/disc_loss': tensor(0.7124, device='cuda:0'), 'train/logits_real': tensor(0.6556, device='cuda:0'), 'train/logits_fake': tensor(-1.4148, device='cuda:0')}
2025-11-14 08:57:00,347 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:57:00,376 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:57:02,975 [INFO] rec_loss: 3.096463680267334, rec_log: {'train/total_loss': tensor(3.0965, device='cuda:0'), 'train/logvar': tensor(0.0110, device='cuda:0'), 'train/kl_loss': tensor(100.5119, device='cuda:0'), 'train/nll_loss': tensor(2.8082, device='cuda:0'), 'train/rec_loss': tensor(0.2076, device='cuda:0'), 'train/perception_loss': tensor(0.7523, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.8772, device='cuda:0')}
2025-11-14 08:57:16,136 [INFO] gan_loss : 0.47505244612693787,  gan_log: {'train/disc_loss': tensor(0.4751, device='cuda:0'), 'train/logits_real': tensor(0.5346, device='cuda:0'), 'train/logits_fake': tensor(-1.8772, device='cuda:0')}
2025-11-14 08:57:19,644 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:57:19,667 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:57:22,263 [INFO] rec_loss: 3.0506865978240967, rec_log: {'train/total_loss': tensor(3.0507, device='cuda:0'), 'train/logvar': tensor(0.0111, device='cuda:0'), 'train/kl_loss': tensor(101.3702, device='cuda:0'), 'train/nll_loss': tensor(2.7838, device='cuda:0'), 'train/rec_loss': tensor(0.2044, device='cuda:0'), 'train/perception_loss': tensor(0.7597, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.6550, device='cuda:0')}
2025-11-14 08:57:35,408 [INFO] gan_loss : 0.35917818546295166,  gan_log: {'train/disc_loss': tensor(0.3592, device='cuda:0'), 'train/logits_real': tensor(1.1595, device='cuda:0'), 'train/logits_fake': tensor(-1.6550, device='cuda:0')}
2025-11-14 08:57:39,192 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:57:39,220 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:57:41,846 [INFO] rec_loss: 2.9510679244995117, rec_log: {'train/total_loss': tensor(2.9511, device='cuda:0'), 'train/logvar': tensor(0.0111, device='cuda:0'), 'train/kl_loss': tensor(95.7518, device='cuda:0'), 'train/nll_loss': tensor(2.7218, device='cuda:0'), 'train/rec_loss': tensor(0.1969, device='cuda:0'), 'train/perception_loss': tensor(0.7725, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3348, device='cuda:0')}
2025-11-14 08:57:55,041 [INFO] gan_loss : 0.3488503694534302,  gan_log: {'train/disc_loss': tensor(0.3489, device='cuda:0'), 'train/logits_real': tensor(1.3460, device='cuda:0'), 'train/logits_fake': tensor(-1.3348, device='cuda:0')}
2025-11-14 08:57:55,111 [INFO] ------------------------------------------- Epoch: [1]
2025-11-14 08:57:58,562 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:57:58,592 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:58:01,187 [INFO] rec_loss: 3.0342824459075928, rec_log: {'train/total_loss': tensor(3.0343, device='cuda:0'), 'train/logvar': tensor(0.0112, device='cuda:0'), 'train/kl_loss': tensor(77.2233, device='cuda:0'), 'train/nll_loss': tensor(2.8635, device='cuda:0'), 'train/rec_loss': tensor(0.2156, device='cuda:0'), 'train/perception_loss': tensor(0.7285, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.9352, device='cuda:0')}
2025-11-14 08:58:14,350 [INFO] gan_loss : 0.3526873290538788,  gan_log: {'train/disc_loss': tensor(0.3527, device='cuda:0'), 'train/logits_real': tensor(1.5406, device='cuda:0'), 'train/logits_fake': tensor(-0.9352, device='cuda:0')}
2025-11-14 08:58:17,922 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:58:17,951 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:58:20,583 [INFO] rec_loss: 3.3660364151000977, rec_log: {'train/total_loss': tensor(3.3660, device='cuda:0'), 'train/logvar': tensor(0.0113, device='cuda:0'), 'train/kl_loss': tensor(84.9147, device='cuda:0'), 'train/nll_loss': tensor(3.1262, device='cuda:0'), 'train/rec_loss': tensor(0.2402, device='cuda:0'), 'train/perception_loss': tensor(0.7485, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.5494, device='cuda:0')}
2025-11-14 08:58:33,769 [INFO] gan_loss : 0.3189030885696411,  gan_log: {'train/disc_loss': tensor(0.3189, device='cuda:0'), 'train/logits_real': tensor(1.1260, device='cuda:0'), 'train/logits_fake': tensor(-1.5494, device='cuda:0')}
2025-11-14 08:58:37,643 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:58:37,672 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:58:40,276 [INFO] rec_loss: 2.9129583835601807, rec_log: {'train/total_loss': tensor(2.9130, device='cuda:0'), 'train/logvar': tensor(0.0113, device='cuda:0'), 'train/kl_loss': tensor(67.4311, device='cuda:0'), 'train/nll_loss': tensor(2.6344, device='cuda:0'), 'train/rec_loss': tensor(0.1906, device='cuda:0'), 'train/perception_loss': tensor(0.7471, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.1109, device='cuda:0')}
2025-11-14 08:58:53,425 [INFO] gan_loss : 0.40129756927490234,  gan_log: {'train/disc_loss': tensor(0.4013, device='cuda:0'), 'train/logits_real': tensor(0.7665, device='cuda:0'), 'train/logits_fake': tensor(-2.1109, device='cuda:0')}
2025-11-14 08:58:57,201 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:58:57,224 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:58:59,789 [INFO] rec_loss: 2.968230962753296, rec_log: {'train/total_loss': tensor(2.9682, device='cuda:0'), 'train/logvar': tensor(0.0114, device='cuda:0'), 'train/kl_loss': tensor(72.6777, device='cuda:0'), 'train/nll_loss': tensor(2.6872, device='cuda:0'), 'train/rec_loss': tensor(0.1960, device='cuda:0'), 'train/perception_loss': tensor(0.7464, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.0837, device='cuda:0')}
2025-11-14 08:59:12,955 [INFO] gan_loss : 0.26872390508651733,  gan_log: {'train/disc_loss': tensor(0.2687, device='cuda:0'), 'train/logits_real': tensor(1.3296, device='cuda:0'), 'train/logits_fake': tensor(-2.0837, device='cuda:0')}
2025-11-14 08:59:16,480 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:59:16,509 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:59:19,073 [INFO] rec_loss: 3.1025540828704834, rec_log: {'train/total_loss': tensor(3.1026, device='cuda:0'), 'train/logvar': tensor(0.0115, device='cuda:0'), 'train/kl_loss': tensor(83.8358, device='cuda:0'), 'train/nll_loss': tensor(2.9203, device='cuda:0'), 'train/rec_loss': tensor(0.2223, device='cuda:0'), 'train/perception_loss': tensor(0.7195, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.9838, device='cuda:0')}
2025-11-14 08:59:32,211 [INFO] gan_loss : 0.35425108671188354,  gan_log: {'train/disc_loss': tensor(0.3543, device='cuda:0'), 'train/logits_real': tensor(1.9238, device='cuda:0'), 'train/logits_fake': tensor(-0.9838, device='cuda:0')}
2025-11-14 08:59:35,610 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:59:35,633 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:59:38,231 [INFO] rec_loss: 2.834721565246582, rec_log: {'train/total_loss': tensor(2.8347, device='cuda:0'), 'train/logvar': tensor(0.0115, device='cuda:0'), 'train/kl_loss': tensor(83.7545, device='cuda:0'), 'train/nll_loss': tensor(2.6454, device='cuda:0'), 'train/rec_loss': tensor(0.1927, device='cuda:0'), 'train/perception_loss': tensor(0.7376, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.0555, device='cuda:0')}
2025-11-14 08:59:51,407 [INFO] gan_loss : 0.24174904823303223,  gan_log: {'train/disc_loss': tensor(0.2417, device='cuda:0'), 'train/logits_real': tensor(2.1431, device='cuda:0'), 'train/logits_fake': tensor(-1.0555, device='cuda:0')}
2025-11-14 08:59:55,355 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 08:59:55,378 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 08:59:57,994 [INFO] rec_loss: 3.0642147064208984, rec_log: {'train/total_loss': tensor(3.0642, device='cuda:0'), 'train/logvar': tensor(0.0116, device='cuda:0'), 'train/kl_loss': tensor(92.6833, device='cuda:0'), 'train/nll_loss': tensor(2.7965, device='cuda:0'), 'train/rec_loss': tensor(0.2072, device='cuda:0'), 'train/perception_loss': tensor(0.7454, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.7508, device='cuda:0')}
2025-11-14 09:00:11,177 [INFO] gan_loss : 0.2712864875793457,  gan_log: {'train/disc_loss': tensor(0.2713, device='cuda:0'), 'train/logits_real': tensor(1.9208, device='cuda:0'), 'train/logits_fake': tensor(-1.7508, device='cuda:0')}
2025-11-14 09:00:14,842 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:00:14,865 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:00:17,495 [INFO] rec_loss: 2.832585096359253, rec_log: {'train/total_loss': tensor(2.8326, device='cuda:0'), 'train/logvar': tensor(0.0117, device='cuda:0'), 'train/kl_loss': tensor(96.0834, device='cuda:0'), 'train/nll_loss': tensor(2.4965, device='cuda:0'), 'train/rec_loss': tensor(0.1752, device='cuda:0'), 'train/perception_loss': tensor(0.7624, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.4004, device='cuda:0')}
2025-11-14 09:00:30,653 [INFO] gan_loss : 0.221811443567276,  gan_log: {'train/disc_loss': tensor(0.2218, device='cuda:0'), 'train/logits_real': tensor(1.3836, device='cuda:0'), 'train/logits_fake': tensor(-2.4004, device='cuda:0')}
2025-11-14 09:00:34,234 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:00:34,257 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:00:36,844 [INFO] rec_loss: 3.1497762203216553, rec_log: {'train/total_loss': tensor(3.1498, device='cuda:0'), 'train/logvar': tensor(0.0117, device='cuda:0'), 'train/kl_loss': tensor(124.2453, device='cuda:0'), 'train/nll_loss': tensor(2.8068, device='cuda:0'), 'train/rec_loss': tensor(0.2089, device='cuda:0'), 'train/perception_loss': tensor(0.7393, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.1872, device='cuda:0')}
2025-11-14 09:00:49,999 [INFO] gan_loss : 0.3146320879459381,  gan_log: {'train/disc_loss': tensor(0.3146, device='cuda:0'), 'train/logits_real': tensor(1.5962, device='cuda:0'), 'train/logits_fake': tensor(-2.1872, device='cuda:0')}
2025-11-14 09:00:53,669 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:00:53,697 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:00:56,305 [INFO] rec_loss: 2.7501776218414307, rec_log: {'train/total_loss': tensor(2.7502, device='cuda:0'), 'train/logvar': tensor(0.0118, device='cuda:0'), 'train/kl_loss': tensor(89.3813, device='cuda:0'), 'train/nll_loss': tensor(2.5388, device='cuda:0'), 'train/rec_loss': tensor(0.1793, device='cuda:0'), 'train/perception_loss': tensor(0.7644, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.2200, device='cuda:0')}
2025-11-14 09:01:09,454 [INFO] gan_loss : 0.1951385885477066,  gan_log: {'train/disc_loss': tensor(0.1951, device='cuda:0'), 'train/logits_real': tensor(2.6064, device='cuda:0'), 'train/logits_fake': tensor(-1.2200, device='cuda:0')}
2025-11-14 09:01:13,079 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:01:13,110 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:01:15,684 [INFO] rec_loss: 2.7394790649414062, rec_log: {'train/total_loss': tensor(2.7395, device='cuda:0'), 'train/logvar': tensor(0.0118, device='cuda:0'), 'train/kl_loss': tensor(99.0715, device='cuda:0'), 'train/nll_loss': tensor(2.4897, device='cuda:0'), 'train/rec_loss': tensor(0.1769, device='cuda:0'), 'train/perception_loss': tensor(0.7387, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.5074, device='cuda:0')}
2025-11-14 09:01:28,853 [INFO] gan_loss : 0.35036319494247437,  gan_log: {'train/disc_loss': tensor(0.3504, device='cuda:0'), 'train/logits_real': tensor(2.1188, device='cuda:0'), 'train/logits_fake': tensor(-1.5074, device='cuda:0')}
2025-11-14 09:01:32,433 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:01:32,461 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:01:35,067 [INFO] rec_loss: 2.6998379230499268, rec_log: {'train/total_loss': tensor(2.6998, device='cuda:0'), 'train/logvar': tensor(0.0119, device='cuda:0'), 'train/kl_loss': tensor(91.5210, device='cuda:0'), 'train/nll_loss': tensor(2.4687, device='cuda:0'), 'train/rec_loss': tensor(0.1750, device='cuda:0'), 'train/perception_loss': tensor(0.7365, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3958, device='cuda:0')}
2025-11-14 09:01:48,251 [INFO] gan_loss : 0.21481941640377045,  gan_log: {'train/disc_loss': tensor(0.2148, device='cuda:0'), 'train/logits_real': tensor(2.5042, device='cuda:0'), 'train/logits_fake': tensor(-1.3958, device='cuda:0')}
2025-11-14 09:01:52,007 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:01:52,035 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:01:54,635 [INFO] rec_loss: 3.550180435180664, rec_log: {'train/total_loss': tensor(3.5502, device='cuda:0'), 'train/logvar': tensor(0.0120, device='cuda:0'), 'train/kl_loss': tensor(110.2309, device='cuda:0'), 'train/nll_loss': tensor(3.2323, device='cuda:0'), 'train/rec_loss': tensor(0.2493, device='cuda:0'), 'train/perception_loss': tensor(0.7663, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.0761, device='cuda:0')}
2025-11-14 09:02:07,811 [INFO] gan_loss : 0.3865223526954651,  gan_log: {'train/disc_loss': tensor(0.3865, device='cuda:0'), 'train/logits_real': tensor(1.3437, device='cuda:0'), 'train/logits_fake': tensor(-2.0761, device='cuda:0')}
2025-11-14 09:02:11,045 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:02:11,074 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:02:13,653 [INFO] rec_loss: 3.3954787254333496, rec_log: {'train/total_loss': tensor(3.3955, device='cuda:0'), 'train/logvar': tensor(0.0120, device='cuda:0'), 'train/kl_loss': tensor(111.6166, device='cuda:0'), 'train/nll_loss': tensor(2.9683, device='cuda:0'), 'train/rec_loss': tensor(0.2228, device='cuda:0'), 'train/perception_loss': tensor(0.7641, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.1560, device='cuda:0')}
2025-11-14 09:02:26,827 [INFO] gan_loss : 0.3139045536518097,  gan_log: {'train/disc_loss': tensor(0.3139, device='cuda:0'), 'train/logits_real': tensor(1.1332, device='cuda:0'), 'train/logits_fake': tensor(-3.1560, device='cuda:0')}
2025-11-14 09:02:30,528 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:02:30,557 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:02:33,163 [INFO] rec_loss: 3.331284523010254, rec_log: {'train/total_loss': tensor(3.3313, device='cuda:0'), 'train/logvar': tensor(0.0121, device='cuda:0'), 'train/kl_loss': tensor(81.5669, device='cuda:0'), 'train/nll_loss': tensor(2.9916, device='cuda:0'), 'train/rec_loss': tensor(0.2266, device='cuda:0'), 'train/perception_loss': tensor(0.7501, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.5812, device='cuda:0')}
2025-11-14 09:02:46,349 [INFO] gan_loss : 0.2707519829273224,  gan_log: {'train/disc_loss': tensor(0.2708, device='cuda:0'), 'train/logits_real': tensor(1.5091, device='cuda:0'), 'train/logits_fake': tensor(-2.5812, device='cuda:0')}
2025-11-14 09:02:50,457 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:02:50,486 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:02:53,101 [INFO] rec_loss: 2.77851939201355, rec_log: {'train/total_loss': tensor(2.7785, device='cuda:0'), 'train/logvar': tensor(0.0122, device='cuda:0'), 'train/kl_loss': tensor(80.7578, device='cuda:0'), 'train/nll_loss': tensor(2.6136, device='cuda:0'), 'train/rec_loss': tensor(0.1847, device='cuda:0'), 'train/perception_loss': tensor(0.7863, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8414, device='cuda:0')}
2025-11-14 09:03:06,287 [INFO] gan_loss : 0.28416183590888977,  gan_log: {'train/disc_loss': tensor(0.2842, device='cuda:0'), 'train/logits_real': tensor(3.0865, device='cuda:0'), 'train/logits_fake': tensor(-0.8414, device='cuda:0')}
2025-11-14 09:03:08,470 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:03:08,499 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:03:11,093 [INFO] rec_loss: 3.0867528915405273, rec_log: {'train/total_loss': tensor(3.0868, device='cuda:0'), 'train/logvar': tensor(0.0122, device='cuda:0'), 'train/kl_loss': tensor(99.7205, device='cuda:0'), 'train/nll_loss': tensor(2.8891, device='cuda:0'), 'train/rec_loss': tensor(0.2148, device='cuda:0'), 'train/perception_loss': tensor(0.7642, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.9792, device='cuda:0')}
2025-11-14 09:03:24,280 [INFO] gan_loss : 0.3352644741535187,  gan_log: {'train/disc_loss': tensor(0.3353, device='cuda:0'), 'train/logits_real': tensor(3.0677, device='cuda:0'), 'train/logits_fake': tensor(-0.9792, device='cuda:0')}
2025-11-14 09:03:27,773 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:03:27,801 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:03:30,372 [INFO] rec_loss: 3.110255002975464, rec_log: {'train/total_loss': tensor(3.1103, device='cuda:0'), 'train/logvar': tensor(0.0123, device='cuda:0'), 'train/kl_loss': tensor(100.9946, device='cuda:0'), 'train/nll_loss': tensor(2.6968, device='cuda:0'), 'train/rec_loss': tensor(0.1956, device='cuda:0'), 'train/perception_loss': tensor(0.7621, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.1244, device='cuda:0')}
2025-11-14 09:03:43,555 [INFO] gan_loss : 0.2093282788991928,  gan_log: {'train/disc_loss': tensor(0.2093, device='cuda:0'), 'train/logits_real': tensor(1.7506, device='cuda:0'), 'train/logits_fake': tensor(-3.1244, device='cuda:0')}
2025-11-14 09:03:45,590 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:03:45,618 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:03:48,243 [INFO] rec_loss: 2.9919052124023438, rec_log: {'train/total_loss': tensor(2.9919, device='cuda:0'), 'train/logvar': tensor(0.0124, device='cuda:0'), 'train/kl_loss': tensor(101.5674, device='cuda:0'), 'train/nll_loss': tensor(2.5397, device='cuda:0'), 'train/rec_loss': tensor(0.1821, device='cuda:0'), 'train/perception_loss': tensor(0.7378, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.5067, device='cuda:0')}
2025-11-14 09:04:01,423 [INFO] gan_loss : 0.2071254998445511,  gan_log: {'train/disc_loss': tensor(0.2071, device='cuda:0'), 'train/logits_real': tensor(1.5529, device='cuda:0'), 'train/logits_fake': tensor(-3.5067, device='cuda:0')}
2025-11-14 09:04:04,671 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:04:04,699 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:04:07,308 [INFO] rec_loss: 3.141073703765869, rec_log: {'train/total_loss': tensor(3.1411, device='cuda:0'), 'train/logvar': tensor(0.0124, device='cuda:0'), 'train/kl_loss': tensor(114.5829, device='cuda:0'), 'train/nll_loss': tensor(2.8134, device='cuda:0'), 'train/rec_loss': tensor(0.2053, device='cuda:0'), 'train/perception_loss': tensor(0.7834, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.1311, device='cuda:0')}
2025-11-14 09:04:20,490 [INFO] gan_loss : 0.26713883876800537,  gan_log: {'train/disc_loss': tensor(0.2671, device='cuda:0'), 'train/logits_real': tensor(2.5147, device='cuda:0'), 'train/logits_fake': tensor(-2.1311, device='cuda:0')}
2025-11-14 09:04:23,712 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:04:23,740 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:04:26,367 [INFO] rec_loss: 3.6649019718170166, rec_log: {'train/total_loss': tensor(3.6649, device='cuda:0'), 'train/logvar': tensor(0.0125, device='cuda:0'), 'train/kl_loss': tensor(113.4516, device='cuda:0'), 'train/nll_loss': tensor(3.3259, device='cuda:0'), 'train/rec_loss': tensor(0.2575, device='cuda:0'), 'train/perception_loss': tensor(0.7796, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.2556, device='cuda:0')}
2025-11-14 09:04:39,552 [INFO] gan_loss : 0.22806832194328308,  gan_log: {'train/disc_loss': tensor(0.2281, device='cuda:0'), 'train/logits_real': tensor(3.1258, device='cuda:0'), 'train/logits_fake': tensor(-2.2556, device='cuda:0')}
2025-11-14 09:04:43,179 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:04:43,202 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:04:45,790 [INFO] rec_loss: 3.109186887741089, rec_log: {'train/total_loss': tensor(3.1092, device='cuda:0'), 'train/logvar': tensor(0.0126, device='cuda:0'), 'train/kl_loss': tensor(85.6441, device='cuda:0'), 'train/nll_loss': tensor(2.8417, device='cuda:0'), 'train/rec_loss': tensor(0.2116, device='cuda:0'), 'train/perception_loss': tensor(0.7486, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.8186, device='cuda:0')}
2025-11-14 09:04:58,983 [INFO] gan_loss : 0.3979029655456543,  gan_log: {'train/disc_loss': tensor(0.3979, device='cuda:0'), 'train/logits_real': tensor(2.5435, device='cuda:0'), 'train/logits_fake': tensor(-1.8186, device='cuda:0')}
2025-11-14 09:05:02,792 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:05:02,823 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:05:05,447 [INFO] rec_loss: 4.202630519866943, rec_log: {'train/total_loss': tensor(4.2026, device='cuda:0'), 'train/logvar': tensor(0.0126, device='cuda:0'), 'train/kl_loss': tensor(100.5353, device='cuda:0'), 'train/nll_loss': tensor(3.7408, device='cuda:0'), 'train/rec_loss': tensor(0.2916, device='cuda:0'), 'train/perception_loss': tensor(0.8596, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.6131, device='cuda:0')}
2025-11-14 09:05:18,627 [INFO] gan_loss : 0.264602929353714,  gan_log: {'train/disc_loss': tensor(0.2646, device='cuda:0'), 'train/logits_real': tensor(2.2625, device='cuda:0'), 'train/logits_fake': tensor(-3.6131, device='cuda:0')}
2025-11-14 09:05:22,315 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:05:22,345 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:05:24,966 [INFO] rec_loss: 3.2972371578216553, rec_log: {'train/total_loss': tensor(3.2972, device='cuda:0'), 'train/logvar': tensor(0.0127, device='cuda:0'), 'train/kl_loss': tensor(89.5672, device='cuda:0'), 'train/nll_loss': tensor(2.8574, device='cuda:0'), 'train/rec_loss': tensor(0.2095, device='cuda:0'), 'train/perception_loss': tensor(0.7861, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.5031, device='cuda:0')}
2025-11-14 09:05:38,137 [INFO] gan_loss : 0.5861133933067322,  gan_log: {'train/disc_loss': tensor(0.5861, device='cuda:0'), 'train/logits_real': tensor(0.7892, device='cuda:0'), 'train/logits_fake': tensor(-3.5031, device='cuda:0')}
2025-11-14 09:05:41,811 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:05:41,839 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:05:44,472 [INFO] rec_loss: 3.192216396331787, rec_log: {'train/total_loss': tensor(3.1922, device='cuda:0'), 'train/logvar': tensor(0.0128, device='cuda:0'), 'train/kl_loss': tensor(109.5894, device='cuda:0'), 'train/nll_loss': tensor(2.9212, device='cuda:0'), 'train/rec_loss': tensor(0.2139, device='cuda:0'), 'train/perception_loss': tensor(0.8069, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.6146, device='cuda:0')}
2025-11-14 09:05:57,659 [INFO] gan_loss : 0.39505088329315186,  gan_log: {'train/disc_loss': tensor(0.3951, device='cuda:0'), 'train/logits_real': tensor(2.6145, device='cuda:0'), 'train/logits_fake': tensor(-1.6146, device='cuda:0')}
2025-11-14 09:06:00,645 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:06:00,668 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:06:03,298 [INFO] rec_loss: 4.202444076538086, rec_log: {'train/total_loss': tensor(4.2024, device='cuda:0'), 'train/logvar': tensor(0.0128, device='cuda:0'), 'train/kl_loss': tensor(81.7758, device='cuda:0'), 'train/nll_loss': tensor(4.0649, device='cuda:0'), 'train/rec_loss': tensor(0.3330, device='cuda:0'), 'train/perception_loss': tensor(0.7744, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5576, device='cuda:0')}
2025-11-14 09:06:16,482 [INFO] gan_loss : 0.7549601793289185,  gan_log: {'train/disc_loss': tensor(0.7550, device='cuda:0'), 'train/logits_real': tensor(2.2761, device='cuda:0'), 'train/logits_fake': tensor(-0.5576, device='cuda:0')}
2025-11-14 09:06:20,039 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:06:20,068 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:06:22,678 [INFO] rec_loss: 3.4009628295898438, rec_log: {'train/total_loss': tensor(3.4010, device='cuda:0'), 'train/logvar': tensor(0.0129, device='cuda:0'), 'train/kl_loss': tensor(88.2934, device='cuda:0'), 'train/nll_loss': tensor(3.1168, device='cuda:0'), 'train/rec_loss': tensor(0.2392, device='cuda:0'), 'train/perception_loss': tensor(0.7524, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.9591, device='cuda:0')}
2025-11-14 09:06:35,860 [INFO] gan_loss : 0.45365116000175476,  gan_log: {'train/disc_loss': tensor(0.4537, device='cuda:0'), 'train/logits_real': tensor(3.4800, device='cuda:0'), 'train/logits_fake': tensor(-1.9591, device='cuda:0')}
2025-11-14 09:06:39,392 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:06:39,426 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:06:42,036 [INFO] rec_loss: 3.5847671031951904, rec_log: {'train/total_loss': tensor(3.5848, device='cuda:0'), 'train/logvar': tensor(0.0130, device='cuda:0'), 'train/kl_loss': tensor(73.1121, device='cuda:0'), 'train/nll_loss': tensor(3.2019, device='cuda:0'), 'train/rec_loss': tensor(0.2501, device='cuda:0'), 'train/perception_loss': tensor(0.7300, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.0975, device='cuda:0')}
2025-11-14 09:06:55,227 [INFO] gan_loss : 0.44842755794525146,  gan_log: {'train/disc_loss': tensor(0.4484, device='cuda:0'), 'train/logits_real': tensor(1.1978, device='cuda:0'), 'train/logits_fake': tensor(-3.0975, device='cuda:0')}
2025-11-14 09:06:59,237 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:06:59,266 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:07:01,870 [INFO] rec_loss: 3.4714913368225098, rec_log: {'train/total_loss': tensor(3.4715, device='cuda:0'), 'train/logvar': tensor(0.0131, device='cuda:0'), 'train/kl_loss': tensor(90.7281, device='cuda:0'), 'train/nll_loss': tensor(3.0688, device='cuda:0'), 'train/rec_loss': tensor(0.2324, device='cuda:0'), 'train/perception_loss': tensor(0.7718, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.1194, device='cuda:0')}
2025-11-14 09:07:15,049 [INFO] gan_loss : 0.3991870880126953,  gan_log: {'train/disc_loss': tensor(0.3992, device='cuda:0'), 'train/logits_real': tensor(1.4249, device='cuda:0'), 'train/logits_fake': tensor(-3.1194, device='cuda:0')}
2025-11-14 09:07:18,392 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:07:18,420 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:07:21,033 [INFO] rec_loss: 3.1275832653045654, rec_log: {'train/total_loss': tensor(3.1276, device='cuda:0'), 'train/logvar': tensor(0.0131, device='cuda:0'), 'train/kl_loss': tensor(98.8033, device='cuda:0'), 'train/nll_loss': tensor(2.8757, device='cuda:0'), 'train/rec_loss': tensor(0.2167, device='cuda:0'), 'train/perception_loss': tensor(0.7335, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.5309, device='cuda:0')}
2025-11-14 09:07:34,190 [INFO] gan_loss : 0.25768762826919556,  gan_log: {'train/disc_loss': tensor(0.2577, device='cuda:0'), 'train/logits_real': tensor(3.1448, device='cuda:0'), 'train/logits_fake': tensor(-1.5309, device='cuda:0')}
2025-11-14 09:07:37,903 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:07:37,932 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
2025-11-14 09:07:40,549 [INFO] rec_loss: 2.78891921043396, rec_log: {'train/total_loss': tensor(2.7889, device='cuda:0'), 'train/logvar': tensor(0.0132, device='cuda:0'), 'train/kl_loss': tensor(114.3856, device='cuda:0'), 'train/nll_loss': tensor(2.5377, device='cuda:0'), 'train/rec_loss': tensor(0.1834, device='cuda:0'), 'train/perception_loss': tensor(0.7236, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3680, device='cuda:0')}
2025-11-14 09:07:53,695 [INFO] gan_loss : 0.4389868676662445,  gan_log: {'train/disc_loss': tensor(0.4390, device='cuda:0'), 'train/logits_real': tensor(3.2220, device='cuda:0'), 'train/logits_fake': tensor(-1.3680, device='cuda:0')}
2025-11-14 09:07:56,820 [INFO] ----------------------------------------------------------- Iteration
2025-11-14 09:07:56,848 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([8, 3, 16, 256, 256])
