2025-11-15 13:39:20,318 [INFO] Starting new training run...
2025-11-15 13:39:27,538 [INFO] ------------------------------------------- Epoch: [0]
2025-11-15 13:39:33,427 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:39:33,469 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:39:36,150 [INFO] rec_loss: 18.23000144958496, rec_log: {'train/total_loss': tensor(18.2300, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(63.3144, device='cuda:0'), 'train/nll_loss': tensor(17.5007, device='cuda:0'), 'train/rec_loss': tensor(1.6602, device='cuda:0'), 'train/perception_loss': tensor(0.8990, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.9615, device='cuda:0')}
2025-11-15 13:39:40,401 [INFO] gan_loss : 1.5434436798095703,  gan_log: {'train/disc_loss': tensor(1.5434, device='cuda:0'), 'train/logits_real': tensor(-1.0586, device='cuda:0'), 'train/logits_fake': tensor(-0.9615, device='cuda:0')}
2025-11-15 13:39:40,445 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:39:40,469 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:39:42,095 [INFO] rec_loss: 40.84404754638672, rec_log: {'train/total_loss': tensor(40.8440, device='cuda:0'), 'train/logvar': tensor(1.0000e-04, device='cuda:0'), 'train/kl_loss': tensor(1334.8442, device='cuda:0'), 'train/nll_loss': tensor(29.7639, device='cuda:0'), 'train/rec_loss': tensor(2.8937, device='cuda:0'), 'train/perception_loss': tensor(0.8294, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-22.6826, device='cuda:0')}
2025-11-15 13:39:46,046 [INFO] gan_loss : 11.842507362365723,  gan_log: {'train/disc_loss': tensor(11.8425, device='cuda:0'), 'train/logits_real': tensor(20.4792, device='cuda:0'), 'train/logits_fake': tensor(22.6826, device='cuda:0')}
2025-11-15 13:39:46,089 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:39:46,114 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:39:47,745 [INFO] rec_loss: 27.66413688659668, rec_log: {'train/total_loss': tensor(27.6641, device='cuda:0'), 'train/logvar': tensor(0.0002, device='cuda:0'), 'train/kl_loss': tensor(1207.6035, device='cuda:0'), 'train/nll_loss': tensor(15.1573, device='cuda:0'), 'train/rec_loss': tensor(1.4329, device='cuda:0'), 'train/perception_loss': tensor(0.8312, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(4.3080, device='cuda:0')}
2025-11-15 13:39:51,701 [INFO] gan_loss : 1.9878225326538086,  gan_log: {'train/disc_loss': tensor(1.9878, device='cuda:0'), 'train/logits_real': tensor(10.6144, device='cuda:0'), 'train/logits_fake': tensor(-4.3080, device='cuda:0')}
2025-11-15 13:39:51,742 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:39:51,768 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:39:53,409 [INFO] rec_loss: 26.0742244720459, rec_log: {'train/total_loss': tensor(26.0742, device='cuda:0'), 'train/logvar': tensor(0.0003, device='cuda:0'), 'train/kl_loss': tensor(267.4131, device='cuda:0'), 'train/nll_loss': tensor(24.4905, device='cuda:0'), 'train/rec_loss': tensor(2.3680, device='cuda:0'), 'train/perception_loss': tensor(0.8173, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-10.9038, device='cuda:0')}
2025-11-15 13:39:57,362 [INFO] gan_loss : 9.045228958129883,  gan_log: {'train/disc_loss': tensor(9.0452, device='cuda:0'), 'train/logits_real': tensor(8.3723, device='cuda:0'), 'train/logits_fake': tensor(10.9038, device='cuda:0')}
2025-11-15 13:39:57,406 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:39:57,430 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:39:59,055 [INFO] rec_loss: 16.81507682800293, rec_log: {'train/total_loss': tensor(16.8151, device='cuda:0'), 'train/logvar': tensor(0.0004, device='cuda:0'), 'train/kl_loss': tensor(67.4129, device='cuda:0'), 'train/nll_loss': tensor(18.4682, device='cuda:0'), 'train/rec_loss': tensor(1.7631, device='cuda:0'), 'train/perception_loss': tensor(0.8444, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-23.2726, device='cuda:0')}
2025-11-15 13:40:03,013 [INFO] gan_loss : 12.960614204406738,  gan_log: {'train/disc_loss': tensor(12.9606, device='cuda:0'), 'train/logits_real': tensor(7.3820, device='cuda:0'), 'train/logits_fake': tensor(23.2726, device='cuda:0')}
2025-11-15 13:40:03,054 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:03,076 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:04,701 [INFO] rec_loss: 25.83844566345215, rec_log: {'train/total_loss': tensor(25.8384, device='cuda:0'), 'train/logvar': tensor(0.0005, device='cuda:0'), 'train/kl_loss': tensor(72.0819, device='cuda:0'), 'train/nll_loss': tensor(26.4805, device='cuda:0'), 'train/rec_loss': tensor(2.5688, device='cuda:0'), 'train/perception_loss': tensor(0.8053, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-13.6285, device='cuda:0')}
2025-11-15 13:40:08,654 [INFO] gan_loss : 7.536289691925049,  gan_log: {'train/disc_loss': tensor(7.5363, device='cuda:0'), 'train/logits_real': tensor(8.2594, device='cuda:0'), 'train/logits_fake': tensor(13.6285, device='cuda:0')}
2025-11-15 13:40:08,696 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:08,722 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:10,351 [INFO] rec_loss: 19.77241325378418, rec_log: {'train/total_loss': tensor(19.7724, device='cuda:0'), 'train/logvar': tensor(0.0006, device='cuda:0'), 'train/kl_loss': tensor(95.7752, device='cuda:0'), 'train/nll_loss': tensor(19.3665, device='cuda:0'), 'train/rec_loss': tensor(1.8597, device='cuda:0'), 'train/perception_loss': tensor(0.7802, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-5.5189, device='cuda:0')}
2025-11-15 13:40:14,313 [INFO] gan_loss : 3.611098289489746,  gan_log: {'train/disc_loss': tensor(3.6111, device='cuda:0'), 'train/logits_real': tensor(4.9168, device='cuda:0'), 'train/logits_fake': tensor(5.5189, device='cuda:0')}
2025-11-15 13:40:14,354 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:14,376 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:16,007 [INFO] rec_loss: 15.01926040649414, rec_log: {'train/total_loss': tensor(15.0193, device='cuda:0'), 'train/logvar': tensor(0.0007, device='cuda:0'), 'train/kl_loss': tensor(129.5984, device='cuda:0'), 'train/nll_loss': tensor(13.6704, device='cuda:0'), 'train/rec_loss': tensor(1.2901, device='cuda:0'), 'train/perception_loss': tensor(0.7785, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5291, device='cuda:0')}
2025-11-15 13:40:19,967 [INFO] gan_loss : 2.0204248428344727,  gan_log: {'train/disc_loss': tensor(2.0204, device='cuda:0'), 'train/logits_real': tensor(-0.1888, device='cuda:0'), 'train/logits_fake': tensor(-0.5291, device='cuda:0')}
2025-11-15 13:40:20,009 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:20,031 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:21,666 [INFO] rec_loss: 26.24733543395996, rec_log: {'train/total_loss': tensor(26.2473, device='cuda:0'), 'train/logvar': tensor(0.0008, device='cuda:0'), 'train/kl_loss': tensor(51.6980, device='cuda:0'), 'train/nll_loss': tensor(25.7569, device='cuda:0'), 'train/rec_loss': tensor(2.4993, device='cuda:0'), 'train/perception_loss': tensor(0.7828, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.2654, device='cuda:0')}
2025-11-15 13:40:25,633 [INFO] gan_loss : 3.427917957305908,  gan_log: {'train/disc_loss': tensor(3.4279, device='cuda:0'), 'train/logits_real': tensor(-4.2275, device='cuda:0'), 'train/logits_fake': tensor(0.2654, device='cuda:0')}
2025-11-15 13:40:25,675 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:25,696 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:27,330 [INFO] rec_loss: 17.052873611450195, rec_log: {'train/total_loss': tensor(17.0529, device='cuda:0'), 'train/logvar': tensor(0.0009, device='cuda:0'), 'train/kl_loss': tensor(89.7081, device='cuda:0'), 'train/nll_loss': tensor(16.0596, device='cuda:0'), 'train/rec_loss': tensor(1.5253, device='cuda:0'), 'train/perception_loss': tensor(0.8194, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.9617, device='cuda:0')}
2025-11-15 13:40:31,289 [INFO] gan_loss : 3.6187257766723633,  gan_log: {'train/disc_loss': tensor(3.6187, device='cuda:0'), 'train/logits_real': tensor(-5.1610, device='cuda:0'), 'train/logits_fake': tensor(-0.9617, device='cuda:0')}
2025-11-15 13:40:31,331 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:31,355 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:32,993 [INFO] rec_loss: 27.236228942871094, rec_log: {'train/total_loss': tensor(27.2362, device='cuda:0'), 'train/logvar': tensor(0.0010, device='cuda:0'), 'train/kl_loss': tensor(86.6365, device='cuda:0'), 'train/nll_loss': tensor(26.0987, device='cuda:0'), 'train/rec_loss': tensor(2.5316, device='cuda:0'), 'train/perception_loss': tensor(0.8067, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.7113, device='cuda:0')}
2025-11-15 13:40:36,961 [INFO] gan_loss : 3.263465404510498,  gan_log: {'train/disc_loss': tensor(3.2635, device='cuda:0'), 'train/logits_real': tensor(-5.4615, device='cuda:0'), 'train/logits_fake': tensor(-2.7113, device='cuda:0')}
2025-11-15 13:40:37,003 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:37,025 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:38,664 [INFO] rec_loss: 18.976282119750977, rec_log: {'train/total_loss': tensor(18.9763, device='cuda:0'), 'train/logvar': tensor(0.0011, device='cuda:0'), 'train/kl_loss': tensor(50.9419, device='cuda:0'), 'train/nll_loss': tensor(18.1959, device='cuda:0'), 'train/rec_loss': tensor(1.7409, device='cuda:0'), 'train/perception_loss': tensor(0.8057, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.7091, device='cuda:0')}
2025-11-15 13:40:42,624 [INFO] gan_loss : 2.3314385414123535,  gan_log: {'train/disc_loss': tensor(2.3314, device='cuda:0'), 'train/logits_real': tensor(-3.4614, device='cuda:0'), 'train/logits_fake': tensor(-2.7091, device='cuda:0')}
2025-11-15 13:40:42,667 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:42,690 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:44,328 [INFO] rec_loss: 14.126961708068848, rec_log: {'train/total_loss': tensor(14.1270, device='cuda:0'), 'train/logvar': tensor(0.0012, device='cuda:0'), 'train/kl_loss': tensor(36.1008, device='cuda:0'), 'train/nll_loss': tensor(13.6471, device='cuda:0'), 'train/rec_loss': tensor(1.2872, device='cuda:0'), 'train/perception_loss': tensor(0.7896, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.1886, device='cuda:0')}
2025-11-15 13:40:48,294 [INFO] gan_loss : 1.731642723083496,  gan_log: {'train/disc_loss': tensor(1.7316, device='cuda:0'), 'train/logits_real': tensor(-1.2756, device='cuda:0'), 'train/logits_fake': tensor(-1.1886, device='cuda:0')}
2025-11-15 13:40:48,335 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:48,360 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:49,996 [INFO] rec_loss: 17.487226486206055, rec_log: {'train/total_loss': tensor(17.4872, device='cuda:0'), 'train/logvar': tensor(0.0013, device='cuda:0'), 'train/kl_loss': tensor(30.4427, device='cuda:0'), 'train/nll_loss': tensor(17.3662, device='cuda:0'), 'train/rec_loss': tensor(1.6558, device='cuda:0'), 'train/perception_loss': tensor(0.8286, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-1.8338, device='cuda:0')}
2025-11-15 13:40:53,962 [INFO] gan_loss : 1.7855738401412964,  gan_log: {'train/disc_loss': tensor(1.7856, device='cuda:0'), 'train/logits_real': tensor(2.0240, device='cuda:0'), 'train/logits_fake': tensor(1.8338, device='cuda:0')}
2025-11-15 13:40:54,005 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:54,031 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:40:55,668 [INFO] rec_loss: 15.073139190673828, rec_log: {'train/total_loss': tensor(15.0731, device='cuda:0'), 'train/logvar': tensor(0.0013, device='cuda:0'), 'train/kl_loss': tensor(17.0553, device='cuda:0'), 'train/nll_loss': tensor(15.1726, device='cuda:0'), 'train/rec_loss': tensor(1.4368, device='cuda:0'), 'train/perception_loss': tensor(0.8240, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-2.7005, device='cuda:0')}
2025-11-15 13:40:59,645 [INFO] gan_loss : 2.040713310241699,  gan_log: {'train/disc_loss': tensor(2.0407, device='cuda:0'), 'train/logits_real': tensor(2.9056, device='cuda:0'), 'train/logits_fake': tensor(2.7005, device='cuda:0')}
2025-11-15 13:40:59,688 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:40:59,710 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:01,341 [INFO] rec_loss: 16.25719451904297, rec_log: {'train/total_loss': tensor(16.2572, device='cuda:0'), 'train/logvar': tensor(0.0014, device='cuda:0'), 'train/kl_loss': tensor(22.5718, device='cuda:0'), 'train/nll_loss': tensor(16.1969, device='cuda:0'), 'train/rec_loss': tensor(1.5405, device='cuda:0'), 'train/perception_loss': tensor(0.8135, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-1.6541, device='cuda:0')}
2025-11-15 13:41:05,308 [INFO] gan_loss : 1.589257001876831,  gan_log: {'train/disc_loss': tensor(1.5893, device='cuda:0'), 'train/logits_real': tensor(2.4024, device='cuda:0'), 'train/logits_fake': tensor(1.6541, device='cuda:0')}
2025-11-15 13:41:05,350 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:05,372 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:06,998 [INFO] rec_loss: 21.604385375976562, rec_log: {'train/total_loss': tensor(21.6044, device='cuda:0'), 'train/logvar': tensor(0.0015, device='cuda:0'), 'train/kl_loss': tensor(21.9304, device='cuda:0'), 'train/nll_loss': tensor(21.3930, device='cuda:0'), 'train/rec_loss': tensor(2.0619, device='cuda:0'), 'train/perception_loss': tensor(0.8055, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.0788, device='cuda:0')}
2025-11-15 13:41:10,960 [INFO] gan_loss : 1.1077749729156494,  gan_log: {'train/disc_loss': tensor(1.1078, device='cuda:0'), 'train/logits_real': tensor(1.9741, device='cuda:0'), 'train/logits_fake': tensor(0.0788, device='cuda:0')}
2025-11-15 13:41:11,003 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:11,028 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:12,666 [INFO] rec_loss: 15.329370498657227, rec_log: {'train/total_loss': tensor(15.3294, device='cuda:0'), 'train/logvar': tensor(0.0016, device='cuda:0'), 'train/kl_loss': tensor(29.8883, device='cuda:0'), 'train/nll_loss': tensor(14.8713, device='cuda:0'), 'train/rec_loss': tensor(1.4077, device='cuda:0'), 'train/perception_loss': tensor(0.8164, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.5921, device='cuda:0')}
2025-11-15 13:41:16,624 [INFO] gan_loss : 0.7982792854309082,  gan_log: {'train/disc_loss': tensor(0.7983, device='cuda:0'), 'train/logits_real': tensor(1.3613, device='cuda:0'), 'train/logits_fake': tensor(-1.5921, device='cuda:0')}
2025-11-15 13:41:16,665 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:16,687 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:18,327 [INFO] rec_loss: 10.640718460083008, rec_log: {'train/total_loss': tensor(10.6407, device='cuda:0'), 'train/logvar': tensor(0.0017, device='cuda:0'), 'train/kl_loss': tensor(41.3754, device='cuda:0'), 'train/nll_loss': tensor(9.9771, device='cuda:0'), 'train/rec_loss': tensor(0.9161, device='cuda:0'), 'train/perception_loss': tensor(0.8319, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.4985, device='cuda:0')}
2025-11-15 13:41:22,295 [INFO] gan_loss : 0.6377303600311279,  gan_log: {'train/disc_loss': tensor(0.6377, device='cuda:0'), 'train/logits_real': tensor(1.1979, device='cuda:0'), 'train/logits_fake': tensor(-2.4985, device='cuda:0')}
2025-11-15 13:41:22,337 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:22,360 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:23,989 [INFO] rec_loss: 13.716193199157715, rec_log: {'train/total_loss': tensor(13.7162, device='cuda:0'), 'train/logvar': tensor(0.0018, device='cuda:0'), 'train/kl_loss': tensor(33.7982, device='cuda:0'), 'train/nll_loss': tensor(13.1075, device='cuda:0'), 'train/rec_loss': tensor(1.2299, device='cuda:0'), 'train/perception_loss': tensor(0.8307, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.7075, device='cuda:0')}
2025-11-15 13:41:27,947 [INFO] gan_loss : 0.49405819177627563,  gan_log: {'train/disc_loss': tensor(0.4941, device='cuda:0'), 'train/logits_real': tensor(0.9630, device='cuda:0'), 'train/logits_fake': tensor(-2.7075, device='cuda:0')}
2025-11-15 13:41:27,990 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:28,013 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:29,642 [INFO] rec_loss: 17.329336166381836, rec_log: {'train/total_loss': tensor(17.3293, device='cuda:0'), 'train/logvar': tensor(0.0019, device='cuda:0'), 'train/kl_loss': tensor(20.4394, device='cuda:0'), 'train/nll_loss': tensor(16.8522, device='cuda:0'), 'train/rec_loss': tensor(1.6107, device='cuda:0'), 'train/perception_loss': tensor(0.7755, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.7273, device='cuda:0')}
2025-11-15 13:41:33,601 [INFO] gan_loss : 0.23982810974121094,  gan_log: {'train/disc_loss': tensor(0.2398, device='cuda:0'), 'train/logits_real': tensor(2.3565, device='cuda:0'), 'train/logits_fake': tensor(-2.7273, device='cuda:0')}
2025-11-15 13:41:33,643 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:33,668 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:35,300 [INFO] rec_loss: 14.646626472473145, rec_log: {'train/total_loss': tensor(14.6466, device='cuda:0'), 'train/logvar': tensor(0.0020, device='cuda:0'), 'train/kl_loss': tensor(27.4416, device='cuda:0'), 'train/nll_loss': tensor(14.2256, device='cuda:0'), 'train/rec_loss': tensor(1.3427, device='cuda:0'), 'train/perception_loss': tensor(0.8253, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.4656, device='cuda:0')}
2025-11-15 13:41:39,264 [INFO] gan_loss : 0.270472913980484,  gan_log: {'train/disc_loss': tensor(0.2705, device='cuda:0'), 'train/logits_real': tensor(3.5440, device='cuda:0'), 'train/logits_fake': tensor(-1.4656, device='cuda:0')}
2025-11-15 13:41:39,306 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:39,330 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:40,965 [INFO] rec_loss: 14.639365196228027, rec_log: {'train/total_loss': tensor(14.6394, device='cuda:0'), 'train/logvar': tensor(0.0021, device='cuda:0'), 'train/kl_loss': tensor(36.2189, device='cuda:0'), 'train/nll_loss': tensor(14.1273, device='cuda:0'), 'train/rec_loss': tensor(1.3324, device='cuda:0'), 'train/perception_loss': tensor(0.8300, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.4987, device='cuda:0')}
2025-11-15 13:41:44,924 [INFO] gan_loss : 0.39758819341659546,  gan_log: {'train/disc_loss': tensor(0.3976, device='cuda:0'), 'train/logits_real': tensor(4.0155, device='cuda:0'), 'train/logits_fake': tensor(-1.4987, device='cuda:0')}
2025-11-15 13:41:44,967 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:44,991 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:46,629 [INFO] rec_loss: 17.146146774291992, rec_log: {'train/total_loss': tensor(17.1461, device='cuda:0'), 'train/logvar': tensor(0.0022, device='cuda:0'), 'train/kl_loss': tensor(43.3395, device='cuda:0'), 'train/nll_loss': tensor(16.6592, device='cuda:0'), 'train/rec_loss': tensor(1.5885, device='cuda:0'), 'train/perception_loss': tensor(0.8082, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5358, device='cuda:0')}
2025-11-15 13:41:50,591 [INFO] gan_loss : 0.718469500541687,  gan_log: {'train/disc_loss': tensor(0.7185, device='cuda:0'), 'train/logits_real': tensor(3.0106, device='cuda:0'), 'train/logits_fake': tensor(-0.5358, device='cuda:0')}
2025-11-15 13:41:50,633 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:50,657 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:52,294 [INFO] rec_loss: 11.643230438232422, rec_log: {'train/total_loss': tensor(11.6432, device='cuda:0'), 'train/logvar': tensor(0.0022, device='cuda:0'), 'train/kl_loss': tensor(47.4954, device='cuda:0'), 'train/nll_loss': tensor(11.1324, device='cuda:0'), 'train/rec_loss': tensor(1.0363, device='cuda:0'), 'train/perception_loss': tensor(0.7920, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.3586, device='cuda:0')}
2025-11-15 13:41:56,262 [INFO] gan_loss : 0.9570226669311523,  gan_log: {'train/disc_loss': tensor(0.9570, device='cuda:0'), 'train/logits_real': tensor(1.6545, device='cuda:0'), 'train/logits_fake': tensor(-0.3586, device='cuda:0')}
2025-11-15 13:41:56,304 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:41:56,329 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:41:57,970 [INFO] rec_loss: 18.885498046875, rec_log: {'train/total_loss': tensor(18.8855, device='cuda:0'), 'train/logvar': tensor(0.0023, device='cuda:0'), 'train/kl_loss': tensor(45.9057, device='cuda:0'), 'train/nll_loss': tensor(18.3953, device='cuda:0'), 'train/rec_loss': tensor(1.7604, device='cuda:0'), 'train/perception_loss': tensor(0.8314, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.3116, device='cuda:0')}
2025-11-15 13:42:01,925 [INFO] gan_loss : 0.9561628699302673,  gan_log: {'train/disc_loss': tensor(0.9562, device='cuda:0'), 'train/logits_real': tensor(1.6200, device='cuda:0'), 'train/logits_fake': tensor(-0.3116, device='cuda:0')}
2025-11-15 13:42:01,967 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:01,992 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:03,622 [INFO] rec_loss: 14.163363456726074, rec_log: {'train/total_loss': tensor(14.1634, device='cuda:0'), 'train/logvar': tensor(0.0024, device='cuda:0'), 'train/kl_loss': tensor(33.8879, device='cuda:0'), 'train/nll_loss': tensor(13.7404, device='cuda:0'), 'train/rec_loss': tensor(1.3006, device='cuda:0'), 'train/perception_loss': tensor(0.7649, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8406, device='cuda:0')}
2025-11-15 13:42:07,586 [INFO] gan_loss : 1.4647408723831177,  gan_log: {'train/disc_loss': tensor(1.4647, device='cuda:0'), 'train/logits_real': tensor(-0.3345, device='cuda:0'), 'train/logits_fake': tensor(-0.8406, device='cuda:0')}
2025-11-15 13:42:07,628 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:07,652 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:09,278 [INFO] rec_loss: 18.461938858032227, rec_log: {'train/total_loss': tensor(18.4619, device='cuda:0'), 'train/logvar': tensor(0.0025, device='cuda:0'), 'train/kl_loss': tensor(48.5256, device='cuda:0'), 'train/nll_loss': tensor(17.8991, device='cuda:0'), 'train/rec_loss': tensor(1.7165, device='cuda:0'), 'train/perception_loss': tensor(0.7765, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7756, device='cuda:0')}
2025-11-15 13:42:13,245 [INFO] gan_loss : 1.0879871845245361,  gan_log: {'train/disc_loss': tensor(1.0880, device='cuda:0'), 'train/logits_real': tensor(0.0563, device='cuda:0'), 'train/logits_fake': tensor(-0.7756, device='cuda:0')}
2025-11-15 13:42:13,287 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:13,314 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:14,952 [INFO] rec_loss: 14.628929138183594, rec_log: {'train/total_loss': tensor(14.6289, device='cuda:0'), 'train/logvar': tensor(0.0026, device='cuda:0'), 'train/kl_loss': tensor(57.3982, device='cuda:0'), 'train/nll_loss': tensor(14.0528, device='cuda:0'), 'train/rec_loss': tensor(1.3278, device='cuda:0'), 'train/perception_loss': tensor(0.8086, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0214, device='cuda:0')}
2025-11-15 13:42:18,907 [INFO] gan_loss : 1.05449378490448,  gan_log: {'train/disc_loss': tensor(1.0545, device='cuda:0'), 'train/logits_real': tensor(1.2329, device='cuda:0'), 'train/logits_fake': tensor(-0.0214, device='cuda:0')}
2025-11-15 13:42:18,949 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:18,974 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:20,610 [INFO] rec_loss: 15.279706001281738, rec_log: {'train/total_loss': tensor(15.2797, device='cuda:0'), 'train/logvar': tensor(0.0027, device='cuda:0'), 'train/kl_loss': tensor(40.3087, device='cuda:0'), 'train/nll_loss': tensor(14.7233, device='cuda:0'), 'train/rec_loss': tensor(1.3961, device='cuda:0'), 'train/perception_loss': tensor(0.7988, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.5331, device='cuda:0')}
2025-11-15 13:42:24,574 [INFO] gan_loss : 1.3295530080795288,  gan_log: {'train/disc_loss': tensor(1.3296, device='cuda:0'), 'train/logits_real': tensor(-0.4762, device='cuda:0'), 'train/logits_fake': tensor(-1.5331, device='cuda:0')}
2025-11-15 13:42:24,616 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:24,646 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:26,282 [INFO] rec_loss: 12.386157035827637, rec_log: {'train/total_loss': tensor(12.3862, device='cuda:0'), 'train/logvar': tensor(0.0028, device='cuda:0'), 'train/kl_loss': tensor(39.6157, device='cuda:0'), 'train/nll_loss': tensor(11.7009, device='cuda:0'), 'train/rec_loss': tensor(1.0954, device='cuda:0'), 'train/perception_loss': tensor(0.7765, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.8908, device='cuda:0')}
2025-11-15 13:42:30,244 [INFO] gan_loss : 0.5352308750152588,  gan_log: {'train/disc_loss': tensor(0.5352, device='cuda:0'), 'train/logits_real': tensor(0.9085, device='cuda:0'), 'train/logits_fake': tensor(-2.8908, device='cuda:0')}
2025-11-15 13:42:30,286 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:30,311 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:31,943 [INFO] rec_loss: 14.388630867004395, rec_log: {'train/total_loss': tensor(14.3886, device='cuda:0'), 'train/logvar': tensor(0.0028, device='cuda:0'), 'train/kl_loss': tensor(53.2321, device='cuda:0'), 'train/nll_loss': tensor(13.6091, device='cuda:0'), 'train/rec_loss': tensor(1.2867, device='cuda:0'), 'train/perception_loss': tensor(0.7781, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.4722, device='cuda:0')}
2025-11-15 13:42:35,903 [INFO] gan_loss : 0.1814815253019333,  gan_log: {'train/disc_loss': tensor(0.1815, device='cuda:0'), 'train/logits_real': tensor(3.4122, device='cuda:0'), 'train/logits_fake': tensor(-2.4722, device='cuda:0')}
2025-11-15 13:42:35,945 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:35,969 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:37,599 [INFO] rec_loss: 14.418031692504883, rec_log: {'train/total_loss': tensor(14.4180, device='cuda:0'), 'train/logvar': tensor(0.0029, device='cuda:0'), 'train/kl_loss': tensor(38.7001, device='cuda:0'), 'train/nll_loss': tensor(13.7261, device='cuda:0'), 'train/rec_loss': tensor(1.3001, device='cuda:0'), 'train/perception_loss': tensor(0.7629, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.0490, device='cuda:0')}
2025-11-15 13:42:41,558 [INFO] gan_loss : 0.4081861972808838,  gan_log: {'train/disc_loss': tensor(0.4082, device='cuda:0'), 'train/logits_real': tensor(3.1626, device='cuda:0'), 'train/logits_fake': tensor(-3.0490, device='cuda:0')}
2025-11-15 13:42:41,600 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:41,624 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:43,260 [INFO] rec_loss: 16.92152214050293, rec_log: {'train/total_loss': tensor(16.9215, device='cuda:0'), 'train/logvar': tensor(0.0030, device='cuda:0'), 'train/kl_loss': tensor(40.1563, device='cuda:0'), 'train/nll_loss': tensor(16.2484, device='cuda:0'), 'train/rec_loss': tensor(1.5507, device='cuda:0'), 'train/perception_loss': tensor(0.7877, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.7151, device='cuda:0')}
2025-11-15 13:42:47,227 [INFO] gan_loss : 0.350124716758728,  gan_log: {'train/disc_loss': tensor(0.3501, device='cuda:0'), 'train/logits_real': tensor(4.2984, device='cuda:0'), 'train/logits_fake': tensor(-2.7151, device='cuda:0')}
2025-11-15 13:42:47,269 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:47,296 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:48,935 [INFO] rec_loss: 10.282891273498535, rec_log: {'train/total_loss': tensor(10.2829, device='cuda:0'), 'train/logvar': tensor(0.0031, device='cuda:0'), 'train/kl_loss': tensor(39.2125, device='cuda:0'), 'train/nll_loss': tensor(9.6941, device='cuda:0'), 'train/rec_loss': tensor(0.8960, device='cuda:0'), 'train/perception_loss': tensor(0.7613, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.9670, device='cuda:0')}
2025-11-15 13:42:52,892 [INFO] gan_loss : 0.5727750062942505,  gan_log: {'train/disc_loss': tensor(0.5728, device='cuda:0'), 'train/logits_real': tensor(5.4859, device='cuda:0'), 'train/logits_fake': tensor(-1.9670, device='cuda:0')}
2025-11-15 13:42:52,934 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:52,958 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:42:54,597 [INFO] rec_loss: 15.788174629211426, rec_log: {'train/total_loss': tensor(15.7882, device='cuda:0'), 'train/logvar': tensor(0.0032, device='cuda:0'), 'train/kl_loss': tensor(30.3471, device='cuda:0'), 'train/nll_loss': tensor(15.2969, device='cuda:0'), 'train/rec_loss': tensor(1.4499, device='cuda:0'), 'train/perception_loss': tensor(0.8432, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.8784, device='cuda:0')}
2025-11-15 13:42:58,576 [INFO] gan_loss : 0.41468217968940735,  gan_log: {'train/disc_loss': tensor(0.4147, device='cuda:0'), 'train/logits_real': tensor(5.7142, device='cuda:0'), 'train/logits_fake': tensor(-1.8784, device='cuda:0')}
2025-11-15 13:42:58,618 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:42:58,642 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:00,280 [INFO] rec_loss: 17.756031036376953, rec_log: {'train/total_loss': tensor(17.7560, device='cuda:0'), 'train/logvar': tensor(0.0033, device='cuda:0'), 'train/kl_loss': tensor(34.1479, device='cuda:0'), 'train/nll_loss': tensor(17.1278, device='cuda:0'), 'train/rec_loss': tensor(1.6327, device='cuda:0'), 'train/perception_loss': tensor(0.8536, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.8670, device='cuda:0')}
2025-11-15 13:43:04,241 [INFO] gan_loss : 0.24195685982704163,  gan_log: {'train/disc_loss': tensor(0.2420, device='cuda:0'), 'train/logits_real': tensor(4.3364, device='cuda:0'), 'train/logits_fake': tensor(-2.8670, device='cuda:0')}
2025-11-15 13:43:04,283 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:04,309 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:05,945 [INFO] rec_loss: 10.209238052368164, rec_log: {'train/total_loss': tensor(10.2092, device='cuda:0'), 'train/logvar': tensor(0.0033, device='cuda:0'), 'train/kl_loss': tensor(37.8086, device='cuda:0'), 'train/nll_loss': tensor(9.3874, device='cuda:0'), 'train/rec_loss': tensor(0.8635, device='cuda:0'), 'train/perception_loss': tensor(0.7803, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(4.4374, device='cuda:0')}
2025-11-15 13:43:09,912 [INFO] gan_loss : 0.33714666962623596,  gan_log: {'train/disc_loss': tensor(0.3371, device='cuda:0'), 'train/logits_real': tensor(3.0832, device='cuda:0'), 'train/logits_fake': tensor(-4.4374, device='cuda:0')}
2025-11-15 13:43:09,955 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:09,981 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:11,618 [INFO] rec_loss: 18.174259185791016, rec_log: {'train/total_loss': tensor(18.1743, device='cuda:0'), 'train/logvar': tensor(0.0034, device='cuda:0'), 'train/kl_loss': tensor(48.5452, device='cuda:0'), 'train/nll_loss': tensor(17.2529, device='cuda:0'), 'train/rec_loss': tensor(1.6539, device='cuda:0'), 'train/perception_loss': tensor(0.7693, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(4.3589, device='cuda:0')}
2025-11-15 13:43:15,573 [INFO] gan_loss : 0.2785000503063202,  gan_log: {'train/disc_loss': tensor(0.2785, device='cuda:0'), 'train/logits_real': tensor(3.0826, device='cuda:0'), 'train/logits_fake': tensor(-4.3589, device='cuda:0')}
2025-11-15 13:43:15,616 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:15,638 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:17,280 [INFO] rec_loss: 14.374619483947754, rec_log: {'train/total_loss': tensor(14.3746, device='cuda:0'), 'train/logvar': tensor(0.0035, device='cuda:0'), 'train/kl_loss': tensor(33.7718, device='cuda:0'), 'train/nll_loss': tensor(13.7265, device='cuda:0'), 'train/rec_loss': tensor(1.2987, device='cuda:0'), 'train/perception_loss': tensor(0.7843, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.1036, device='cuda:0')}
2025-11-15 13:43:21,250 [INFO] gan_loss : 0.347280353307724,  gan_log: {'train/disc_loss': tensor(0.3473, device='cuda:0'), 'train/logits_real': tensor(4.5815, device='cuda:0'), 'train/logits_fake': tensor(-3.1036, device='cuda:0')}
2025-11-15 13:43:21,292 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:21,318 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:22,956 [INFO] rec_loss: 11.671855926513672, rec_log: {'train/total_loss': tensor(11.6719, device='cuda:0'), 'train/logvar': tensor(0.0036, device='cuda:0'), 'train/kl_loss': tensor(39.3021, device='cuda:0'), 'train/nll_loss': tensor(11.1622, device='cuda:0'), 'train/rec_loss': tensor(1.0416, device='cuda:0'), 'train/perception_loss': tensor(0.7827, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.1664, device='cuda:0')}
2025-11-15 13:43:26,918 [INFO] gan_loss : 0.3865007758140564,  gan_log: {'train/disc_loss': tensor(0.3865, device='cuda:0'), 'train/logits_real': tensor(6.1238, device='cuda:0'), 'train/logits_fake': tensor(-1.1664, device='cuda:0')}
2025-11-15 13:43:26,960 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:26,983 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:28,623 [INFO] rec_loss: 13.20062255859375, rec_log: {'train/total_loss': tensor(13.2006, device='cuda:0'), 'train/logvar': tensor(0.0037, device='cuda:0'), 'train/kl_loss': tensor(32.7639, device='cuda:0'), 'train/nll_loss': tensor(12.7511, device='cuda:0'), 'train/rec_loss': tensor(1.2020, device='cuda:0'), 'train/perception_loss': tensor(0.7740, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.2186, device='cuda:0')}
2025-11-15 13:43:32,592 [INFO] gan_loss : 0.4253208339214325,  gan_log: {'train/disc_loss': tensor(0.4253, device='cuda:0'), 'train/logits_real': tensor(4.1476, device='cuda:0'), 'train/logits_fake': tensor(-1.2186, device='cuda:0')}
2025-11-15 13:43:32,634 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:32,663 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:34,295 [INFO] rec_loss: 20.571453094482422, rec_log: {'train/total_loss': tensor(20.5715, device='cuda:0'), 'train/logvar': tensor(0.0038, device='cuda:0'), 'train/kl_loss': tensor(45.6716, device='cuda:0'), 'train/nll_loss': tensor(20.1042, device='cuda:0'), 'train/rec_loss': tensor(1.9401, device='cuda:0'), 'train/perception_loss': tensor(0.7750, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.1056, device='cuda:0')}
2025-11-15 13:43:38,259 [INFO] gan_loss : 0.8353763222694397,  gan_log: {'train/disc_loss': tensor(0.8354, device='cuda:0'), 'train/logits_real': tensor(4.8935, device='cuda:0'), 'train/logits_fake': tensor(-0.1056, device='cuda:0')}
2025-11-15 13:43:38,301 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:38,325 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:39,957 [INFO] rec_loss: 11.895654678344727, rec_log: {'train/total_loss': tensor(11.8957, device='cuda:0'), 'train/logvar': tensor(0.0038, device='cuda:0'), 'train/kl_loss': tensor(40.9210, device='cuda:0'), 'train/nll_loss': tensor(11.4477, device='cuda:0'), 'train/rec_loss': tensor(1.0652, device='cuda:0'), 'train/perception_loss': tensor(0.8357, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.3878, device='cuda:0')}
2025-11-15 13:43:43,919 [INFO] gan_loss : 1.1754120588302612,  gan_log: {'train/disc_loss': tensor(1.1754, device='cuda:0'), 'train/logits_real': tensor(2.5173, device='cuda:0'), 'train/logits_fake': tensor(-0.3878, device='cuda:0')}
2025-11-15 13:43:43,961 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:43,989 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:45,626 [INFO] rec_loss: 21.82909393310547, rec_log: {'train/total_loss': tensor(21.8291, device='cuda:0'), 'train/logvar': tensor(0.0039, device='cuda:0'), 'train/kl_loss': tensor(45.8751, device='cuda:0'), 'train/nll_loss': tensor(21.2027, device='cuda:0'), 'train/rec_loss': tensor(2.0483, device='cuda:0'), 'train/perception_loss': tensor(0.7991, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.6761, device='cuda:0')}
2025-11-15 13:43:49,591 [INFO] gan_loss : 1.020205020904541,  gan_log: {'train/disc_loss': tensor(1.0202, device='cuda:0'), 'train/logits_real': tensor(0.9896, device='cuda:0'), 'train/logits_fake': tensor(-1.6761, device='cuda:0')}
2025-11-15 13:43:49,634 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:49,659 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:51,285 [INFO] rec_loss: 15.961153984069824, rec_log: {'train/total_loss': tensor(15.9612, device='cuda:0'), 'train/logvar': tensor(0.0040, device='cuda:0'), 'train/kl_loss': tensor(42.2310, device='cuda:0'), 'train/nll_loss': tensor(15.3166, device='cuda:0'), 'train/rec_loss': tensor(1.4587, device='cuda:0'), 'train/perception_loss': tensor(0.7866, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.2223, device='cuda:0')}
2025-11-15 13:43:55,245 [INFO] gan_loss : 0.8623592853546143,  gan_log: {'train/disc_loss': tensor(0.8624, device='cuda:0'), 'train/logits_real': tensor(0.1416, device='cuda:0'), 'train/logits_fake': tensor(-2.2223, device='cuda:0')}
2025-11-15 13:43:55,290 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:43:55,322 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:43:56,954 [INFO] rec_loss: 15.177961349487305, rec_log: {'train/total_loss': tensor(15.1780, device='cuda:0'), 'train/logvar': tensor(0.0041, device='cuda:0'), 'train/kl_loss': tensor(37.2774, device='cuda:0'), 'train/nll_loss': tensor(14.6109, device='cuda:0'), 'train/rec_loss': tensor(1.3815, device='cuda:0'), 'train/perception_loss': tensor(0.8513, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.9433, device='cuda:0')}
2025-11-15 13:44:00,912 [INFO] gan_loss : 0.801117479801178,  gan_log: {'train/disc_loss': tensor(0.8011, device='cuda:0'), 'train/logits_real': tensor(0.9563, device='cuda:0'), 'train/logits_fake': tensor(-1.9433, device='cuda:0')}
2025-11-15 13:44:00,954 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:00,978 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:02,613 [INFO] rec_loss: 10.523520469665527, rec_log: {'train/total_loss': tensor(10.5235, device='cuda:0'), 'train/logvar': tensor(0.0042, device='cuda:0'), 'train/kl_loss': tensor(26.6286, device='cuda:0'), 'train/nll_loss': tensor(10.1901, device='cuda:0'), 'train/rec_loss': tensor(0.9481, device='cuda:0'), 'train/perception_loss': tensor(0.7473, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6716, device='cuda:0')}
2025-11-15 13:44:06,571 [INFO] gan_loss : 1.0320404767990112,  gan_log: {'train/disc_loss': tensor(1.0320, device='cuda:0'), 'train/logits_real': tensor(1.4012, device='cuda:0'), 'train/logits_fake': tensor(-0.6716, device='cuda:0')}
2025-11-15 13:44:06,613 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:06,638 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:08,263 [INFO] rec_loss: 12.805355072021484, rec_log: {'train/total_loss': tensor(12.8054, device='cuda:0'), 'train/logvar': tensor(0.0043, device='cuda:0'), 'train/kl_loss': tensor(32.7054, device='cuda:0'), 'train/nll_loss': tensor(12.3130, device='cuda:0'), 'train/rec_loss': tensor(1.1501, device='cuda:0'), 'train/perception_loss': tensor(0.8609, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.6526, device='cuda:0')}
2025-11-15 13:44:12,226 [INFO] gan_loss : 0.5239454507827759,  gan_log: {'train/disc_loss': tensor(0.5239, device='cuda:0'), 'train/logits_real': tensor(2.6680, device='cuda:0'), 'train/logits_fake': tensor(-1.6526, device='cuda:0')}
2025-11-15 13:44:12,268 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:12,292 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:13,924 [INFO] rec_loss: 12.339926719665527, rec_log: {'train/total_loss': tensor(12.3399, device='cuda:0'), 'train/logvar': tensor(0.0044, device='cuda:0'), 'train/kl_loss': tensor(28.1119, device='cuda:0'), 'train/nll_loss': tensor(11.7926, device='cuda:0'), 'train/rec_loss': tensor(1.1046, device='cuda:0'), 'train/perception_loss': tensor(0.7939, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.6624, device='cuda:0')}
2025-11-15 13:44:17,882 [INFO] gan_loss : 0.27914729714393616,  gan_log: {'train/disc_loss': tensor(0.2791, device='cuda:0'), 'train/logits_real': tensor(3.0477, device='cuda:0'), 'train/logits_fake': tensor(-2.6624, device='cuda:0')}
2025-11-15 13:44:17,925 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:17,953 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:19,585 [INFO] rec_loss: 20.153244018554688, rec_log: {'train/total_loss': tensor(20.1532, device='cuda:0'), 'train/logvar': tensor(0.0044, device='cuda:0'), 'train/kl_loss': tensor(49.3409, device='cuda:0'), 'train/nll_loss': tensor(19.4441, device='cuda:0'), 'train/rec_loss': tensor(1.8756, device='cuda:0'), 'train/perception_loss': tensor(0.7699, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.1571, device='cuda:0')}
2025-11-15 13:44:23,550 [INFO] gan_loss : 0.3238149583339691,  gan_log: {'train/disc_loss': tensor(0.3238, device='cuda:0'), 'train/logits_real': tensor(2.4380, device='cuda:0'), 'train/logits_fake': tensor(-2.1571, device='cuda:0')}
2025-11-15 13:44:23,592 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:23,617 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:25,251 [INFO] rec_loss: 10.918200492858887, rec_log: {'train/total_loss': tensor(10.9182, device='cuda:0'), 'train/logvar': tensor(0.0045, device='cuda:0'), 'train/kl_loss': tensor(61.7910, device='cuda:0'), 'train/nll_loss': tensor(10.1950, device='cuda:0'), 'train/rec_loss': tensor(0.9458, device='cuda:0'), 'train/perception_loss': tensor(0.7788, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.0529, device='cuda:0')}
2025-11-15 13:44:29,218 [INFO] gan_loss : 0.4298314154148102,  gan_log: {'train/disc_loss': tensor(0.4298, device='cuda:0'), 'train/logits_real': tensor(4.5628, device='cuda:0'), 'train/logits_fake': tensor(-1.0529, device='cuda:0')}
2025-11-15 13:44:29,260 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:29,288 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:30,911 [INFO] rec_loss: 16.335220336914062, rec_log: {'train/total_loss': tensor(16.3352, device='cuda:0'), 'train/logvar': tensor(0.0046, device='cuda:0'), 'train/kl_loss': tensor(92.3552, device='cuda:0'), 'train/nll_loss': tensor(15.2851, device='cuda:0'), 'train/rec_loss': tensor(1.4531, device='cuda:0'), 'train/perception_loss': tensor(0.8199, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.2661, device='cuda:0')}
2025-11-15 13:44:34,879 [INFO] gan_loss : 0.5570025444030762,  gan_log: {'train/disc_loss': tensor(0.5570, device='cuda:0'), 'train/logits_real': tensor(3.6212, device='cuda:0'), 'train/logits_fake': tensor(-1.2661, device='cuda:0')}
2025-11-15 13:44:34,920 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:34,948 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:36,584 [INFO] rec_loss: 11.713863372802734, rec_log: {'train/total_loss': tensor(11.7139, device='cuda:0'), 'train/logvar': tensor(0.0047, device='cuda:0'), 'train/kl_loss': tensor(87.5716, device='cuda:0'), 'train/nll_loss': tensor(10.6820, device='cuda:0'), 'train/rec_loss': tensor(0.9956, device='cuda:0'), 'train/perception_loss': tensor(0.7715, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.5617, device='cuda:0')}
2025-11-15 13:44:40,548 [INFO] gan_loss : 0.35909169912338257,  gan_log: {'train/disc_loss': tensor(0.3591, device='cuda:0'), 'train/logits_real': tensor(3.7337, device='cuda:0'), 'train/logits_fake': tensor(-1.5617, device='cuda:0')}
2025-11-15 13:44:40,590 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:40,618 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:42,252 [INFO] rec_loss: 11.748186111450195, rec_log: {'train/total_loss': tensor(11.7482, device='cuda:0'), 'train/logvar': tensor(0.0048, device='cuda:0'), 'train/kl_loss': tensor(71.6543, device='cuda:0'), 'train/nll_loss': tensor(10.7678, device='cuda:0'), 'train/rec_loss': tensor(1.0001, device='cuda:0'), 'train/perception_loss': tensor(0.8139, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.6384, device='cuda:0')}
2025-11-15 13:44:46,216 [INFO] gan_loss : 0.4031028747558594,  gan_log: {'train/disc_loss': tensor(0.4031, device='cuda:0'), 'train/logits_real': tensor(2.0359, device='cuda:0'), 'train/logits_fake': tensor(-2.6384, device='cuda:0')}
2025-11-15 13:44:46,258 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:46,278 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:47,910 [INFO] rec_loss: 11.886167526245117, rec_log: {'train/total_loss': tensor(11.8862, device='cuda:0'), 'train/logvar': tensor(0.0049, device='cuda:0'), 'train/kl_loss': tensor(76.4483, device='cuda:0'), 'train/nll_loss': tensor(11.0673, device='cuda:0'), 'train/rec_loss': tensor(1.0327, device='cuda:0'), 'train/perception_loss': tensor(0.7896, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5439, device='cuda:0')}
2025-11-15 13:44:51,879 [INFO] gan_loss : 0.7617332339286804,  gan_log: {'train/disc_loss': tensor(0.7617, device='cuda:0'), 'train/logits_real': tensor(2.2962, device='cuda:0'), 'train/logits_fake': tensor(-0.5439, device='cuda:0')}
2025-11-15 13:44:51,922 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:51,944 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:53,581 [INFO] rec_loss: 11.030608177185059, rec_log: {'train/total_loss': tensor(11.0306, device='cuda:0'), 'train/logvar': tensor(0.0049, device='cuda:0'), 'train/kl_loss': tensor(55.6114, device='cuda:0'), 'train/nll_loss': tensor(10.4678, device='cuda:0'), 'train/rec_loss': tensor(0.9787, device='cuda:0'), 'train/perception_loss': tensor(0.7281, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.0667, device='cuda:0')}
2025-11-15 13:44:57,551 [INFO] gan_loss : 1.0340747833251953,  gan_log: {'train/disc_loss': tensor(1.0341, device='cuda:0'), 'train/logits_real': tensor(1.8045, device='cuda:0'), 'train/logits_fake': tensor(-0.0667, device='cuda:0')}
2025-11-15 13:44:57,594 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:44:57,620 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:44:59,253 [INFO] rec_loss: 15.280681610107422, rec_log: {'train/total_loss': tensor(15.2807, device='cuda:0'), 'train/logvar': tensor(0.0050, device='cuda:0'), 'train/kl_loss': tensor(86.5601, device='cuda:0'), 'train/nll_loss': tensor(14.2222, device='cuda:0'), 'train/rec_loss': tensor(1.3537, device='cuda:0'), 'train/perception_loss': tensor(0.7520, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.9292, device='cuda:0')}
2025-11-15 13:45:03,217 [INFO] gan_loss : 1.5480713844299316,  gan_log: {'train/disc_loss': tensor(1.5481, device='cuda:0'), 'train/logits_real': tensor(-1.6176, device='cuda:0'), 'train/logits_fake': tensor(-1.9292, device='cuda:0')}
2025-11-15 13:45:03,259 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:03,286 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:04,909 [INFO] rec_loss: 12.689250946044922, rec_log: {'train/total_loss': tensor(12.6893, device='cuda:0'), 'train/logvar': tensor(0.0051, device='cuda:0'), 'train/kl_loss': tensor(56.3903, device='cuda:0'), 'train/nll_loss': tensor(12.0593, device='cuda:0'), 'train/rec_loss': tensor(1.1379, device='cuda:0'), 'train/perception_loss': tensor(0.7367, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6608, device='cuda:0')}
2025-11-15 13:45:08,878 [INFO] gan_loss : 1.6231328248977661,  gan_log: {'train/disc_loss': tensor(1.6231, device='cuda:0'), 'train/logits_real': tensor(-1.3063, device='cuda:0'), 'train/logits_fake': tensor(-0.6608, device='cuda:0')}
2025-11-15 13:45:08,921 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:08,947 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:10,585 [INFO] rec_loss: 10.359254837036133, rec_log: {'train/total_loss': tensor(10.3593, device='cuda:0'), 'train/logvar': tensor(0.0052, device='cuda:0'), 'train/kl_loss': tensor(49.3072, device='cuda:0'), 'train/nll_loss': tensor(9.8055, device='cuda:0'), 'train/rec_loss': tensor(0.9049, device='cuda:0'), 'train/perception_loss': tensor(0.8019, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6072, device='cuda:0')}
2025-11-15 13:45:14,555 [INFO] gan_loss : 1.246548056602478,  gan_log: {'train/disc_loss': tensor(1.2465, device='cuda:0'), 'train/logits_real': tensor(-0.2452, device='cuda:0'), 'train/logits_fake': tensor(-0.6072, device='cuda:0')}
2025-11-15 13:45:14,596 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:14,623 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:16,262 [INFO] rec_loss: 14.519347190856934, rec_log: {'train/total_loss': tensor(14.5193, device='cuda:0'), 'train/logvar': tensor(0.0053, device='cuda:0'), 'train/kl_loss': tensor(49.2890, device='cuda:0'), 'train/nll_loss': tensor(13.9046, device='cuda:0'), 'train/rec_loss': tensor(1.3194, device='cuda:0'), 'train/perception_loss': tensor(0.7786, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.2184, device='cuda:0')}
2025-11-15 13:45:20,219 [INFO] gan_loss : 1.0768427848815918,  gan_log: {'train/disc_loss': tensor(1.0768, device='cuda:0'), 'train/logits_real': tensor(-0.2887, device='cuda:0'), 'train/logits_fake': tensor(-1.2184, device='cuda:0')}
2025-11-15 13:45:20,261 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:20,284 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:21,916 [INFO] rec_loss: 15.289873123168945, rec_log: {'train/total_loss': tensor(15.2899, device='cuda:0'), 'train/logvar': tensor(0.0053, device='cuda:0'), 'train/kl_loss': tensor(80.1733, device='cuda:0'), 'train/nll_loss': tensor(14.4268, device='cuda:0'), 'train/rec_loss': tensor(1.3722, device='cuda:0'), 'train/perception_loss': tensor(0.7764, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6132, device='cuda:0')}
2025-11-15 13:45:25,876 [INFO] gan_loss : 0.4958356022834778,  gan_log: {'train/disc_loss': tensor(0.4958, device='cuda:0'), 'train/logits_real': tensor(2.7201, device='cuda:0'), 'train/logits_fake': tensor(-0.6132, device='cuda:0')}
2025-11-15 13:45:25,918 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:25,945 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:27,579 [INFO] rec_loss: 11.310601234436035, rec_log: {'train/total_loss': tensor(11.3106, device='cuda:0'), 'train/logvar': tensor(0.0054, device='cuda:0'), 'train/kl_loss': tensor(63.6306, device='cuda:0'), 'train/nll_loss': tensor(10.6120, device='cuda:0'), 'train/rec_loss': tensor(0.9859, device='cuda:0'), 'train/perception_loss': tensor(0.8053, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.6231, device='cuda:0')}
2025-11-15 13:45:31,543 [INFO] gan_loss : 0.8583356142044067,  gan_log: {'train/disc_loss': tensor(0.8583, device='cuda:0'), 'train/logits_real': tensor(1.5957, device='cuda:0'), 'train/logits_fake': tensor(-0.6231, device='cuda:0')}
2025-11-15 13:45:31,585 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:31,608 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:33,241 [INFO] rec_loss: 12.947157859802246, rec_log: {'train/total_loss': tensor(12.9472, device='cuda:0'), 'train/logvar': tensor(0.0055, device='cuda:0'), 'train/kl_loss': tensor(80.6410, device='cuda:0'), 'train/nll_loss': tensor(12.0053, device='cuda:0'), 'train/rec_loss': tensor(1.1278, device='cuda:0'), 'train/perception_loss': tensor(0.7875, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3544, device='cuda:0')}
2025-11-15 13:45:37,211 [INFO] gan_loss : 0.5422468781471252,  gan_log: {'train/disc_loss': tensor(0.5422, device='cuda:0'), 'train/logits_real': tensor(2.0115, device='cuda:0'), 'train/logits_fake': tensor(-1.3544, device='cuda:0')}
2025-11-15 13:45:37,253 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:37,278 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:38,908 [INFO] rec_loss: 11.721515655517578, rec_log: {'train/total_loss': tensor(11.7215, device='cuda:0'), 'train/logvar': tensor(0.0056, device='cuda:0'), 'train/kl_loss': tensor(113.7024, device='cuda:0'), 'train/nll_loss': tensor(10.4022, device='cuda:0'), 'train/rec_loss': tensor(0.9686, device='cuda:0'), 'train/perception_loss': tensor(0.7691, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.8226, device='cuda:0')}
2025-11-15 13:45:42,871 [INFO] gan_loss : 0.6102359890937805,  gan_log: {'train/disc_loss': tensor(0.6102, device='cuda:0'), 'train/logits_real': tensor(1.0297, device='cuda:0'), 'train/logits_fake': tensor(-1.8226, device='cuda:0')}
2025-11-15 13:45:42,913 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:42,944 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:44,584 [INFO] rec_loss: 11.329730987548828, rec_log: {'train/total_loss': tensor(11.3297, device='cuda:0'), 'train/logvar': tensor(0.0056, device='cuda:0'), 'train/kl_loss': tensor(82.9991, device='cuda:0'), 'train/nll_loss': tensor(10.3968, device='cuda:0'), 'train/rec_loss': tensor(0.9665, device='cuda:0'), 'train/perception_loss': tensor(0.7845, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.0294, device='cuda:0')}
2025-11-15 13:45:48,548 [INFO] gan_loss : 1.434707760810852,  gan_log: {'train/disc_loss': tensor(1.4347, device='cuda:0'), 'train/logits_real': tensor(-0.0664, device='cuda:0'), 'train/logits_fake': tensor(-1.0294, device='cuda:0')}
2025-11-15 13:45:48,591 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:48,617 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:50,253 [INFO] rec_loss: 15.049616813659668, rec_log: {'train/total_loss': tensor(15.0496, device='cuda:0'), 'train/logvar': tensor(0.0057, device='cuda:0'), 'train/kl_loss': tensor(73.2759, device='cuda:0'), 'train/nll_loss': tensor(14.5565, device='cuda:0'), 'train/rec_loss': tensor(1.3859, device='cuda:0'), 'train/perception_loss': tensor(0.7755, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-2.3968, device='cuda:0')}
2025-11-15 13:45:54,206 [INFO] gan_loss : 2.399294376373291,  gan_log: {'train/disc_loss': tensor(2.3993, device='cuda:0'), 'train/logits_real': tensor(0.7688, device='cuda:0'), 'train/logits_fake': tensor(2.3968, device='cuda:0')}
2025-11-15 13:45:54,249 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:54,273 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:45:55,908 [INFO] rec_loss: 13.497949600219727, rec_log: {'train/total_loss': tensor(13.4979, device='cuda:0'), 'train/logvar': tensor(0.0058, device='cuda:0'), 'train/kl_loss': tensor(85.1845, device='cuda:0'), 'train/nll_loss': tensor(12.6195, device='cuda:0'), 'train/rec_loss': tensor(1.1934, device='cuda:0'), 'train/perception_loss': tensor(0.7535, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2663, device='cuda:0')}
2025-11-15 13:45:59,878 [INFO] gan_loss : 1.368614673614502,  gan_log: {'train/disc_loss': tensor(1.3686, device='cuda:0'), 'train/logits_real': tensor(0.1448, device='cuda:0'), 'train/logits_fake': tensor(-0.2663, device='cuda:0')}
2025-11-15 13:45:59,921 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:45:59,945 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:01,586 [INFO] rec_loss: 13.507917404174805, rec_log: {'train/total_loss': tensor(13.5079, device='cuda:0'), 'train/logvar': tensor(0.0059, device='cuda:0'), 'train/kl_loss': tensor(49.3401, device='cuda:0'), 'train/nll_loss': tensor(13.0904, device='cuda:0'), 'train/rec_loss': tensor(1.2373, device='cuda:0'), 'train/perception_loss': tensor(0.7890, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.7588, device='cuda:0')}
2025-11-15 13:46:05,545 [INFO] gan_loss : 1.9108997583389282,  gan_log: {'train/disc_loss': tensor(1.9109, device='cuda:0'), 'train/logits_real': tensor(-0.3567, device='cuda:0'), 'train/logits_fake': tensor(0.7588, device='cuda:0')}
2025-11-15 13:46:05,587 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:05,612 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:07,249 [INFO] rec_loss: 12.303080558776855, rec_log: {'train/total_loss': tensor(12.3031, device='cuda:0'), 'train/logvar': tensor(0.0060, device='cuda:0'), 'train/kl_loss': tensor(59.9947, device='cuda:0'), 'train/nll_loss': tensor(11.6699, device='cuda:0'), 'train/rec_loss': tensor(1.0890, device='cuda:0'), 'train/perception_loss': tensor(0.8434, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.3328, device='cuda:0')}
2025-11-15 13:46:11,213 [INFO] gan_loss : 1.19345223903656,  gan_log: {'train/disc_loss': tensor(1.1935, device='cuda:0'), 'train/logits_real': tensor(0.2486, device='cuda:0'), 'train/logits_fake': tensor(-0.3328, device='cuda:0')}
2025-11-15 13:46:11,255 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:11,280 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:12,923 [INFO] rec_loss: 11.550092697143555, rec_log: {'train/total_loss': tensor(11.5501, device='cuda:0'), 'train/logvar': tensor(0.0060, device='cuda:0'), 'train/kl_loss': tensor(55.2296, device='cuda:0'), 'train/nll_loss': tensor(10.9492, device='cuda:0'), 'train/rec_loss': tensor(1.0148, device='cuda:0'), 'train/perception_loss': tensor(0.8610, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.4858, device='cuda:0')}
2025-11-15 13:46:16,892 [INFO] gan_loss : 1.3059784173965454,  gan_log: {'train/disc_loss': tensor(1.3060, device='cuda:0'), 'train/logits_real': tensor(0.0578, device='cuda:0'), 'train/logits_fake': tensor(-0.4858, device='cuda:0')}
2025-11-15 13:46:16,935 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:16,956 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:18,589 [INFO] rec_loss: 9.311203002929688, rec_log: {'train/total_loss': tensor(9.3112, device='cuda:0'), 'train/logvar': tensor(0.0061, device='cuda:0'), 'train/kl_loss': tensor(75.0704, device='cuda:0'), 'train/nll_loss': tensor(8.4023, device='cuda:0'), 'train/rec_loss': tensor(0.7698, device='cuda:0'), 'train/perception_loss': tensor(0.7496, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.5817, device='cuda:0')}
2025-11-15 13:46:22,562 [INFO] gan_loss : 1.402571439743042,  gan_log: {'train/disc_loss': tensor(1.4026, device='cuda:0'), 'train/logits_real': tensor(-1.3987, device='cuda:0'), 'train/logits_fake': tensor(-1.5817, device='cuda:0')}
2025-11-15 13:46:22,603 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:22,628 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:24,258 [INFO] rec_loss: 11.43509578704834, rec_log: {'train/total_loss': tensor(11.4351, device='cuda:0'), 'train/logvar': tensor(0.0062, device='cuda:0'), 'train/kl_loss': tensor(87.6749, device='cuda:0'), 'train/nll_loss': tensor(10.4224, device='cuda:0'), 'train/rec_loss': tensor(0.9728, device='cuda:0'), 'train/perception_loss': tensor(0.7530, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3595, device='cuda:0')}
2025-11-15 13:46:28,212 [INFO] gan_loss : 0.918454647064209,  gan_log: {'train/disc_loss': tensor(0.9185, device='cuda:0'), 'train/logits_real': tensor(-0.0817, device='cuda:0'), 'train/logits_fake': tensor(-1.3595, device='cuda:0')}
2025-11-15 13:46:28,254 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:28,278 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:29,920 [INFO] rec_loss: 14.025911331176758, rec_log: {'train/total_loss': tensor(14.0259, device='cuda:0'), 'train/logvar': tensor(0.0063, device='cuda:0'), 'train/kl_loss': tensor(86.9440, device='cuda:0'), 'train/nll_loss': tensor(13.1147, device='cuda:0'), 'train/rec_loss': tensor(1.2426, device='cuda:0'), 'train/perception_loss': tensor(0.7647, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.4173, device='cuda:0')}
2025-11-15 13:46:33,884 [INFO] gan_loss : 0.9450415372848511,  gan_log: {'train/disc_loss': tensor(0.9450, device='cuda:0'), 'train/logits_real': tensor(0.9642, device='cuda:0'), 'train/logits_fake': tensor(-0.4173, device='cuda:0')}
2025-11-15 13:46:33,925 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:33,953 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:35,589 [INFO] rec_loss: 10.130996704101562, rec_log: {'train/total_loss': tensor(10.1310, device='cuda:0'), 'train/logvar': tensor(0.0063, device='cuda:0'), 'train/kl_loss': tensor(82.0848, device='cuda:0'), 'train/nll_loss': tensor(9.3538, device='cuda:0'), 'train/rec_loss': tensor(0.8623, device='cuda:0'), 'train/perception_loss': tensor(0.7840, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.4361, device='cuda:0')}
2025-11-15 13:46:39,551 [INFO] gan_loss : 1.1121742725372314,  gan_log: {'train/disc_loss': tensor(1.1122, device='cuda:0'), 'train/logits_real': tensor(0.6663, device='cuda:0'), 'train/logits_fake': tensor(0.4361, device='cuda:0')}
2025-11-15 13:46:39,593 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:39,621 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:41,257 [INFO] rec_loss: 12.352343559265137, rec_log: {'train/total_loss': tensor(12.3523, device='cuda:0'), 'train/logvar': tensor(0.0064, device='cuda:0'), 'train/kl_loss': tensor(96.1814, device='cuda:0'), 'train/nll_loss': tensor(11.3064, device='cuda:0'), 'train/rec_loss': tensor(1.0568, device='cuda:0'), 'train/perception_loss': tensor(0.8044, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8414, device='cuda:0')}
2025-11-15 13:46:45,217 [INFO] gan_loss : 0.7551896572113037,  gan_log: {'train/disc_loss': tensor(0.7552, device='cuda:0'), 'train/logits_real': tensor(0.4522, device='cuda:0'), 'train/logits_fake': tensor(-0.8414, device='cuda:0')}
2025-11-15 13:46:45,259 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:45,286 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:46,917 [INFO] rec_loss: 10.122706413269043, rec_log: {'train/total_loss': tensor(10.1227, device='cuda:0'), 'train/logvar': tensor(0.0065, device='cuda:0'), 'train/kl_loss': tensor(77.8791, device='cuda:0'), 'train/nll_loss': tensor(9.2447, device='cuda:0'), 'train/rec_loss': tensor(0.8525, device='cuda:0'), 'train/perception_loss': tensor(0.7729, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.9923, device='cuda:0')}
2025-11-15 13:46:50,879 [INFO] gan_loss : 0.6529532670974731,  gan_log: {'train/disc_loss': tensor(0.6530, device='cuda:0'), 'train/logits_real': tensor(0.4826, device='cuda:0'), 'train/logits_fake': tensor(-0.9923, device='cuda:0')}
2025-11-15 13:46:50,921 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:50,947 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:52,577 [INFO] rec_loss: 9.490269660949707, rec_log: {'train/total_loss': tensor(9.4903, device='cuda:0'), 'train/logvar': tensor(0.0066, device='cuda:0'), 'train/kl_loss': tensor(79.4842, device='cuda:0'), 'train/nll_loss': tensor(8.5604, device='cuda:0'), 'train/rec_loss': tensor(0.7869, device='cuda:0'), 'train/perception_loss': tensor(0.7414, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.3500, device='cuda:0')}
2025-11-15 13:46:56,539 [INFO] gan_loss : 0.6386914253234863,  gan_log: {'train/disc_loss': tensor(0.6387, device='cuda:0'), 'train/logits_real': tensor(0.3437, device='cuda:0'), 'train/logits_fake': tensor(-1.3500, device='cuda:0')}
2025-11-15 13:46:56,581 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:46:56,610 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:46:58,243 [INFO] rec_loss: 13.936572074890137, rec_log: {'train/total_loss': tensor(13.9366, device='cuda:0'), 'train/logvar': tensor(0.0066, device='cuda:0'), 'train/kl_loss': tensor(69.0268, device='cuda:0'), 'train/nll_loss': tensor(13.1611, device='cuda:0'), 'train/rec_loss': tensor(1.2443, device='cuda:0'), 'train/perception_loss': tensor(0.7991, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8516, device='cuda:0')}
2025-11-15 13:47:02,214 [INFO] gan_loss : 0.6915733814239502,  gan_log: {'train/disc_loss': tensor(0.6916, device='cuda:0'), 'train/logits_real': tensor(1.6965, device='cuda:0'), 'train/logits_fake': tensor(-0.8516, device='cuda:0')}
2025-11-15 13:47:02,256 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:47:02,280 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:47:03,913 [INFO] rec_loss: 12.850614547729492, rec_log: {'train/total_loss': tensor(12.8506, device='cuda:0'), 'train/logvar': tensor(0.0067, device='cuda:0'), 'train/kl_loss': tensor(81.9248, device='cuda:0'), 'train/nll_loss': tensor(12.0043, device='cuda:0'), 'train/rec_loss': tensor(1.1226, device='cuda:0'), 'train/perception_loss': tensor(0.8520, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.2704, device='cuda:0')}
2025-11-15 13:47:07,872 [INFO] gan_loss : 0.6839794516563416,  gan_log: {'train/disc_loss': tensor(0.6840, device='cuda:0'), 'train/logits_real': tensor(2.2875, device='cuda:0'), 'train/logits_fake': tensor(-0.2704, device='cuda:0')}
2025-11-15 13:47:07,915 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:47:07,944 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:47:09,582 [INFO] rec_loss: 14.42514705657959, rec_log: {'train/total_loss': tensor(14.4251, device='cuda:0'), 'train/logvar': tensor(0.0068, device='cuda:0'), 'train/kl_loss': tensor(53.0418, device='cuda:0'), 'train/nll_loss': tensor(13.8385, device='cuda:0'), 'train/rec_loss': tensor(1.3161, device='cuda:0'), 'train/perception_loss': tensor(0.7652, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.5623, device='cuda:0')}
2025-11-15 13:47:13,547 [INFO] gan_loss : 0.9325999617576599,  gan_log: {'train/disc_loss': tensor(0.9326, device='cuda:0'), 'train/logits_real': tensor(0.6403, device='cuda:0'), 'train/logits_fake': tensor(-0.5623, device='cuda:0')}
2025-11-15 13:47:13,589 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:47:13,616 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:47:15,249 [INFO] rec_loss: 13.032265663146973, rec_log: {'train/total_loss': tensor(13.0323, device='cuda:0'), 'train/logvar': tensor(0.0069, device='cuda:0'), 'train/kl_loss': tensor(46.8037, device='cuda:0'), 'train/nll_loss': tensor(12.5269, device='cuda:0'), 'train/rec_loss': tensor(1.1794, device='cuda:0'), 'train/perception_loss': tensor(0.8120, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.3732, device='cuda:0')}
2025-11-15 13:47:19,209 [INFO] gan_loss : 0.9166690111160278,  gan_log: {'train/disc_loss': tensor(0.9167, device='cuda:0'), 'train/logits_real': tensor(0.4757, device='cuda:0'), 'train/logits_fake': tensor(-0.3732, device='cuda:0')}
2025-11-15 13:47:19,251 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:47:19,279 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:47:20,918 [INFO] rec_loss: 10.596121788024902, rec_log: {'train/total_loss': tensor(10.5961, device='cuda:0'), 'train/logvar': tensor(0.0069, device='cuda:0'), 'train/kl_loss': tensor(64.8542, device='cuda:0'), 'train/nll_loss': tensor(9.8579, device='cuda:0'), 'train/rec_loss': tensor(0.9128, device='cuda:0'), 'train/perception_loss': tensor(0.7915, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.8971, device='cuda:0')}
2025-11-15 13:47:24,875 [INFO] gan_loss : 1.1330788135528564,  gan_log: {'train/disc_loss': tensor(1.1331, device='cuda:0'), 'train/logits_real': tensor(0.1383, device='cuda:0'), 'train/logits_fake': tensor(-0.8971, device='cuda:0')}
2025-11-15 13:47:24,918 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:47:24,943 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:47:26,583 [INFO] rec_loss: 13.069295883178711, rec_log: {'train/total_loss': tensor(13.0693, device='cuda:0'), 'train/logvar': tensor(0.0070, device='cuda:0'), 'train/kl_loss': tensor(78.7938, device='cuda:0'), 'train/nll_loss': tensor(12.1635, device='cuda:0'), 'train/rec_loss': tensor(1.1480, device='cuda:0'), 'train/perception_loss': tensor(0.7618, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(1.1784, device='cuda:0')}
2025-11-15 13:47:30,540 [INFO] gan_loss : 1.278448462486267,  gan_log: {'train/disc_loss': tensor(1.2784, device='cuda:0'), 'train/logits_real': tensor(-0.7589, device='cuda:0'), 'train/logits_fake': tensor(-1.1784, device='cuda:0')}
2025-11-15 13:47:30,582 [INFO] ----------------------------------------------------------- Iteration
2025-11-15 13:47:30,606 [INFO] what is the batch size >>>>>>>>>>>>>>>>>>: torch.Size([4, 3, 16, 256, 256])
2025-11-15 13:47:32,250 [INFO] rec_loss: 11.028615951538086, rec_log: {'train/total_loss': tensor(11.0286, device='cuda:0'), 'train/logvar': tensor(0.0071, device='cuda:0'), 'train/kl_loss': tensor(102.9265, device='cuda:0'), 'train/nll_loss': tensor(9.9237, device='cuda:0'), 'train/rec_loss': tensor(0.9218, device='cuda:0'), 'train/perception_loss': tensor(0.7687, device='cuda:0'), 'train/d_weight': tensor(0.1000, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7570, device='cuda:0')}
