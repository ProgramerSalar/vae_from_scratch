------------------------------------------- Epoch: [0]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(11.2612, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(11.2612, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(32.9530, device='cuda:0'), 'train/nll_loss': tensor(12.1222, device='cuda:0'), 'train/rec_loss': tensor(1.2134, device='cuda:0'), 'train/perception_loss': tensor(-0.0121, device='cuda:0'), 'train/d_weight': tensor(1.8437, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.4670, device='cuda:0')}
tensor(1.5340, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(1.5340, device='cuda:0'), 'train/logits_real': tensor(0.3818, device='cuda:0'), 'train/logits_fake': tensor(0.4670, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(157.5512, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(157.5512, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(69980.8594, device='cuda:0'), 'train/nll_loss': tensor(59.6579, device='cuda:0'), 'train/rec_loss': tensor(5.9675, device='cuda:0'), 'train/perception_loss': tensor(-0.0170, device='cuda:0'), 'train/d_weight': tensor(28.7337, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.4069, device='cuda:0')}
tensor(8.0374, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(8.0374, device='cuda:0'), 'train/logits_real': tensor(-3.9214, device='cuda:0'), 'train/logits_fake': tensor(-3.4069, device='cuda:0')}
------------------------------------------- Epoch: [1]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(13.0228, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(13.0228, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(1.5433e+09, device='cuda:0'), 'train/nll_loss': tensor(16.8450, device='cuda:0'), 'train/rec_loss': tensor(1.6858, device='cuda:0'), 'train/perception_loss': tensor(-0.0132, device='cuda:0'), 'train/d_weight': tensor(3.1557, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-1.3090, device='cuda:0')}
tensor(4.4134, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(4.4134, device='cuda:0'), 'train/logits_real': tensor(5.3982, device='cuda:0'), 'train/logits_fake': tensor(1.3090, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(13.1341, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(13.1341, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(8.8350e+08, device='cuda:0'), 'train/nll_loss': tensor(11.8431, device='cuda:0'), 'train/rec_loss': tensor(1.1861, device='cuda:0'), 'train/perception_loss': tensor(-0.0180, device='cuda:0'), 'train/d_weight': tensor(0.1136, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(9.0298, device='cuda:0')}
tensor(3.9854, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(3.9854, device='cuda:0'), 'train/logits_real': tensor(1.1781, device='cuda:0'), 'train/logits_fake': tensor(-9.0298, device='cuda:0')}
------------------------------------------- Epoch: [2]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(10.4756, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(10.4756, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(115211.2422, device='cuda:0'), 'train/nll_loss': tensor(10.4872, device='cuda:0'), 'train/rec_loss': tensor(1.0508, device='cuda:0'), 'train/perception_loss': tensor(-0.0211, device='cuda:0'), 'train/d_weight': tensor(0.0196, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.5905, device='cuda:0')}
tensor(2.0843, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(2.0843, device='cuda:0'), 'train/logits_real': tensor(9.8921, device='cuda:0'), 'train/logits_fake': tensor(0.5905, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(10.8182, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(10.8182, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(1006.3967, device='cuda:0'), 'train/nll_loss': tensor(10.8650, device='cuda:0'), 'train/rec_loss': tensor(1.0884, device='cuda:0'), 'train/perception_loss': tensor(-0.0186, device='cuda:0'), 'train/d_weight': tensor(0.0472, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-0.9922, device='cuda:0')}
tensor(2.0027, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(2.0027, device='cuda:0'), 'train/logits_real': tensor(13.4550, device='cuda:0'), 'train/logits_fake': tensor(0.9922, device='cuda:0')}
------------------------------------------- Epoch: [3]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(10.9592, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(10.9592, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(988.2812, device='cuda:0'), 'train/nll_loss': tensor(10.5142, device='cuda:0'), 'train/rec_loss': tensor(1.0530, device='cuda:0'), 'train/perception_loss': tensor(-0.0155, device='cuda:0'), 'train/d_weight': tensor(0.1073, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(4.1480, device='cuda:0')}
tensor(1.0222, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(1.0222, device='cuda:0'), 'train/logits_real': tensor(4.2201, device='cuda:0'), 'train/logits_fake': tensor(-4.1480, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(10.3093, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(10.3093, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(970.1953, device='cuda:0'), 'train/nll_loss': tensor(10.6426, device='cuda:0'), 'train/rec_loss': tensor(1.0661, device='cuda:0'), 'train/perception_loss': tensor(-0.0179, device='cuda:0'), 'train/d_weight': tensor(0.0649, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-5.1350, device='cuda:0')}
------------------------------------------- Epoch: [4]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(18.6269, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(18.6269, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(1028.9293, device='cuda:0'), 'train/nll_loss': tensor(16.3196, device='cuda:0'), 'train/rec_loss': tensor(1.6335, device='cuda:0'), 'train/perception_loss': tensor(-0.0158, device='cuda:0'), 'train/d_weight': tensor(0.6047, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(3.8158, device='cuda:0')}
tensor(1.7971, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(1.7971, device='cuda:0'), 'train/logits_real': tensor(0.4818, device='cuda:0'), 'train/logits_fake': tensor(-3.8158, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(12.3366, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(12.3366, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(1679.8875, device='cuda:0'), 'train/nll_loss': tensor(11.8288, device='cuda:0'), 'train/rec_loss': tensor(1.1843, device='cuda:0'), 'train/perception_loss': tensor(-0.0146, device='cuda:0'), 'train/d_weight': tensor(0.0723, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(7.0284, device='cuda:0')}
tensor(1.3621, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(1.3621, device='cuda:0'), 'train/logits_real': tensor(-0.3024, device='cuda:0'), 'train/logits_fake': tensor(-7.0284, device='cuda:0')}
------------------------------------------- Epoch: [5]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(10.8676, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(10.8676, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(1801.7766, device='cuda:0'), 'train/nll_loss': tensor(11.3193, device='cuda:0'), 'train/rec_loss': tensor(1.1338, device='cuda:0'), 'train/perception_loss': tensor(-0.0191, device='cuda:0'), 'train/d_weight': tensor(0.1886, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-2.3955, device='cuda:0')}
tensor(3.1888, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(3.1888, device='cuda:0'), 'train/logits_real': tensor(0.8583, device='cuda:0'), 'train/logits_fake': tensor(2.3955, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(11.5663, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(11.5663, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(3023.8481, device='cuda:0'), 'train/nll_loss': tensor(11.3270, device='cuda:0'), 'train/rec_loss': tensor(1.1345, device='cuda:0'), 'train/perception_loss': tensor(-0.0181, device='cuda:0'), 'train/d_weight': tensor(0.0816, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(2.9331, device='cuda:0')}
tensor(1.4437, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(1.4437, device='cuda:0'), 'train/logits_real': tensor(-0.8026, device='cuda:0'), 'train/logits_fake': tensor(-2.9331, device='cuda:0')}
------------------------------------------- Epoch: [6]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(12.1018, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(12.1018, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(80871.2500, device='cuda:0'), 'train/nll_loss': tensor(11.4779, device='cuda:0'), 'train/rec_loss': tensor(1.1499, device='cuda:0'), 'train/perception_loss': tensor(-0.0211, device='cuda:0'), 'train/d_weight': tensor(0.1446, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(4.3153, device='cuda:0')}
tensor(0.3803, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(0.3803, device='cuda:0'), 'train/logits_real': tensor(2.8149, device='cuda:0'), 'train/logits_fake': tensor(-4.3153, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(11.4277, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(11.4277, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(4169627., device='cuda:0'), 'train/nll_loss': tensor(11.3941, device='cuda:0'), 'train/rec_loss': tensor(1.1411, device='cuda:0'), 'train/perception_loss': tensor(-0.0171, device='cuda:0'), 'train/d_weight': tensor(0.0377, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(0.7473, device='cuda:0')}
tensor(0.7691, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(0.7691, device='cuda:0'), 'train/logits_real': tensor(4.7734, device='cuda:0'), 'train/logits_fake': tensor(-0.7473, device='cuda:0')}
------------------------------------------- Epoch: [7]
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(10.6057, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(10.6057, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(64214400., device='cuda:0'), 'train/nll_loss': tensor(10.7979, device='cuda:0'), 'train/rec_loss': tensor(1.0814, device='cuda:0'), 'train/perception_loss': tensor(-0.0157, device='cuda:0'), 'train/d_weight': tensor(0.0523, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-5.3964, device='cuda:0')}
tensor(3.3111, device='cuda:0', grad_fn=<MulBackward0>) {'train/disc_loss': tensor(3.3111, device='cuda:0'), 'train/logits_real': tensor(8.4485, device='cuda:0'), 'train/logits_fake': tensor(5.3964, device='cuda:0')}
what is the shape of logits_fake: >>>>>>>>>>> torch.Size([1, 1, 3, 14, 14])
tensor(10.8066, device='cuda:0', grad_fn=<AddBackward0>) {'train/total_loss': tensor(10.8066, device='cuda:0'), 'train/logvar': tensor(0., device='cuda:0'), 'train/kl_loss': tensor(1073486.6250, device='cuda:0'), 'train/nll_loss': tensor(11.3086, device='cuda:0'), 'train/rec_loss': tensor(1.1327, device='cuda:0'), 'train/perception_loss': tensor(-0.0186, device='cuda:0'), 'train/d_weight': tensor(0.0913, device='cuda:0'), 'train/disc_factor': tensor(1.), 'train/g_loss': tensor(-5.5139, device='cuda:0')}




















