{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e6edac",
   "metadata": {},
   "source": [
    "## 0.1 nn.Sequantial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb8ecb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (layer1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (linear_layer): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (1): Linear(in_features=200, out_features=300, bias=True)\n",
       "    (2): Linear(in_features=300, out_features=400, bias=True)\n",
       "    (3): Linear(in_features=400, out_features=500, bias=True)\n",
       "    (4): Linear(in_features=500, out_features=600, bias=True)\n",
       "    (5): Linear(in_features=600, out_features=700, bias=True)\n",
       "    (6): Linear(in_features=700, out_features=800, bias=True)\n",
       "    (7): Linear(in_features=800, out_features=900, bias=True)\n",
       "    (8): Linear(in_features=900, out_features=1000, bias=True)\n",
       "    (9): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                    out_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(in_channels, 2*out_channels),\n",
    "            nn.Linear(2*out_channels, 3*out_channels),\n",
    "            nn.Linear(3*out_channels, 4*out_channels),\n",
    "            nn.Linear(4*out_channels, 5*out_channels),\n",
    "            nn.Linear(5*out_channels, 6*out_channels),\n",
    "            nn.Linear(6*out_channels, 7*out_channels),\n",
    "            nn.Linear(7*out_channels, 8*out_channels),\n",
    "            nn.Linear(8*out_channels,9*out_channels),\n",
    "            nn.Linear(9*out_channels,10*out_channels),\n",
    "            nn.Linear(10*out_channels,10*out_channels),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        torch.utils.checkpoint.checkpoint(\n",
    "            self.linear_layer,\n",
    "            x,\n",
    "            use_reentrant=True\n",
    "        )\n",
    "        # x = self.linear_layer(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel(in_channels=100,\n",
    "                out_channels=100)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d29e2793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.112\n",
      "0.744\n",
      "0.721\n",
      "0.720\n",
      "0.714\n",
      "0.711\n",
      "0.711\n",
      "0.710\n",
      "0.705\n",
      "0.699\n",
      "0.697\n",
      "0.698\n",
      "0.700\n",
      "0.700\n",
      "0.699\n",
      "0.697\n",
      "0.696\n",
      "0.695\n",
      "0.694\n",
      "0.693\n",
      "0.693\n",
      "0.694\n",
      "0.694\n",
      "0.694\n",
      "0.693\n",
      "0.692\n",
      "0.691\n",
      "0.691\n",
      "0.692\n",
      "0.692\n",
      "0.692\n",
      "0.692\n",
      "0.692\n",
      "0.691\n",
      "0.691\n",
      "0.691\n",
      "0.691\n",
      "0.691\n",
      "0.691\n",
      "0.691\n",
      "0.691\n",
      "0.691\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n",
      "0.690\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = torch.randn(100)\n",
    "target = torch.randn(100)\n",
    "# output = model(data)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-2)\n",
    "scaler = torch.amp.GradScaler(device=\"cpu\", enabled=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=\"cpu\", enabled=True):\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        print(f\"{loss.item():.3f}\")\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ee8f6",
   "metadata": {},
   "source": [
    "## 0.2 nn.ModuleList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff5f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 2.3260e-01, 0.0000e+00, 3.1295e-01, 6.2666e-02, 8.1320e-01,\n",
       "        0.0000e+00, 4.5498e-02, 9.0034e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        7.0397e-02, 0.0000e+00, 3.4555e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 6.8577e-01, 2.4133e-01, 2.1677e-02, 1.4320e-01, 1.0488e-01,\n",
       "        9.0700e-02, 0.0000e+00, 2.2227e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.8234e-01, 0.0000e+00, 0.0000e+00, 1.4475e-01, 0.0000e+00,\n",
       "        7.2062e-02, 5.5174e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2355e-02,\n",
       "        3.5442e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6579e-02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3682e-01, 5.5449e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.6910e-01, 0.0000e+00, 7.0966e-02, 3.2540e-02, 0.0000e+00, 0.0000e+00,\n",
       "        4.1872e-01, 0.0000e+00, 0.0000e+00, 4.6128e-01, 2.9216e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 4.7815e-01, 2.2681e-01, 0.0000e+00, 0.0000e+00,\n",
       "        1.2360e-01, 0.0000e+00, 2.3116e-01, 0.0000e+00, 0.0000e+00, 1.5981e-01,\n",
       "        3.4881e-01, 4.5017e-01, 0.0000e+00, 3.0140e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 5.6741e-02, 0.0000e+00, 4.0452e-02, 5.5013e-01,\n",
       "        2.6545e-01, 4.5129e-02, 1.6309e-01, 2.5580e-01, 3.2164e-01, 0.0000e+00,\n",
       "        0.0000e+00, 4.0035e-01, 3.8259e-02, 1.3511e-01, 0.0000e+00, 0.0000e+00,\n",
       "        2.3665e-01, 1.4372e-01, 0.0000e+00, 0.0000e+00, 1.9185e-01, 1.5030e-01,\n",
       "        0.0000e+00, 0.0000e+00, 3.1060e-01, 0.0000e+00, 3.8435e-01, 0.0000e+00,\n",
       "        6.1830e-01, 1.0074e-01, 3.0049e-01, 3.1713e-01, 4.7730e-02, 2.9856e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4265e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.0757e-01, 1.2990e-01, 4.3017e-01, 0.0000e+00,\n",
       "        4.6896e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.8676e-02, 0.0000e+00, 4.0750e-02, 4.8185e-01, 5.3670e-02,\n",
       "        6.2969e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4518e-01, 9.4275e-02,\n",
       "        0.0000e+00, 4.6815e-01, 9.7233e-02, 0.0000e+00, 0.0000e+00, 5.4219e-01,\n",
       "        2.3203e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2562e-01, 8.1086e-01,\n",
       "        0.0000e+00, 0.0000e+00, 3.9153e-01, 0.0000e+00, 4.1933e-01, 1.7220e-01,\n",
       "        2.6678e-01, 3.6529e-02, 1.7526e-01, 3.9137e-02, 0.0000e+00, 8.5747e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6929e-02, 8.5369e-01, 5.3705e-01,\n",
       "        0.0000e+00, 2.5111e-01, 0.0000e+00, 3.4858e-05, 2.8583e-01, 1.3808e-01,\n",
       "        0.0000e+00, 2.3463e-01, 0.0000e+00, 1.2554e-01, 1.7535e-01, 0.0000e+00,\n",
       "        5.0608e-02, 0.0000e+00], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                    out_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(in_channels, 2*out_channels)\n",
    "\n",
    "\n",
    "        self.linear_layers = nn.ModuleList([])\n",
    "        for i in range(3):\n",
    "            \n",
    "            self.linear_layers.append(\n",
    "                nn.Linear(2*out_channels, 2*out_channels),\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        def create_custom_forward(module):\n",
    "            def custom_forward(*inputs):\n",
    "                return module(*inputs)\n",
    "                \n",
    "            return custom_forward\n",
    "\n",
    "        for layer in self.linear_layers:\n",
    "           sample = torch.utils.checkpoint.checkpoint(create_custom_forward(layer),\n",
    "                                                      x,\n",
    "                                                      use_reentrant=False)\n",
    "        \n",
    "        # activation function\n",
    "        x = self.relu(sample)\n",
    "        return x \n",
    "    \n",
    "model = MyModel(in_channels=100,\n",
    "                out_channels=100)\n",
    "\n",
    "x = torch.randn(100)\n",
    "out = model(x)\n",
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a8a9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976\n",
      "0.774\n",
      "0.685\n",
      "0.677\n",
      "0.666\n",
      "0.650\n",
      "0.655\n",
      "0.658\n",
      "0.651\n",
      "0.630\n",
      "0.626\n",
      "0.641\n",
      "0.630\n",
      "0.614\n",
      "0.621\n",
      "0.624\n",
      "0.618\n",
      "0.616\n",
      "0.612\n",
      "0.611\n",
      "0.615\n",
      "0.612\n",
      "0.608\n",
      "0.608\n",
      "0.608\n",
      "0.608\n",
      "0.608\n",
      "0.606\n",
      "0.606\n",
      "0.607\n",
      "0.605\n",
      "0.604\n",
      "0.606\n",
      "0.603\n",
      "0.604\n",
      "0.601\n",
      "0.600\n",
      "0.603\n",
      "0.602\n",
      "0.600\n",
      "0.601\n",
      "0.601\n",
      "0.600\n",
      "0.600\n",
      "0.601\n",
      "0.600\n",
      "0.599\n",
      "0.583\n",
      "0.587\n",
      "0.594\n",
      "0.587\n",
      "0.582\n",
      "0.584\n",
      "0.587\n",
      "0.586\n",
      "0.582\n",
      "0.581\n",
      "0.583\n",
      "0.585\n",
      "0.583\n",
      "0.581\n",
      "0.581\n",
      "0.582\n",
      "0.582\n",
      "0.582\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.580\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.580\n",
      "0.580\n",
      "0.580\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.581\n",
      "0.582\n",
      "0.583\n",
      "0.586\n",
      "0.590\n",
      "0.593\n",
      "0.591\n",
      "0.584\n",
      "0.580\n",
      "0.583\n",
      "0.586\n",
      "0.582\n",
      "0.580\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = torch.randn(100)\n",
    "target = torch.randn(200)\n",
    "# output = model(data)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-2)\n",
    "scaler = torch.amp.GradScaler(device=\"cpu\", enabled=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=\"cpu\", enabled=True):\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        print(f\"{loss.item():.3f}\")\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9f845f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 16, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn \n",
    "import torch \n",
    "\n",
    "conv = nn.Conv3d(in_channels=3,\n",
    "                 out_channels=3,\n",
    "                 kernel_size=3,\n",
    "                 padding=1,\n",
    "                 )\n",
    "\n",
    "x = torch.randn(2, 3, 1, 16, 16)\n",
    "out = conv(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326fb2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 2, 17, 17])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn \n",
    "import torch \n",
    "\n",
    "\n",
    "transpose = nn.ConvTranspose3d(in_channels=3,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=4,\n",
    "                               padding=1)\n",
    "\n",
    "x = torch.randn(2, 3, 1, 16, 16)\n",
    "\n",
    "out = transpose(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e986b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 1, 16, 16)\n",
    "\n",
    "from torch.nn import functional as F \n",
    "\n",
    "model = F.interpolate(input=x,\n",
    "                      scale_factor=(1, 2, 2),\n",
    "                      mode=\"nearest\")\n",
    "\n",
    "model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7f2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000.0\n"
     ]
    }
   ],
   "source": [
    "print(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b057a428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel = [64, 128, 256, 512, 512]\n",
    "len(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb4b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "t = torch.randn(2, 3, 32, 32)\n",
    "\n",
    "total = 0\n",
    "for i in range(5):\n",
    "    # print(sum(t.shape))\n",
    "    out = t\n",
    "    # print(out.shape)\n",
    "    total += out\n",
    "    print(total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4ec4420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "t = torch.randn(2, 3, 32, 32)\n",
    "n = ~torch.isnan(t)\n",
    "n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450d5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5434720",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m), \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i), \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m....\u001b[39m\u001b[38;5;124m\"\u001b[39m, j)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for i, j in range(4), range(5):\n",
    "    print(i), print(\"....\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e587ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.0006e+00, 2.0013e+00,  ..., 1.5710e+03, 1.5720e+03,\n",
       "        1.5730e+03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "# generator = torch.Generator(device='cpu').manual_seed(42)\n",
    "# generator.device.type\n",
    "\n",
    "line = torch.linspace(0, 1573, 1573)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6d39ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n"
     ]
    }
   ],
   "source": [
    "if 1e-5 > 5e-5:\n",
    "    print(\"hello\")\n",
    "elif 1e-5 < 5e-5:\n",
    "    print(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c40ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = max(256/512, 256/512)\n",
    "new_width = round(512 * 0.5)\n",
    "new_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5e49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adopt_weight(weight, global_step, threshold=0, value=0.0):\n",
    "    if global_step < threshold:\n",
    "        weight = value\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3d1b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_factor = adopt_weight(weight=1.0,\n",
    "                           global_step=0,\n",
    "                           threshold=250000)\n",
    "disc_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea71560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 100, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "img1 = (torch.randn(10, 3, 100, 100) * 2) - 1\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bbb3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_  = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6f98d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n",
      "torch.Size([2, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from einops import repeat, reduce\n",
    "\n",
    "\n",
    "x = torch.randn(2, 128, 8, 256, 256)\n",
    "temb = torch.randn(2, 128)\n",
    "\n",
    "t = x.shape[2]\n",
    "temb = repeat(temb, 'b c -> (b t) c', t=t) \n",
    "print(temb.shape)\n",
    "# temb = repeat(temb, '(b t) c -> b c', t=t)\n",
    "temb = reduce(temb, '(b t) c -> b c', t=t, reduction=\"max\")\n",
    "print(temb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c855ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels,\n",
    "                 out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=0),\n",
    "        \n",
    "            nn.GroupNorm(num_groups=2,\n",
    "                                    num_channels=in_channels),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(in_channels=out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=3,\n",
    "                    ),\n",
    "            nn.GroupNorm(num_groups=2,\n",
    "                        num_channels=out_channels),\n",
    "            nn.ReLU()\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        print(f\"what is the dtype: {x.dtype}\")\n",
    "        return x \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e23c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manish/anaconda3/envs/cuda121/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/manish/anaconda3/envs/cuda121/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the dtype: torch.float32\n",
      "loss: 1.4965813159942627 and dtype: torch.float32\n",
      "what is the dtype: torch.float32\n",
      "loss: 1.3918112516403198 and dtype: torch.float32\n",
      "what is the dtype: torch.float32\n",
      "loss: 1.3645098209381104 and dtype: torch.float32\n",
      "what is the dtype: torch.float32\n",
      "loss: 1.3362582921981812 and dtype: torch.float32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optim)\n\u001b[1;32m     18\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda121/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda121/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda121/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model(in_channels=128,\n",
    "              out_channels=128).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(params=model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "x = torch.randn(2, 128, 8, 256, 256, requires_grad=True).to(device)\n",
    "target = torch.randn(2, 128, 4, 252, 252, requires_grad=True).to(device)\n",
    "scaler = torch.GradScaler(device=\"cuda\")\n",
    "\n",
    "for epoch in range(100):\n",
    "    optim.zero_grad()\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, target)\n",
    "        print(f\"loss: {loss} and dtype: {loss.dtype}\")\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optim)\n",
    "    scaler.update()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6beb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
