{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0cf0d1",
   "metadata": {},
   "source": [
    "# 0.1  collections.deque()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de5a0a",
   "metadata": {},
   "source": [
    "`deque` (pronounced \"deck\") stands for \"double-ended queue.\" It's a generalization of a stack and a queue, allowing you to add and remove elements from both ends. In Python, `deque` is part of the `collections` module.\n",
    "\n",
    "Here's a breakdown of what it is, where it's used, and why you might use it:\n",
    "\n",
    "### What is `deque`?\n",
    "\n",
    "Think of a regular list or array. If you want to add or remove an element from the beginning of a large list, all subsequent elements need to be shifted, which can be inefficient (O(n) time complexity).\n",
    "\n",
    "A `deque`, on the other hand, is implemented using a doubly linked list. This means that adding or removing elements from *either* end (the \"left\" or \"right\") is an extremely efficient operation, typically taking constant time (O(1)).\n",
    "\n",
    "**Key characteristics:**\n",
    "\n",
    "  * **Appends/Pops from both ends:** You can add elements to the left (`appendleft()`) or right (`append()`), and remove elements from the left (`popleft()`) or right (`pop()`).\n",
    "  * **Efficient:** O(1) time complexity for appending and popping from either end.\n",
    "  * **Iterable:** You can iterate over a `deque` just like a list.\n",
    "  * **Fixed-size (optional):** You can create a `deque` with a `maxlen` argument, which will automatically discard elements from the opposite end when new elements are added, maintaining a fixed size.\n",
    "\n",
    "### Where is `deque` used?\n",
    "\n",
    "`deque` is particularly useful in scenarios where you need efficient additions and removals from both ends of a sequence. Common use cases include:\n",
    "\n",
    "1.  **Implementing Queues and Stacks:**\n",
    "\n",
    "      * **Queue (FIFO - First-In, First-Out):** You can use `append()` to add to one end and `popleft()` to remove from the other. This is more efficient than using a standard list for a queue, where `pop(0)` is slow.\n",
    "      * **Stack (LIFO - Last-In, First-Out):** You can use `append()` to push onto the stack and `pop()` to pop from the stack. While a list is also efficient for a stack (`append()` and `pop()` are O(1)), `deque` offers the flexibility of also being a queue.\n",
    "\n",
    "2.  **Breadth-First Search (BFS) in Graphs and Trees:**\n",
    "\n",
    "      * BFS algorithms explore a graph level by level. A `deque` is ideal for storing the nodes to visit, as you add new neighbors to one end and process nodes from the other.\n",
    "\n",
    "3.  **Recent History or Log Files:**\n",
    "\n",
    "      * If you need to keep track of the last N items (e.g., last 10 commands, last 5 search queries), a `deque` with a `maxlen` is perfect. When a new item is added, the oldest item is automatically discarded.\n",
    "\n",
    "4.  **Sliding Window Problems:**\n",
    "\n",
    "      * In algorithms that involve a \"sliding window\" over a sequence (e.g., finding the maximum in a sliding window), a `deque` can efficiently store and manage elements within that window.\n",
    "\n",
    "5.  **Undo/Redo Functionality:**\n",
    "\n",
    "      * You can use two deques (one for undo, one for redo) to manage actions that can be reversed and then reapplied.\n",
    "\n",
    "6.  **Producer-Consumer Scenarios:**\n",
    "\n",
    "      * When one part of your program produces data and another consumes it, a `deque` can act as a thread-safe buffer (though in multi-threaded contexts, you'd typically use `queue.Queue` for thread safety, which often uses a `deque` internally).\n",
    "\n",
    "### Why use `deque`?\n",
    "\n",
    "You should use `deque` when:\n",
    "\n",
    "1.  **Performance is critical for appends/pops from both ends:** If your operations primarily involve adding or removing elements from the beginning or end of a sequence, `deque` will significantly outperform a standard Python list.\n",
    "\n",
    "      * **List `insert(0, item)` and `pop(0)` are O(n).**\n",
    "      * **`deque` `appendleft()` and `popleft()` are O(1).**\n",
    "      * **List `append()` and `pop()` are O(1).**\n",
    "      * **`deque` `append()` and `pop()` are O(1).**\n",
    "\n",
    "2.  **You need a fixed-size collection that automatically discards old items:** The `maxlen` argument is a very convenient feature for managing limited-size historical data.\n",
    "\n",
    "3.  **You are implementing algorithms that naturally fit the double-ended queue pattern:** As seen in BFS, sliding windows, and undo/redo systems.\n",
    "\n",
    "**Example of `deque` usage:**\n",
    "\n",
    "```python\n",
    "from collections import deque\n",
    "\n",
    "# Basic deque\n",
    "d = deque()\n",
    "d.append('a')\n",
    "d.append('b')\n",
    "d.appendleft('c')\n",
    "print(d)  # deque(['c', 'a', 'b'])\n",
    "\n",
    "d.pop()\n",
    "print(d)  # deque(['c', 'a'])\n",
    "\n",
    "d.popleft()\n",
    "print(d)  # deque(['a'])\n",
    "\n",
    "# Deque with a maximum length\n",
    "history = deque(maxlen=3)\n",
    "history.append('search 1')\n",
    "history.append('search 2')\n",
    "history.append('search 3')\n",
    "print(history)  # deque(['search 1', 'search 2', 'search 3'])\n",
    "\n",
    "history.append('search 4')\n",
    "print(history)  # deque(['search 2', 'search 3', 'search 4'])\n",
    "# 'search 1' was automatically discarded\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82676b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G\n",
      "H\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "# make a new deque with three items \n",
    "d = deque('ghi')\n",
    "\n",
    "for element in d:\n",
    "    print(element.upper())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5c5619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque(['g', 'h', 'i'])\n",
      "deque(['g', 'h', 'i'])\n"
     ]
    }
   ],
   "source": [
    "# add a new entry to the right side \n",
    "d.append('j')\n",
    "\n",
    "# add new entry to the left side \n",
    "d.appendleft('f')\n",
    "\n",
    "\n",
    "# remvoe the right item \n",
    "d.pop()\n",
    "\n",
    "# remove the lift item \n",
    "d.popleft()\n",
    "\n",
    "\n",
    "# list the content from the deque \n",
    "list(d)\n",
    "\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46bb59",
   "metadata": {},
   "source": [
    "# 0.2 unitest\n",
    "\n",
    "you can run this function in in the <u>test.py</u> file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "class TestStringMethods(unittest.TestCase):\n",
    "\n",
    "    def test_upper(self):\n",
    "        self.assertEqual('foo'.upper(), 'FOO')\n",
    "\n",
    "    def test_isupper(self):\n",
    "        self.assertTrue('FOO'.isupper())\n",
    "        self.assertFalse('Foo'.isupper())\n",
    "\n",
    "    def test_split(self):\n",
    "        s = 'hello world'\n",
    "        self.assertEqual(s.split(), ['hello', 'world'])\n",
    "        # check that s.split fails when the seqperator is not string \n",
    "        with self.assertRaises(TypeError):\n",
    "            s.split(2)\n",
    "\n",
    "\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c38db",
   "metadata": {},
   "source": [
    "# 0.3 torch.distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016bbc3",
   "metadata": {},
   "source": [
    "## [A] torch.distributed.is_available()\n",
    "- This `torch.distributed.is_available` package which is essential for parallel and distributed computing, is available on the current system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91db7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.distributed package is available on this system.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "if torch.distributed.is_available():\n",
    "    print(\"torch.distributed package is available on this system.\")\n",
    "\n",
    "else:\n",
    "    print(\"The torch.distributed package Don't available on this system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bfe77b",
   "metadata": {},
   "source": [
    "## [B] torch.distributed.is_initialization()\n",
    "\n",
    "- The `torch.distributed.is_initialization()` function is a crucial check in PyTorch for distributed training.\n",
    "- It returns `True` if the default distributed process group has been initialized and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d441e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.distributed as dist \n",
    "import os \n",
    "\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    \"\"\" \n",
    "    Initializes the distributed environment.\n",
    "    \"\"\"\n",
    "\n",
    "    # set the MASTER_ADDR and MASTER_PORT environment variables \n",
    "    # This is a common way to set up the communication\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # Initialize the process group with a backend (e.g. 'gloo' for CPU)\n",
    "    dist.init_process_group(backend='gloo',\n",
    "                            rank=rank,\n",
    "                            world_size=world_size)\n",
    "    \n",
    "\n",
    "def cleanup():\n",
    "\n",
    "    \"\"\"Destroys the distributed process group.\"\"\"\n",
    "\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "def run_distributed_job(rank,\n",
    "                        world_size):\n",
    "    \n",
    "    print(f\"Rank {rank}: Checking if distributed is initialized...\")\n",
    "    # This will be False before the setup function is called \n",
    "    print(f\"Rank {rank}: Initialized status before setup: {dist.is_initialized()}\")\n",
    "\n",
    "    # Now that the process group is initialized, we can perform distributed operation:\n",
    "    # for example, a simple All-Reduce to sum tensors across all processes \n",
    "    tensor = torch.tensor([float(rank)]) # Each process has a different value \n",
    "    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n",
    "\n",
    "    print(f\"Rank {rank}: After all_reduce, the tensor value is {tensor.item()}\")\n",
    "\n",
    "    cleanup()\n",
    "    print(f\"Rank {rank}: Initialized status after cleanup: {dist.is_initialized()}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    world_size = 2 \n",
    "    print(\"A proper run would look like: `torchrun --nproc_per_node=2 your_script.py`\")\n",
    "\n",
    "    try:\n",
    "        dist.init_process_group('gloo', rank=0, world_size=1)\n",
    "        print(\"Example with a single process:\")\n",
    "        print(f\"Is distributed initialized ? {dist.is_initialized()}\")\n",
    "        dist.destroy_process_group()\n",
    "        print(f\"Is distributed initialized after cleanup ? {dist.is_initialized()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42d5600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 16, 512, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 32, 16, 512, 512)\n",
    "temb = torch.randn(2, 512)\n",
    "\n",
    "x_temb = temb[:, None, None, None, :]\n",
    "output = x + x_temb\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb26fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (512) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m temb \u001b[38;5;241m=\u001b[39m temb[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# output = x * (1 + temb) + temb\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# [2, 32, 8, 512, ]\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m output1 \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m output1\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (512) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "x = x = torch.randn(2, 32, 8, 512, 512)\n",
    "temb = torch.randn(2, 32)\n",
    "temb = temb[:, :, None, None]\n",
    "\n",
    "# output = x * (1 + temb) + temb\n",
    "\n",
    "# [2, 32, 8, 512, 512] * [2, 32, 1, 1]\n",
    "output1 = x * (1 + temb)\n",
    "output1.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91275b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
