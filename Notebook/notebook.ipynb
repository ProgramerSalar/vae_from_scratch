{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c9e4c4",
   "metadata": {},
   "source": [
    "# 1. dummy time_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccad48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0657, -0.2787, -1.2110,  ...,  0.5981, -0.5768, -0.5393],\n",
       "        [ 1.1917, -0.1065,  1.9694,  ..., -0.1435, -1.1355, -0.3291]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "\n",
    "# (batch_size, tembedding_channels)\n",
    "temb = torch.randn(2, 512)\n",
    "temb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f46e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 1, 1, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,) * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c5f08",
   "metadata": {},
   "source": [
    "# 2. AdaGroupNorm\n",
    "\n",
    "`for - images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf18cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaGroupNorm(\n",
      "  (linear): Linear(in_features=6, out_features=12, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.models.normalization import AdaGroupNorm\n",
    "import torch \n",
    "\n",
    "# in_channels = 3\n",
    "out_channels = 6\n",
    "temb_channels = 6\n",
    "\n",
    "x = torch.randn(2, out_channels,  64, 64)\n",
    "temb = torch.randn(2, temb_channels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ada_group_normalization = AdaGroupNorm(embedding_dim=temb_channels,   # make sure in `embedding_dim` to put the `time_embedding` that is 256 in here.\n",
    "                                       out_dim=out_channels,\n",
    "                                       num_groups=2,\n",
    "                                       eps=1e-6)\n",
    "\n",
    "print(ada_group_normalization)\n",
    "\n",
    "ada_group_normalization = ada_group_normalization(x, temb)\n",
    "ada_group_normalization.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5889f",
   "metadata": {},
   "source": [
    "`for - video`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01205bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaGroupNorm(\n",
      "  (linear): Linear(in_features=8, out_features=128, bias=True)\n",
      ")\n",
      "what is the shape of row data: torch.Size([16, 64, 64, 64]) and what is the shape of scale: torch.Size([16, 64, 1, 1]) and what is the shape of shift: torch.Size([16, 64, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 64, 64, 64])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.models.normalization import AdaGroupNorm\n",
    "import torch \n",
    "\n",
    "in_channels = 3\n",
    "out_channels = 64\n",
    "temb_channels = 8\n",
    "batch_size = 2\n",
    "frame = 8 \n",
    "\n",
    "batch_frame = batch_size * frame\n",
    "\n",
    "# video_x = torch.randn(batch_size, out_channels, frame,  64, 64)\n",
    "image_x = torch.randn(batch_frame, out_channels, 64, 64) # so the total image = 2 * 8 => 16 images\n",
    "temb = torch.randn(batch_frame, temb_channels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ada_group_normalization = AdaGroupNorm(embedding_dim=temb_channels,   # make sure in `embedding_dim` to put the `time_embedding` that is 256 in here.\n",
    "                                       out_dim=out_channels,\n",
    "                                       num_groups=batch_size,\n",
    "                                       eps=1e-6)\n",
    "\n",
    "print(ada_group_normalization)\n",
    "\n",
    "ada_group_normalization = ada_group_normalization(image_x, temb)\n",
    "ada_group_normalization.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e6d1a1",
   "metadata": {},
   "source": [
    "# 3. SpatialNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.nn import functional as F \n",
    "\n",
    "class SpatialNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatially conditioned normalization as defined in https://arxiv.org/abs/2209.09002.\n",
    "\n",
    "    Args:\n",
    "        f_channels (`int`):\n",
    "            The number of channels for input to group normalization layer, and output of the spatial norm layer.\n",
    "        zq_channels (`int`):\n",
    "            The number of channels for the quantized vector as described in the paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        f_channels: int,\n",
    "        zq_channels: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm_layer = nn.GroupNorm(num_channels=f_channels, num_groups=32, eps=1e-6, affine=True)\n",
    "        self.conv_y = nn.Conv2d(zq_channels, f_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_b = nn.Conv2d(zq_channels, f_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, f: torch.Tensor, zq: torch.Tensor) -> torch.Tensor:\n",
    "        f_size = f.shape[-2:] \n",
    "        zq = F.interpolate(zq, size=f_size, mode=\"nearest\")\n",
    "        norm_f = self.norm_layer(f)\n",
    "        new_f = norm_f * self.conv_y(zq) + self.conv_b(zq)\n",
    "        return new_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021a094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatialNorm(\n",
      "  (norm_layer): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "  (conv_y): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_b): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "what is the shape of f : torch.Size([2, 128, 64, 64]) and zq: torch.Size([2, 16, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 64, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_channels = 64\n",
    "zq_channels = 8\n",
    "\n",
    "spatial_norm = SpatialNorm(f_channels=128,\n",
    "                           zq_channels=16)\n",
    "\n",
    "print(spatial_norm)\n",
    "\n",
    "# feature map \n",
    "x = torch.randn(2, 128, 64, 64)\n",
    "# quantized vector \n",
    "z = torch.randn(2, 16, 8, 8)\n",
    "\n",
    "spatial_norm = spatial_norm(x, z)\n",
    "spatial_norm.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280eea31",
   "metadata": {},
   "source": [
    "# 4. torch.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a0bfe",
   "metadata": {},
   "source": [
    "#### `mode: 'nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58fe52a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 1024, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# x = torch.rand(1, 1, 2, 2)\n",
    "x = torch.rand(32, 3, 256, 256)\n",
    "\n",
    "nearest_interpolate = F.interpolate(x, \n",
    "                                #  size=(64, 64),\n",
    "                                scale_factor=(4, 4),\n",
    "                                 mode='nearest')\n",
    "nearest_interpolate.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65704c",
   "metadata": {},
   "source": [
    "#### `mode: 'Linear'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35fafaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size = 32, channels=3, length=4\n",
    "x_linear = torch.randn(32, 3, 4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "linear_interpolate = F.interpolate(x_linear,\n",
    "                                   size=8,\n",
    "                                   mode='linear',\n",
    "                                   align_corners=False  # a/c to pytorch library\n",
    "                                   )\n",
    "\n",
    "linear_interpolate.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a319f7",
   "metadata": {},
   "source": [
    "#### `mode: 'BiLinear'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67bac6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bilinear_interpolate = F.interpolate(x,\n",
    "                                     size=(64, 64),\n",
    "                                     mode='bilinear')\n",
    "bilinear_interpolate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea34d7",
   "metadata": {},
   "source": [
    "# 5. conv 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa48f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural_Network(\n",
      "  (norm1): GroupNorm(2, 16, eps=1e-06, affine=True)\n",
      "  (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 8, 256, 256])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "class Neural_Network(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Union[int, Tuple[int, int, int]] = 3,\n",
    "                 stride: Union[int, Tuple[int, int, int]] = 1,\n",
    "                 group: Optional[int] = 32,\n",
    "                 dilation: Optional[int] = 1,\n",
    "                 padding: Optional[int] = 1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.norm1 = nn.GroupNorm(num_groups=group,\n",
    "                             num_channels=in_channels,\n",
    "                             eps=1e-6)\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=stride,\n",
    "                          padding=padding,\n",
    "                          dilation=dilation)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.norm1(x)\n",
    "        x = self.conv1(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "x = torch.randn(2, 16, 8, 256, 256)\n",
    "\n",
    "neural_network = Neural_Network(in_channels=16,\n",
    "                                out_channels=16,\n",
    "                                group=2)\n",
    "\n",
    "print(neural_network)\n",
    "\n",
    "output = neural_network(x)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319d5cb",
   "metadata": {},
   "source": [
    "# 6. if add the two different dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2adb5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.randn(2, 16, 32, 32)\n",
    "temb = torch.rand(2, 16)\n",
    "\n",
    "temb = temb[:, :, None, None]\n",
    "\n",
    "\n",
    "\n",
    "add = x + temb\n",
    "add.shape  # [2, 16, 32, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c775e05",
   "metadata": {},
   "source": [
    "# 7. torch.chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21e944a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128]), torch.Size([2, 128]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "temb = torch.randn(2, 256)\n",
    "\n",
    "a, b = torch.chunk(temb,\n",
    "                         chunks=2,\n",
    "                         dim=1)\n",
    "\n",
    "a.shape, b.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1fb373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 8, 68, 68])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.randn(2, 32, 8, 68, 68)\n",
    "\n",
    "conv = torch.nn.Conv3d(in_channels=32,\n",
    "                       out_channels=64,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=1,\n",
    "                        dilation=1,\n",
    "                        groups=2)\n",
    "\n",
    "conv = conv(x)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3e3e8",
   "metadata": {},
   "source": [
    "# 8. what is the meaning Pixelshuffle() and PixelUnshuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa253ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 512, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "\n",
    "x = torch.randn(2, 4, 256, 256) # output = [2, 1, 512, 512]\n",
    "x = torch.randn(2, 8, 256, 256) # output = [2, 2, 512, 512]\n",
    "\n",
    "# make sure the `input_channels` is square of `upscale_factor` \n",
    "# out_channels = in_channels / upscaling^2, height, width * upscaling  \n",
    "pixel_shuffle = torch.nn.PixelShuffle(2) # upscale the channels \n",
    "output = pixel_shuffle(x)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d3860",
   "metadata": {},
   "source": [
    "in_channels = 4 \n",
    "upscaling = 2*2 = 4 \n",
    "\n",
    "out_channels = in_channels / upscaling\n",
    "out_channels = 4 / 4 = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b83a31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 128, 128])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.randn(2, 4, 256, 256)\n",
    "\n",
    "# out_channels = in_channels * downscale^2, height, width / downscale \n",
    "pixel_unshuffle = torch.nn.PixelUnshuffle(2)\n",
    "output = pixel_unshuffle(x)\n",
    "output.shape # [2, 1, 128, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6060e2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_output = (64,)\n",
    "block_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a6dd4",
   "metadata": {},
   "source": [
    "# 9. torch.layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a4c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tensor = torch.randn(2, 3)\n",
    "tensor.layout\n",
    "\n",
    "converted_shape = tensor.t().stride()\n",
    "converted_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e028e",
   "metadata": {},
   "source": [
    "# 10. torch.generator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99156774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8784880626046803224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "generator = torch.Generator(device=device)\n",
    "generator.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fadbedf",
   "metadata": {},
   "source": [
    "# 11. diffusers.register_to_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831fb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.configuration_utils import register_to_config, ConfigMixin\n",
    "\n",
    "class vae_Config(ConfigMixin):\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(self,\n",
    "                 model_name=\"bert\",\n",
    "                 hidden_size=768,\n",
    "                 num_layers=12,\n",
    "                 temporary_param=None,\n",
    "                 _private_param=None):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.temporary_param = temporary_param\n",
    "        self._private_param = _private_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vae_Config {\n",
       "  \"_class_name\": \"vae_Config\",\n",
       "  \"_diffusers_version\": \"0.33.1\",\n",
       "  \"_private_param\": null,\n",
       "  \"hidden_size\": 768,\n",
       "  \"model_name\": \"bert\",\n",
       "  \"num_layers\": 12,\n",
       "  \"temporary_param\": null\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_Config.config_name = \"vae_Config\"\n",
    "model_config = vae_Config()\n",
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352873c",
   "metadata": {},
   "source": [
    "## 12. nn.register_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d218b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.register_buffer('tensor1', torch.tensor([0.2, 0.3, 0.4])[None, :, None, None])\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        return self.tensor2\n",
    "    \n",
    "\n",
    "a = Test()\n",
    "a = a()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa305ef",
   "metadata": {},
   "source": [
    "## 13. torchvision.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4066a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "vgg_16 = models.vgg16().features\n",
    "vgg_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1583567e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 256, 256])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from collections import namedtuple\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class Vgg16(nn.Module):\n",
    "    def __init__(self,\n",
    "                 requires_grad=False,\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        vgg_pretrained_features = models.vgg16().features\n",
    "        self.slice1 = nn.Sequential()\n",
    "        self.slice2 = nn.Sequential()\n",
    "        self.slice3 = nn.Sequential()\n",
    "        self.slice4 = nn.Sequential()\n",
    "        self.slice5 = nn.Sequential()\n",
    "        \n",
    "        \n",
    "        for i in range(4): \n",
    "            self.slice1.add_module(name=str(i), module=vgg_pretrained_features[i]) \n",
    "        for i in range(4, 9): \n",
    "            self.slice2.add_module(name=str(i), module=vgg_pretrained_features[i])\n",
    "        for i in range(9, 16):  \n",
    "            self.slice3.add_module(name=str(i), module=vgg_pretrained_features[i])\n",
    "        for i in range(16, 23):  \n",
    "            self.slice4.add_module(name=str(i), module=vgg_pretrained_features[i])\n",
    "        for i in range(23, 30):  \n",
    "            self.slice5.add_module(name=str(i), module=vgg_pretrained_features[i])\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.slice1(x)\n",
    "        h2 = self.slice2(h1)\n",
    "        h3 = self.slice3(h2)\n",
    "        h4 = self.slice4(h3)\n",
    "        h5 = self.slice5(h4)\n",
    "\n",
    "        vgg_outputs = namedtuple(typename=\"VggOutputs\", field_names=['h1', 'h2', 'h3', 'h4', 'h5'])\n",
    "        out = vgg_outputs(h1, h2, h3, h4, h5)\n",
    "\n",
    "        return out \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "out = Vgg16()\n",
    "x = torch.randn(2, 3, 256, 256)\n",
    "out = out(x)\n",
    "out.h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetLinLayer(nn.Module):\n",
    "    \"\"\"A single linear layer which does a 1x1 conv.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels: int = 1,\n",
    "                 use_dropout: bool = False):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential([\n",
    "            nn.Dropout(),\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=out_channels,\n",
    "                      kernel_size=1,\n",
    "                      stride=1,\n",
    "                      padding=0,\n",
    "                      bias=False)\n",
    "        ])\n",
    "\n",
    "out = NetLinLayer(in_channels=3)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "760fe177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor([1.])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n",
      "tensor([[[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "           [1., 1., 1.,  ..., 1., 1., 1.]]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.ones(())) # zero dim \n",
    "print(torch.ones(1)) # one dim \n",
    "print(torch.ones(2, 2)) # two dim \n",
    "print(torch.ones(2, 2, 2))  # three dim\n",
    "print(torch.ones(2, 3, 128, 128))   # four dim\n",
    "print(torch.ones(2, 3, 4, 128, 128))   # five dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0c667",
   "metadata": {},
   "source": [
    "## 15. init distributed mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e3b87",
   "metadata": {},
   "source": [
    "Of course. This Python code is designed to set up a distributed computing environment, specifically for situations where the script is launched using Open MPI (a common framework for parallel computing). It acts as a compatibility layer, translating Open MPI's environment variables into a format that a different library, likely PyTorch Distributed, expects.\n",
    "\n",
    "However, there appears to be a **critical bug** in the code you provided.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Code Explanation\n",
    "\n",
    "The primary goal is to detect if the program is running in a multi-process, multi-machine setup managed by Open MPI and then configure it accordingly.\n",
    "\n",
    "1.  **Detecting the Open MPI Environment**\n",
    "\n",
    "    ```python\n",
    "    if int(os.getenv('OMPI_COMM_WORLD_SIZE', '0')) > 0:\n",
    "    ```\n",
    "\n",
    "      * This line checks for an environment variable named `OMPI_COMM_WORLD_SIZE`.\n",
    "      * When you launch a program with Open MPI's `mpirun`, it automatically sets this variable to the total number of processes you requested. For example, `mpirun -np 8 ...` would set it to `'8'`.\n",
    "      * `os.getenv(..., '0')` safely gets the value, defaulting to `'0'` if it doesn't exist.\n",
    "      * The `if` condition is true only if the script is launched by Open MPI with more than one process.\n",
    "\n",
    "2.  **Reading Open MPI Variables**\n",
    "\n",
    "    ```python\n",
    "    rank = int(os.environ['OMPI_COMM_WORLD_RANK'])\n",
    "    local_rank = int(os.environ['OMPI_COMM_WORLD_LOCAL_RANK'])\n",
    "    world_size = int(os.environ['OMPI_COMM_WORLD_SIZE'])\n",
    "    ```\n",
    "\n",
    "    If the code is in an Open MPI environment, it reads these key variables:\n",
    "\n",
    "      * `OMPI_COMM_WORLD_SIZE`: The **world size**, or the total number of processes in the job.\n",
    "      * `OMPI_COMM_WORLD_RANK`: The **global rank**, a unique ID for the current process, from `0` to `world_size - 1`.\n",
    "      * `OMPI_COMM_WORLD_LOCAL_RANK`: The **local rank**, which is the process's unique ID *on its specific machine*. This is crucial for assigning one GPU per process on a multi-GPU server.\n",
    "\n",
    "3.  **Mapping to Standard Variables (with a Bug)**\n",
    "\n",
    "    ```python\n",
    "    # This block contains an error\n",
    "    os.environ[\"LOCAL_RANK\"] = os.environ['OMPI_COMM_WORLD_LOCAL_RANK']\n",
    "    os.environ[\"RANK\"] = os.environ['OMPI_COMM_WORLD_SIZE']\n",
    "    os.environ[\"WORLD_SIZE\"] = os.environ['OMPI_COMM_WORLD_RANK']\n",
    "    ```\n",
    "\n",
    "    This section tries to create the standard environment variables (`LOCAL_RANK`, `RANK`, `WORLD_SIZE`) that frameworks like PyTorch Distributed use for auto-configuration.\n",
    "\n",
    "      * `LOCAL_RANK` is set correctly.\n",
    "      * **BUG:** `RANK` and `WORLD_SIZE` are swapped. The global rank is being set to the world size, and the world size is being set to the global rank. This will cause the distributed setup to fail.\n",
    "\n",
    "4.  **Setting Program Arguments**\n",
    "\n",
    "    ```python\n",
    "    args.rank = int(os.environ[\"RANK\"])\n",
    "    args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
    "    ```\n",
    "\n",
    "    Finally, it populates an `args` object (likely from `argparse`) with these values so the rest of the application can easily use them, for instance, to assign the correct GPU to the process.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# The Corrected Code\n",
    "\n",
    "To fix the bug, you need to swap the assignments for `RANK` and `WORLD_SIZE`.\n",
    "\n",
    "```python\n",
    "# Corrected version\n",
    "if int(os.getenv('OMPI_COMM_WORLD_SIZE', '0')) > 0:\n",
    "\n",
    "    # Set the standard variables correctly\n",
    "    os.environ[\"LOCAL_RANK\"] = os.environ['OMPI_COMM_WORLD_LOCAL_RANK']\n",
    "    os.environ[\"RANK\"] = os.environ['OMPI_COMM_WORLD_RANK']          # Corrected\n",
    "    os.environ[\"WORLD_SIZE\"] = os.environ['OMPI_COMM_WORLD_SIZE']      # Corrected\n",
    "\n",
    "    # Populate the args object from the newly set variables\n",
    "    args.rank = int(os.environ[\"RANK\"])\n",
    "    args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
    "```\n",
    "\n",
    "In short, this code is a bridge that allows a program expecting PyTorch's distributed environment to be launched using Open MPI's `mpirun` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ce5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import argparse as args\n",
    "\n",
    "if int(os.getenv('OMPI_COMM_WORLD_SIZE', '0')) > 0:\n",
    "    rank = int(os.environ['OMPI_COMM_WORLD_RANK'])\n",
    "    local_rank = int(os.environ['OMPI_COMM_WORLD_LOCAL_RANK'])\n",
    "    world_size = int(os.environ['OMPI_COMM_WORLD_SIZE'])\n",
    "\n",
    "    os.environ[\"LOCAL_RANK\"] = os.environ['OMPI_COMM_WORLD_LOCAL_RANK']\n",
    "    os.environ[\"RANK\"] = os.environ['OMPI_COMM_WORLD_RANK']\n",
    "    os.environ[\"WORLD_SIZE\"] = os.environ['OMPI_COMM_WORLD_SIZE']\n",
    "\n",
    "    args.rank = int(os.environ[\"RANK\"])\n",
    "    args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
    "\n",
    "elif 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n",
    "    args.rank = int(os.environ[\"RANK\"])\n",
    "    args.world_size = int(os.environ['WORLD_SIZE'])\n",
    "    args.gpu = int(os.environ['LOCAL_RANK'])\n",
    "\n",
    "else:\n",
    "    print('Not using distributed mode')\n",
    "    args.distributed = False\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819483f",
   "metadata": {},
   "source": [
    "This code configures the settings for a distributed training session, most commonly used in a framework like PyTorch. Each line sets a specific parameter for how multiple processes (running on different GPUs or machines) should coordinate.\n",
    "\n",
    "---\n",
    "\n",
    "### ## `args.distributed = True`\n",
    "\n",
    "This is a simple boolean flag that **enables distributed mode**. üö©\n",
    "\n",
    "Your training script will likely have `if` statements that check this flag. If it's `True`, the script will execute code to set up communication between processes. If `False`, it will run as a standard, single-process program.\n",
    "\n",
    "---\n",
    "\n",
    "### ## `args.dist_backend = 'nccl'`\n",
    "\n",
    "This line sets the **communication backend** to `'nccl'`.\n",
    "\n",
    "The backend is the underlying library that manages how data (like gradients and model weights) is sent between your GPUs.\n",
    "\n",
    "* **`nccl`** stands for the **NVIDIA Collective Communications Library**. It is a highly optimized library for communication between NVIDIA GPUs. It's the standard and fastest choice for multi-GPU training on NVIDIA hardware. Other options exist, like `gloo` (for CPUs) or `mpi`, but `nccl` is preferred for deep learning with CUDA.\n",
    "\n",
    "---\n",
    "\n",
    "### ## `args.dist_url = \"env://\"`\n",
    "\n",
    "This line tells the program **how to find the other processes** to form a communication group.\n",
    "\n",
    "The `\"env://\"` method instructs the program to initialize itself by reading connection details from the **environment variables**. This is the most common and flexible approach because a launch utility like PyTorch's `torchrun` will automatically set the required variables (`MASTER_ADDR`, `MASTER_PORT`, `RANK`, and `WORLD_SIZE`) for each process it starts. This way, you don't have to hardcode IP addresses or other machine-specific details into your script.\n",
    "\n",
    "In summary, these three lines work together to tell your script: \"Yes, run in **distributed mode** using the fast **NCCL backend** for GPUs, and get the connection details from the **environment variables** set up by the launcher.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feaf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.distributed = True\n",
    "args.dist_backend = 'nccl'\n",
    "args.dist_url = \"env://\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004427d3",
   "metadata": {},
   "source": [
    "This code block initializes the PyTorch Distributed Data Parallel (DDP) environment, which is the standard way to perform multi-GPU or multi-machine training in PyTorch. It ensures that all the separate processes can communicate and synchronize with each other.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Conditional Initialization\n",
    "\n",
    "```python\n",
    "if init_pytorch_ddp:\n",
    "```\n",
    "\n",
    "This is a simple check. The code inside this `if` block only runs if the `init_pytorch_ddp` variable is `True`. This is a useful way to control whether the script should handle the DDP setup itself or if it's being managed by an external framework like Hugging Face's `accelerate` (as the comment suggests).\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Assigning a GPU\n",
    "\n",
    "```python\n",
    "torch.cuda.set_device(args.gpu)\n",
    "```\n",
    "\n",
    "This line is crucial for multi-GPU setups. It **binds the current process to a specific GPU**. üìå\n",
    "\n",
    "In distributed training, you launch one process for each GPU. This command uses the `args.gpu` value (which is typically the process's **local rank**) to ensure that each process exclusively controls one GPU. For example, the process with `local_rank=0` takes control of GPU 0, `local_rank=1` takes GPU 1, and so on. This prevents conflicts and ensures memory is managed correctly.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Initializing the Process Group\n",
    "\n",
    "```python\n",
    "torch.distributed.init_process_group(backend=args.dist_backend,\n",
    "                                     init_method=args.dist_url,\n",
    "                                     world_size=args.world_size,\n",
    "                                     rank=args.rank,\n",
    "                                     timeout=timedelta(days=365))\n",
    "```\n",
    "\n",
    "This is the main command that **establishes the connection between all processes**. ü§ù It's like the official start of a conference call where everyone joins and can now hear each other.\n",
    "\n",
    "  * `backend=args.dist_backend`: Sets the communication library, which is typically `'nccl'` for fast communication between NVIDIA GPUs.\n",
    "  * `init_method=args.dist_url`: Tells the processes how to find each other. As discussed, this is usually `\"env://\"` so the processes can read the connection info from environment variables.\n",
    "  * `world_size=args.world_size`: Informs this process about the total number of processes participating in the training job.\n",
    "  * `rank=args.rank`: Gives this specific process its unique global ID.\n",
    "  * `timeout=timedelta(days=365)`: This sets an extremely long timeout for operations. If one process has to wait for another for longer than this period, it will raise an error. Setting a long timeout can prevent your job from crashing during long data loading phases or when debugging.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Synchronizing All Processes\n",
    "\n",
    "```python\n",
    "torch.distributed.barrier()\n",
    "```\n",
    "\n",
    "This command acts as a **synchronization point**. üöß\n",
    "\n",
    "When a process executes `barrier()`, it will pause and wait until **every single process** in the group has also reached this exact point. This ensures that no process moves on to the next step (like loading the model) until all other processes have successfully finished the initialization. It prevents race conditions and guarantees everyone starts on the same page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "init_pytorch_ddp = True\n",
    "\n",
    "if init_pytorch_ddp:\n",
    "    # Init DDP Group, for script without using accelerate framework\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    torch.distributed.init_process_group(backend=args.dist_backend, \n",
    "                                         init_method=args.dist_url,\n",
    "                                        world_size=args.world_size, \n",
    "                                        rank=args.rank, \n",
    "                                        timeout=timedelta(days=365))\n",
    "    torch.distributed.barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d0ce8",
   "metadata": {},
   "source": [
    "This function cleverly modifies Python's built-in `print()` function to control which process can write output in a distributed computing environment.\n",
    "\n",
    "Its main purpose is to **prevent log spam**. In distributed training, you run the same script on multiple GPUs or machines simultaneously. If every process prints logs, your console output becomes a messy and unreadable wall of duplicated text. This function ensures that, by default, **only the main process (the \"master\") can print messages**.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# How It Works\n",
    "\n",
    "1.  **Saves the Original `print`**:\n",
    "\n",
    "    ```python\n",
    "    import builtins as __builtin__\n",
    "    builtin_print = __builtin__.print\n",
    "    ```\n",
    "\n",
    "    First, it gets a reference to the original, built-in `print` function and saves it in a variable called `builtin_print`. This is essential because it needs a way to call the real `print` function later.\n",
    "\n",
    "2.  **Creates a New, Custom `print`**:\n",
    "\n",
    "    ```python\n",
    "    def print(*args, **kwargs):\n",
    "        force = kwargs.pop('force', False)\n",
    "        if is_master or force:\n",
    "            builtin_print(*args, **kwargs)\n",
    "    ```\n",
    "\n",
    "    Next, it defines a new function, which is also named `print`. This new function contains the special logic:\n",
    "\n",
    "      * It checks for a special keyword argument called `force`. If you call `print(\"message\", force=True)`, it will set `force` to `True`. Otherwise, `force` is `False`.\n",
    "      * The `if is_master or force:` condition is the core of the function. It allows printing only if one of two things is true:\n",
    "          * The process is the master process (`is_master` is `True`).\n",
    "          * The print call was explicitly told to override the rule (`force` is `True`).\n",
    "      * If the condition passes, it calls the original `builtin_print` to display the message. Otherwise, it does nothing, effectively silencing the print statement.\n",
    "\n",
    "3.  **Replaces the Built-in `print`**:\n",
    "\n",
    "    ```python\n",
    "    __builtin__.print = print\n",
    "    ```\n",
    "\n",
    "    Finally, this line overwrites the global, built-in `print` with the new custom `print` function. This technique is called **monkey-patching**. From this point on, whenever any part of your code calls `print()`, it will execute your new, conditional version instead of the original one.\n",
    "\n",
    "-----\n",
    "\n",
    "### \\#\\# Practical Example\n",
    "\n",
    "Imagine you call this function at the start of your script:\n",
    "\n",
    "```python\n",
    "# In the master process (rank 0)\n",
    "is_master = True\n",
    "setup_for_distributed(is_master)\n",
    "\n",
    "# In a worker process (rank > 0)\n",
    "is_master = False\n",
    "setup_for_distributed(is_master)\n",
    "\n",
    "# --- Now, in both processes ---\n",
    "print(\"Epoch 1 starting...\")  # Only prints on the master process\n",
    "print(\"Debugging worker.\", force=True) # Prints on ALL processes because of 'force'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_for_distributed(is_master):\n",
    "    \"\"\"\n",
    "    This function disables printing when not in master process\n",
    "    \"\"\"\n",
    "    import builtins as __builtin__\n",
    "    builtin_print = __builtin__.print\n",
    "\n",
    "    def print(*args, **kwargs):\n",
    "        force = kwargs.pop('force', False)\n",
    "        \n",
    "        if force==False:\n",
    "            raise \"make sure `force=True`\"\n",
    "        \n",
    "        if is_master or force:\n",
    "            builtin_print(*args, **kwargs)\n",
    "\n",
    "    __builtin__.print = print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fbc12f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be132356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: layer1.weight, Shape: torch.Size([20, 10])\n",
      "Name: layer1.bias, Shape: torch.Size([20])\n",
      "Name: layer2.weight, Shape: torch.Size([5, 20])\n",
      "Name: layer2.bias, Shape: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 20)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(20, 5)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print the name of each learnable parameter\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "# --- Output ---\n",
    "# Name: layer1.weight, Shape: torch.Size([20, 10])\n",
    "# Name: layer1.bias, Shape: torch.Size([20])\n",
    "# Name: layer2.weight, Shape: torch.Size([5, 20])\n",
    "# Name: layer2.bias, Shape: torch.Size([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5378fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mustang\n"
     ]
    }
   ],
   "source": [
    "car = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}\n",
    "\n",
    "x = car.get('model', [])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6100e023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adamw'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = 'adamW'\n",
    "optimizer.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b540846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = {'applebananache': 'fav'}\n",
    "\n",
    "fruits.pop('applebananacherry', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed255c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "skip = {}\n",
    "skip_list = None\n",
    "if skip_list is not None:\n",
    "    skip = skip_list\n",
    "print(skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb950472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterable = 'hello worl how are you an this the understanding' \n",
    "a = str(len(iterable))  # 48\n",
    "b = str(len(a)) # 2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ebc774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([5., 4.]),\n",
       "indices=tensor([4, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x =torch.arange(1., 6.)\n",
    "x = torch.topk(x, k=2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c327578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\t world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\\t world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea5bdd",
   "metadata": {},
   "source": [
    "## 16. scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9d280b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.1 * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb663ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000.000000\n"
     ]
    }
   ],
   "source": [
    "lr = 4000.0000000\n",
    "print(f\"{lr:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be8f3b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('40000000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a5d91c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# global_iter = 0\u001b[39;00m\n\u001b[1;32m      7\u001b[0m global_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mlr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mglobal_iter\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# 1e-6 \n",
    "# 0.000001\n",
    "\n",
    "lr = 0.000001\n",
    "str_lr = str(0.000001)\n",
    "# global_iter = 0\n",
    "global_iter = 4\n",
    "\n",
    "lr[global_iter]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02bbc297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "w_s = np.linspace(1e-6, 5e-5, 10000)\n",
    "w_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df110884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 99997, 99998, 99999], shape=(100000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d081669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00000000e-05, 5.00000000e-05, 5.00000000e-05, 5.00000000e-05,\n",
       "       5.00000000e-05, 4.99999999e-05, 4.99999999e-05, 4.99999999e-05,\n",
       "       4.99999998e-05, 4.99999998e-05])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "final_value = 1e-5\n",
    "base_value = 5e-5\n",
    "epochs = 100\n",
    "num_iter_per_epoch = 2000 \n",
    "warmup_iters = 10000\n",
    "\n",
    "iters = np.arange(epochs * num_iter_per_epoch - warmup_iters)\n",
    "\n",
    "scheduler = np.array([\n",
    "        final_value + 0.5 \\\n",
    "        * (base_value - final_value) \\\n",
    "        * (1 + math.cos(math.pi * i / (len(iters))))\n",
    "        for i in iters\n",
    "    ])\n",
    "scheduler[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af188404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.9999999901577356e-05)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69670b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "d = deque({2, 3, 4}, maxlen=4)\n",
    "d[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c49d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 1 \n",
    "count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4694d824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor([0, 0.0],\n",
    "                              dtype=torch.float64,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8032867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "n = True\n",
    "def check(n):\n",
    "    if not n:\n",
    "        return \n",
    "    \n",
    "print(check(n=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c36bf342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759562934.898867"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcc38a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759562946.8939738"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fcf0c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object check at 0x7bec7cac5070>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check():\n",
    "    for i in range(3):\n",
    "        yield i\n",
    "        print(i)\n",
    "\n",
    "check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8ba0e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 % 20 == 0\n",
    "0 == 2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf14f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 % 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d2cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d90466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "devide = 2 / 4\n",
    "devide = math.floor(devide)\n",
    "devide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cfacd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 2, 256, 256])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input = torch.randn(2, 3, 8, 256, 256)\n",
    "dim = 2 \n",
    "\n",
    "out = input.transpose(0, dim)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97228131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = 2 \n",
    "two = 5 \n",
    "\n",
    "one -= two\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7802102f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cddfb400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 3 \n",
    "\n",
    "out = torch.empty_like(input=input[-kernel_size + 1 :])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a03532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[1.7664e+22, 1.1704e-19, 1.3563e-19,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.1328e-42, 3.9236e-44, 2.1328e-42,  ..., 0.0000e+00,\n",
       "            4.5742e-16, 0.0000e+00],\n",
       "           [8.5591e-42, 0.0000e+00, 4.5741e-16,  ..., 0.0000e+00,\n",
       "            2.1328e-42, 2.8026e-44],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = input[-4:]\n",
    "out = torch.empty_like(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e190d",
   "metadata": {},
   "source": [
    "## 17. Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "370f94e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6090,  0.7671,  0.5947,  1.0956],\n",
       "        [ 1.6462, -0.3694, -0.0300, -0.0473],\n",
       "        [ 0.5524,  1.1561, -0.4806,  0.4219],\n",
       "        [-1.4790,  0.1446,  0.5324,  0.3418]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "input = torch.randn(4, 4)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30019dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.6462, -0.3694, -0.0300, -0.0473]),\n",
       " tensor([ 0.5524,  1.1561, -0.4806,  0.4219]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st row, 2nd row \n",
    "input[1], input[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e552634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.7671, -0.3694,  1.1561,  0.1446]),\n",
       " tensor([ 0.5947, -0.0300, -0.4806,  0.5324]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st column and 2nd column \n",
    "input[:, 1], input[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0256555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2346, -1.8471],\n",
       "          [-0.4486, -0.9047]],\n",
       "\n",
       "         [[ 0.5094,  0.7443],\n",
       "          [-0.8460, -0.5566]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7990,  0.3911],\n",
       "          [ 0.6681, -1.1001]],\n",
       "\n",
       "         [[-0.6530, -0.7455],\n",
       "          [ 0.6711, -0.3098]]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d = torch.randn(2, 2, 2, 2)\n",
    "tensor_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776963ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7990,  0.3911],\n",
       "         [ 0.6681, -1.1001]],\n",
       "\n",
       "        [[-0.6530, -0.7455],\n",
       "         [ 0.6711, -0.3098]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st index \n",
    "tensor = tensor_3d[1]\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476382f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7990, 0.3911])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_index_tensor_row = tensor[0, 0]\n",
    "first_index_tensor_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "78980288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2346, -1.8471],\n",
       "         [-0.4486, -0.9047]],\n",
       "\n",
       "        [[ 0.5094,  0.7443],\n",
       "         [-0.8460, -0.5566]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tensor = tensor_3d[-2]\n",
    "last_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc85f2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.2159,  0.2922],\n",
       "           [ 0.6101,  0.8806]],\n",
       "\n",
       "          [[ 0.5033, -1.1003],\n",
       "           [ 0.1755,  0.0851]]],\n",
       "\n",
       "\n",
       "         [[[-0.9306, -0.9487],\n",
       "           [-1.2997,  2.5439]],\n",
       "\n",
       "          [[-0.0484,  2.9517],\n",
       "           [-1.1340, -1.4258]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.7713,  0.6745],\n",
       "           [-0.5057, -1.9241]],\n",
       "\n",
       "          [[-1.3120,  0.9602],\n",
       "           [-1.2095,  0.7724]]],\n",
       "\n",
       "\n",
       "         [[[ 1.0048,  0.0684],\n",
       "           [-0.7349,  0.3215]],\n",
       "\n",
       "          [[-0.7210,  1.1837],\n",
       "           [ 0.6812, -1.1118]]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tensor = torch.randn(2, 2, 2, 2, 2)\n",
    "d_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9b61de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2159,  0.2922],\n",
       "          [ 0.6101,  0.8806]],\n",
       "\n",
       "         [[ 0.5033, -1.1003],\n",
       "          [ 0.1755,  0.0851]]],\n",
       "\n",
       "\n",
       "        [[[-0.9306, -0.9487],\n",
       "          [-1.2997,  2.5439]],\n",
       "\n",
       "         [[-0.0484,  2.9517],\n",
       "          [-1.1340, -1.4258]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus_2 = d_tensor[-2]\n",
    "minus_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4fbe05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 2.9745e-01,  1.3441e+00,  3.5147e-02,  ...,  5.3068e-01,\n",
       "             6.9909e-02, -2.4022e-01],\n",
       "           [-1.2411e+00, -4.7110e-01, -5.7105e-01,  ..., -4.0464e-01,\n",
       "             6.3043e-01,  1.7091e+00],\n",
       "           [-1.0300e+00,  1.1480e+00,  6.3891e-01,  ...,  2.7181e-03,\n",
       "            -2.6160e-01,  3.9460e-01],\n",
       "           ...,\n",
       "           [-4.3370e-01, -1.1448e-01, -1.0761e+00,  ...,  1.8738e-01,\n",
       "            -3.6680e-01, -7.5374e-01],\n",
       "           [-8.4699e-01,  1.0010e+00,  6.8630e-01,  ...,  5.2631e-01,\n",
       "            -1.7470e-02, -4.5802e-01],\n",
       "           [ 1.4046e+00, -1.0166e+00,  3.0299e-01,  ..., -2.4158e-01,\n",
       "             3.9345e-01, -5.7416e-01]],\n",
       "\n",
       "          [[-7.6112e-03, -1.5876e+00,  2.1127e-01,  ...,  1.3060e+00,\n",
       "            -5.8906e-01,  4.6567e-01],\n",
       "           [-8.7258e-01, -1.5428e+00, -4.0475e-01,  ..., -1.1454e+00,\n",
       "             3.8571e-01,  4.7024e-01],\n",
       "           [-7.5192e-01, -5.9806e-01, -5.4278e-01,  ...,  4.7558e-01,\n",
       "            -2.3283e+00, -1.3255e+00],\n",
       "           ...,\n",
       "           [ 5.3950e-01, -1.1672e+00,  1.0218e+00,  ..., -1.8641e+00,\n",
       "            -1.4575e+00,  1.1456e-01],\n",
       "           [ 2.7571e-01, -2.1699e-01, -2.2262e-01,  ...,  9.7849e-01,\n",
       "            -1.0704e+00, -1.0490e+00],\n",
       "           [-1.9996e+00,  1.6225e+00, -7.3796e-01,  ...,  1.9597e+00,\n",
       "             8.4017e-01, -5.8397e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 2.1016e+00, -9.4128e-03, -5.7521e-01,  ...,  1.7746e-01,\n",
       "             6.6146e-01,  1.4038e+00],\n",
       "           [ 6.7368e-01, -2.1673e-01,  8.4157e-01,  ..., -5.2003e-01,\n",
       "            -6.0586e-01,  4.4670e-01],\n",
       "           [ 5.7853e-01,  9.1155e-01, -3.8960e-01,  ...,  1.6932e-01,\n",
       "            -5.7896e-01,  8.3887e-01],\n",
       "           ...,\n",
       "           [ 2.9561e-01,  2.7638e-01, -3.8151e-01,  ..., -2.7228e+00,\n",
       "             6.2240e-01,  4.7235e-01],\n",
       "           [ 1.2442e-01, -4.5035e-01, -1.0388e+00,  ...,  1.5401e+00,\n",
       "            -7.2481e-01, -2.5163e-01],\n",
       "           [ 1.3166e+00, -6.3529e-01, -1.5666e+00,  ..., -6.7316e-01,\n",
       "            -1.2110e+00,  1.3096e+00]],\n",
       "\n",
       "          [[ 9.7813e-01, -1.8481e+00,  4.9464e-01,  ..., -1.4686e+00,\n",
       "             1.7486e+00, -2.6500e-01],\n",
       "           [ 8.5895e-01,  5.9364e-01,  6.2203e-01,  ..., -1.7122e+00,\n",
       "             4.0382e-01, -1.3015e+00],\n",
       "           [ 1.1923e+00,  5.3560e-01,  1.8969e+00,  ...,  1.8903e-01,\n",
       "            -6.5680e-01, -1.7905e-01],\n",
       "           ...,\n",
       "           [-4.2898e-01, -6.7753e-01, -2.8620e-02,  ...,  8.6042e-01,\n",
       "             1.3410e-02, -7.4486e-01],\n",
       "           [-6.8876e-01, -4.1679e-01,  8.3850e-01,  ..., -3.2941e-01,\n",
       "             8.9329e-01, -3.6553e-01],\n",
       "           [-4.0458e-01, -1.0095e+00, -5.0456e-02,  ...,  5.0177e-02,\n",
       "             3.8046e-01, -3.2204e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 1.7214e+00,  8.9925e-01, -1.5250e+00,  ...,  7.8194e-01,\n",
       "             9.9999e-01,  1.3655e-01],\n",
       "           [ 2.4099e+00,  5.1808e-01, -3.9933e-01,  ...,  1.0217e+00,\n",
       "             2.7247e-02,  7.7993e-01],\n",
       "           [-5.0125e-01, -3.1236e-01, -5.9839e-01,  ..., -9.4333e-01,\n",
       "             6.9638e-01, -4.4964e-02],\n",
       "           ...,\n",
       "           [ 3.2255e-01, -4.3905e-01, -2.4722e-01,  ...,  1.3272e-01,\n",
       "             5.8561e-01,  4.4725e-01],\n",
       "           [ 1.5058e-01,  1.6069e+00, -1.1355e+00,  ...,  1.7623e+00,\n",
       "            -8.4311e-01, -1.4801e+00],\n",
       "           [-7.0775e-01,  5.8115e-01,  7.2426e-02,  ..., -4.1748e-01,\n",
       "            -1.7200e+00,  6.7485e-01]],\n",
       "\n",
       "          [[-3.5184e-01, -1.6215e+00,  1.0960e+00,  ...,  1.3154e-01,\n",
       "             6.8329e-01, -8.7273e-01],\n",
       "           [-2.8095e+00, -2.1296e+00,  2.0989e+00,  ...,  1.3368e+00,\n",
       "             1.2102e+00,  1.8826e+00],\n",
       "           [-4.1432e-01,  1.2715e+00, -3.5861e-01,  ...,  1.5468e+00,\n",
       "            -9.9604e-01, -9.6924e-01],\n",
       "           ...,\n",
       "           [-7.3649e-01,  1.4675e+00,  1.4938e+00,  ..., -2.6676e-01,\n",
       "             5.5191e-01,  1.7169e+00],\n",
       "           [ 7.3079e-01,  5.3863e-01, -1.3436e+00,  ..., -2.2472e+00,\n",
       "             9.8140e-01,  1.1935e+00],\n",
       "           [-9.4528e-01,  2.3196e+00, -1.3846e+00,  ...,  8.4273e-01,\n",
       "            -4.0880e-02, -6.8966e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.1360e+00, -6.1367e-01, -1.0385e+00,  ...,  4.5828e-01,\n",
       "            -7.9426e-01, -4.7653e-01],\n",
       "           [-3.9213e-01, -1.5844e+00, -2.1408e-01,  ...,  1.4522e+00,\n",
       "            -2.0012e-01, -1.9080e+00],\n",
       "           [ 2.4321e-01,  7.2071e-01,  1.6403e+00,  ...,  7.9585e-01,\n",
       "            -1.6764e-01,  4.3864e-01],\n",
       "           ...,\n",
       "           [ 6.0440e-01, -5.0721e-01, -1.0361e+00,  ...,  9.3074e-01,\n",
       "            -5.7224e-01, -7.0204e-01],\n",
       "           [-1.7723e+00, -1.2826e+00,  1.5444e+00,  ...,  4.5044e-01,\n",
       "             7.2990e-01,  1.1506e+00],\n",
       "           [-4.3942e-01, -3.8391e-01, -1.3633e+00,  ...,  1.8748e+00,\n",
       "             5.0378e-01,  1.7536e-01]],\n",
       "\n",
       "          [[-5.5974e-01,  2.3274e-01, -5.7808e-01,  ..., -4.1261e-01,\n",
       "             9.2919e-02, -3.5095e-02],\n",
       "           [-4.6443e-01, -2.9160e-02,  6.6446e-01,  ...,  1.8143e-01,\n",
       "            -1.6628e+00, -2.5615e+00],\n",
       "           [ 1.3782e+00, -2.4638e-01,  9.6906e-01,  ...,  2.0795e-01,\n",
       "            -9.1728e-01,  3.6664e-01],\n",
       "           ...,\n",
       "           [ 6.5639e-01, -1.2241e-01,  1.1550e+00,  ...,  1.3355e+00,\n",
       "             2.6348e+00, -1.0418e+00],\n",
       "           [ 1.8183e-01, -3.4818e-01,  1.1285e+00,  ..., -4.8421e-01,\n",
       "             3.6191e-01, -2.1639e-01],\n",
       "           [ 2.2994e+00, -6.9434e-01, -1.0832e+00,  ...,  2.3156e-01,\n",
       "             2.6751e-01, -6.6142e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.0357e+00, -1.0572e+00, -7.3939e-01,  ...,  1.0915e+00,\n",
       "            -9.6768e-02,  1.7958e-01],\n",
       "           [ 1.5457e+00, -1.3379e+00,  4.9169e-01,  ..., -2.5292e+00,\n",
       "            -4.4479e-01, -1.0958e+00],\n",
       "           [ 9.1913e-02, -8.2627e-01,  8.9643e-01,  ...,  7.8007e-02,\n",
       "             1.7471e+00,  8.8986e-01],\n",
       "           ...,\n",
       "           [-2.7068e-02,  1.8744e+00, -1.4481e+00,  ..., -1.1443e+00,\n",
       "            -3.8250e-02,  1.2235e+00],\n",
       "           [ 9.5682e-02, -1.5186e+00, -3.6100e-01,  ...,  1.1657e+00,\n",
       "            -5.1055e-01, -1.6872e+00],\n",
       "           [-1.3210e-01, -1.4206e+00,  1.9828e-02,  ..., -7.1635e-01,\n",
       "            -1.6377e+00,  1.4468e+00]],\n",
       "\n",
       "          [[ 2.8238e-01,  1.7274e+00, -9.8572e-01,  ..., -5.1715e-01,\n",
       "            -9.7797e-01, -1.4312e+00],\n",
       "           [-5.7962e-01, -1.2689e+00,  4.5863e-01,  ..., -2.6222e-01,\n",
       "            -1.1221e+00, -1.0090e+00],\n",
       "           [ 1.1225e+00,  2.1520e-01,  1.0292e+00,  ...,  4.4383e-01,\n",
       "             2.1932e-01, -8.6706e-01],\n",
       "           ...,\n",
       "           [ 3.7605e-01, -3.9663e-01,  1.7583e-01,  ...,  1.5045e+00,\n",
       "             4.0051e-01, -4.4830e-02],\n",
       "           [-6.9597e-01, -1.4254e+00, -5.8933e-01,  ...,  6.3174e-01,\n",
       "             5.4923e-01,  8.5678e-01],\n",
       "           [-1.4745e+00,  1.7751e+00,  8.4761e-01,  ...,  9.6525e-01,\n",
       "            -4.4883e-01,  4.4262e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 1.1959e+00, -1.0046e+00, -1.2543e-01,  ..., -1.2048e-01,\n",
       "             1.7026e-01,  2.6135e-01],\n",
       "           [ 1.0330e+00, -1.2375e+00,  9.8372e-02,  ..., -6.5538e-02,\n",
       "             8.8057e-01, -1.2224e+00],\n",
       "           [ 3.6589e-01,  3.8830e-02, -1.0349e+00,  ...,  2.0343e-01,\n",
       "            -1.6322e-01, -1.9516e+00],\n",
       "           ...,\n",
       "           [ 1.0920e+00,  4.3767e-01, -2.5911e-02,  ...,  1.4194e+00,\n",
       "            -1.8659e+00, -1.3839e+00],\n",
       "           [-1.5398e+00,  1.2100e-01, -1.5382e-04,  ...,  1.4682e-01,\n",
       "            -1.8477e+00,  6.6371e-01],\n",
       "           [ 4.7020e-01,  3.2526e-01,  3.0264e+00,  ...,  3.5197e-01,\n",
       "             1.1529e+00,  1.0502e+00]],\n",
       "\n",
       "          [[ 1.5007e-01, -2.0656e-01,  5.0298e-01,  ..., -3.4554e-01,\n",
       "            -1.2132e+00, -1.3477e+00],\n",
       "           [ 1.3295e+00,  9.8842e-01,  2.5800e-01,  ...,  1.4646e+00,\n",
       "             4.0405e-01,  9.9940e-01],\n",
       "           [ 1.3811e+00, -1.7278e+00,  1.4150e-01,  ...,  1.0487e+00,\n",
       "            -6.3117e-02,  7.5251e-01],\n",
       "           ...,\n",
       "           [-6.7256e-01, -6.0838e-01,  4.9802e-01,  ..., -9.1821e-01,\n",
       "             5.2354e-01,  3.0543e-01],\n",
       "           [-2.2321e+00,  1.6048e+00,  4.2377e-01,  ..., -1.8731e+00,\n",
       "            -3.0924e-01,  3.7703e-01],\n",
       "           [-3.9788e-01,  1.5933e+00,  1.1266e+00,  ...,  5.3790e-01,\n",
       "            -1.9651e-02, -1.0502e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 9.9507e-02,  2.5636e-01, -1.1720e+00,  ..., -7.1348e-01,\n",
       "             1.9173e-02,  1.6668e-01],\n",
       "           [ 9.7889e-01, -2.5580e-01,  5.4707e-01,  ..., -7.2603e-01,\n",
       "             4.2238e-01,  2.8777e-01],\n",
       "           [ 5.6483e-01, -4.9735e-01, -1.7907e+00,  ...,  1.2610e+00,\n",
       "            -4.4324e-01,  8.0146e-01],\n",
       "           ...,\n",
       "           [ 1.5834e+00,  1.1419e+00, -1.4945e+00,  ..., -1.2555e+00,\n",
       "            -1.1127e+00,  3.0871e-01],\n",
       "           [-4.8116e-01, -2.4676e+00, -8.6955e-01,  ...,  8.5234e-01,\n",
       "             4.6564e-01,  1.6934e-01],\n",
       "           [-1.0771e-01, -9.2824e-01,  4.4789e-01,  ...,  5.7329e-01,\n",
       "            -8.9686e-02,  1.2343e+00]],\n",
       "\n",
       "          [[-3.5798e-01, -3.3805e-01, -3.1724e-01,  ..., -3.2545e-01,\n",
       "            -5.6270e-01,  1.8307e-01],\n",
       "           [ 1.5582e+00,  8.8882e-01,  9.1014e-01,  ..., -5.9254e-01,\n",
       "             1.2176e+00,  2.2274e-01],\n",
       "           [ 5.6253e-01, -1.1054e+00,  1.7336e-01,  ..., -6.5565e-01,\n",
       "             2.3320e+00,  2.5484e-01],\n",
       "           ...,\n",
       "           [-1.4710e+00,  8.2149e-01,  1.0515e+00,  ..., -1.8051e+00,\n",
       "            -7.4985e-01,  6.1193e-01],\n",
       "           [ 1.2214e-02,  2.6757e-01, -5.0954e-01,  ..., -4.9308e-01,\n",
       "            -8.1425e-01, -1.3543e+00],\n",
       "           [ 1.7160e+00, -1.0582e+00, -4.7213e-01,  ..., -4.4991e-01,\n",
       "             9.2666e-01, -1.2947e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 1.0373e+00,  2.3910e-01, -6.8236e-01,  ..., -8.3867e-01,\n",
       "            -1.9600e-01, -2.3465e-01],\n",
       "           [-3.9355e-01, -6.8466e-02, -1.3715e+00,  ...,  7.4552e-01,\n",
       "             9.9441e-03, -6.0413e-01],\n",
       "           [-5.3591e-01, -1.9195e+00, -5.5342e-01,  ...,  1.1497e+00,\n",
       "             9.1305e-01,  1.0195e+00],\n",
       "           ...,\n",
       "           [-1.3497e-02, -2.6751e-01,  8.8550e-01,  ...,  1.2343e+00,\n",
       "             1.6627e+00,  2.5360e-01],\n",
       "           [-7.3946e-01, -3.3070e-01, -3.1272e-01,  ..., -8.4172e-01,\n",
       "            -3.6453e-01,  9.7245e-01],\n",
       "           [ 1.2866e+00, -1.7482e-01,  1.0273e+00,  ..., -4.7396e-01,\n",
       "            -7.6876e-01, -1.8704e-01]],\n",
       "\n",
       "          [[-9.5672e-01, -4.7174e-01,  1.2220e+00,  ...,  1.8667e+00,\n",
       "             5.4566e-02,  3.6849e-01],\n",
       "           [-1.5497e+00, -3.3625e-01, -5.1336e-01,  ...,  1.7493e-01,\n",
       "             6.2259e-01,  1.4161e+00],\n",
       "           [ 2.4889e+00, -3.6267e-01, -1.2762e+00,  ..., -1.9818e+00,\n",
       "             1.0388e+00,  4.2721e-01],\n",
       "           ...,\n",
       "           [ 8.3695e-01,  9.2999e-01, -1.2645e+00,  ...,  8.6630e-01,\n",
       "            -8.1725e-01,  3.7935e-01],\n",
       "           [ 2.9635e-03,  1.4684e+00,  3.3455e-01,  ...,  1.5822e-01,\n",
       "            -3.7734e-01,  1.1117e+00],\n",
       "           [ 1.7280e+00, -4.8654e-03,  7.7140e-02,  ..., -3.4728e-02,\n",
       "             1.4565e+00, -7.6470e-01]]],\n",
       "\n",
       "\n",
       "         [[[-1.0002e+00, -2.1081e+00,  6.9241e-01,  ..., -8.8752e-01,\n",
       "             4.2099e-01, -1.5361e-01],\n",
       "           [ 5.2356e-01, -1.7805e+00,  1.0654e+00,  ..., -3.3843e-01,\n",
       "            -5.9748e-01, -3.5070e-01],\n",
       "           [-1.1417e+00, -2.7441e-01,  8.4839e-02,  ..., -3.4534e-01,\n",
       "             1.1066e+00, -3.5061e-01],\n",
       "           ...,\n",
       "           [-1.3579e+00, -2.4457e-01,  1.4008e+00,  ...,  3.2485e-01,\n",
       "            -9.7853e-01, -2.3932e-01],\n",
       "           [-1.1351e+00, -9.7473e-01,  8.3543e-01,  ..., -2.2138e+00,\n",
       "            -3.8855e-01,  7.5345e-01],\n",
       "           [-7.1593e-01,  1.4093e+00, -1.0100e+00,  ...,  3.7942e-01,\n",
       "            -1.4970e+00,  1.7807e-01]],\n",
       "\n",
       "          [[ 1.6738e-01,  1.5870e+00, -3.0562e-01,  ..., -5.0236e-01,\n",
       "             5.1144e-01,  1.9207e+00],\n",
       "           [-1.7132e+00, -4.0985e-02, -2.2714e-01,  ..., -5.5388e-01,\n",
       "             1.1401e+00, -6.3128e-02],\n",
       "           [ 7.5533e-02,  1.6692e-01,  1.4747e-01,  ..., -1.7694e-01,\n",
       "             2.2344e+00, -9.4039e-01],\n",
       "           ...,\n",
       "           [ 1.6654e-02,  1.2774e+00, -6.6165e-01,  ..., -1.1272e+00,\n",
       "             1.3311e+00,  9.4164e-01],\n",
       "           [ 2.5320e-01,  4.5295e-01, -1.0239e+00,  ...,  1.4483e+00,\n",
       "             8.2505e-01, -7.7143e-01],\n",
       "           [-1.3213e+00, -7.7446e-02, -2.3814e+00,  ...,  9.1152e-01,\n",
       "            -1.4534e+00, -8.0771e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[-5.8837e-01,  5.5325e-01,  1.1191e+00,  ...,  6.7175e-01,\n",
       "            -9.6135e-01, -2.1211e-01],\n",
       "           [ 4.0353e-01, -5.8752e-01,  1.6999e+00,  ..., -9.9018e-01,\n",
       "             9.0110e-01, -5.4119e-01],\n",
       "           [ 1.3829e+00, -1.2100e-01, -8.7573e-01,  ...,  3.5985e-01,\n",
       "            -8.6091e-02,  1.3158e-01],\n",
       "           ...,\n",
       "           [-1.7809e+00,  1.1660e+00, -4.8375e-01,  ..., -1.3260e+00,\n",
       "             5.1226e-01,  4.8567e-01],\n",
       "           [-7.6510e-02,  8.7917e-01, -1.2714e+00,  ..., -1.3195e+00,\n",
       "            -1.3715e+00,  5.4507e-01],\n",
       "           [-1.9917e-01, -9.8014e-01, -1.2807e+00,  ..., -5.5361e-01,\n",
       "             1.8990e+00,  1.9386e+00]],\n",
       "\n",
       "          [[ 1.1365e+00, -2.1758e-01, -3.6713e-01,  ..., -6.9873e-01,\n",
       "            -4.0638e-01, -1.7550e+00],\n",
       "           [-1.1275e+00, -2.5265e+00,  1.8098e+00,  ...,  1.7357e+00,\n",
       "             3.7344e-01, -9.7592e-01],\n",
       "           [ 2.5259e-01,  1.4409e+00, -6.4531e-01,  ...,  8.9167e-01,\n",
       "            -8.0796e-01, -1.7650e-01],\n",
       "           ...,\n",
       "           [-2.0938e-01,  6.4065e-01, -1.0912e+00,  ...,  1.2400e+00,\n",
       "             2.4139e-01, -2.1837e-01],\n",
       "           [ 8.6315e-01, -6.0890e-03, -1.8358e-01,  ..., -1.8705e+00,\n",
       "             1.0419e+00, -1.4055e+00],\n",
       "           [ 9.1525e-01,  2.7246e-01, -1.6315e+00,  ...,  1.0972e-01,\n",
       "            -6.0932e-01,  1.3075e+00]]],\n",
       "\n",
       "\n",
       "         [[[-7.3820e-01,  4.7383e-01,  1.4090e+00,  ...,  4.6633e-02,\n",
       "             5.2740e-02,  9.1039e-01],\n",
       "           [-2.7893e-01, -1.0027e+00, -6.4207e-01,  ...,  7.7846e-02,\n",
       "             1.2079e+00, -3.7724e-01],\n",
       "           [ 1.0396e+00, -4.0575e-01, -1.0219e+00,  ...,  9.1633e-01,\n",
       "             1.0085e+00,  4.8635e-01],\n",
       "           ...,\n",
       "           [ 8.0609e-01, -8.3946e-01, -1.2769e+00,  ...,  6.9732e-01,\n",
       "            -1.3252e+00, -1.6587e+00],\n",
       "           [ 2.1892e-01,  5.7555e-01, -3.6170e-01,  ...,  1.0189e+00,\n",
       "            -1.4256e+00,  2.3757e+00],\n",
       "           [ 3.7294e-02,  4.8743e-01, -1.4049e+00,  ..., -8.8725e-02,\n",
       "            -1.4190e+00, -3.1638e-01]],\n",
       "\n",
       "          [[ 7.9809e-01, -3.0951e-01, -1.3533e-01,  ...,  3.1500e-01,\n",
       "             1.0742e+00, -1.4543e+00],\n",
       "           [ 7.9994e-01, -7.5389e-02, -1.6607e+00,  ...,  1.6029e-01,\n",
       "             1.4291e+00, -5.2138e-01],\n",
       "           [-1.0774e+00, -8.6053e-01, -1.5460e-01,  ..., -6.5998e-01,\n",
       "            -1.7307e+00, -8.9664e-01],\n",
       "           ...,\n",
       "           [ 9.4844e-01,  3.3364e-02, -2.9681e-01,  ...,  5.3896e-01,\n",
       "            -6.6471e-01, -6.2863e-01],\n",
       "           [ 2.2361e+00, -6.8708e-01,  5.8120e-02,  ...,  4.1180e-02,\n",
       "            -7.3011e-02,  3.0251e-01],\n",
       "           [-4.6465e-01, -7.3200e-01,  2.4787e-01,  ..., -2.7501e-01,\n",
       "             1.8534e+00, -5.9509e-01]]],\n",
       "\n",
       "\n",
       "         [[[-3.9085e-01, -5.6667e-01, -9.6111e-01,  ..., -1.3257e+00,\n",
       "            -1.0947e+00,  5.4917e-02],\n",
       "           [ 1.1323e+00,  6.6772e-02, -3.6780e-01,  ..., -5.5311e-02,\n",
       "             7.4529e-01, -7.4794e-01],\n",
       "           [ 1.1778e+00,  1.6036e+00,  1.9955e-01,  ...,  2.0299e+00,\n",
       "             1.8593e-03, -2.4207e-01],\n",
       "           ...,\n",
       "           [-1.9565e+00,  1.2604e+00, -1.6394e+00,  ...,  1.1876e-01,\n",
       "             1.1931e+00, -5.0367e-01],\n",
       "           [-1.2515e+00,  2.6942e-01, -2.6237e-01,  ...,  4.3135e-02,\n",
       "            -6.4127e-01,  1.0532e+00],\n",
       "           [-1.3666e+00, -9.0398e-01,  1.3490e+00,  ...,  1.2953e+00,\n",
       "            -5.5914e-02,  4.3203e-01]],\n",
       "\n",
       "          [[-1.6661e-01,  8.5447e-01,  2.6768e-01,  ..., -3.5567e-01,\n",
       "            -2.6398e+00, -8.0576e-01],\n",
       "           [ 5.4349e-01,  6.1273e-02, -9.7605e-01,  ..., -1.0201e+00,\n",
       "             8.4396e-01, -1.1000e+00],\n",
       "           [ 3.6685e-01, -2.0922e-01,  1.7316e-01,  ..., -5.3175e-01,\n",
       "            -1.0576e-01,  2.2886e-01],\n",
       "           ...,\n",
       "           [ 7.8616e-01,  1.2626e+00,  2.4597e-01,  ...,  1.6614e-02,\n",
       "            -9.0590e-01,  1.2511e+00],\n",
       "           [-1.5166e-01,  1.1046e-01, -1.6257e-01,  ...,  1.6232e+00,\n",
       "            -9.1305e-01, -3.1088e-01],\n",
       "           [-2.9101e-01,  8.8386e-01,  1.3863e+00,  ..., -1.8860e+00,\n",
       "            -1.5329e+00,  1.6392e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.2127e+00,  8.8635e-02,  4.0829e-02,  ..., -3.6335e-01,\n",
       "            -9.0285e-01, -2.1998e+00],\n",
       "           [-1.2676e+00, -1.7008e+00, -5.0671e-01,  ...,  5.0088e-01,\n",
       "             1.1970e-01,  1.2176e-01],\n",
       "           [-2.9037e+00, -1.1764e+00, -1.4681e+00,  ...,  1.5804e-01,\n",
       "             9.2999e-01,  1.4859e+00],\n",
       "           ...,\n",
       "           [-7.8579e-01, -1.5541e+00,  2.6316e+00,  ..., -4.9008e-01,\n",
       "            -1.8607e+00,  2.9692e-01],\n",
       "           [-8.2628e-02, -1.7121e-01,  1.4565e+00,  ...,  1.8449e-01,\n",
       "             3.3877e-02, -8.9256e-01],\n",
       "           [-1.7836e+00,  1.7822e+00,  3.1866e-01,  ..., -1.6228e+00,\n",
       "             6.8477e-01,  1.4123e-01]],\n",
       "\n",
       "          [[ 3.5952e-01,  1.7189e-01,  2.0150e-01,  ...,  8.3542e-02,\n",
       "            -1.8534e+00, -1.8006e-01],\n",
       "           [ 2.5150e-02,  1.0918e+00, -3.4624e-01,  ..., -1.8278e+00,\n",
       "            -4.6559e-01,  3.0786e-01],\n",
       "           [-1.9133e+00,  1.5482e+00, -1.0784e+00,  ...,  7.3744e-01,\n",
       "             4.0254e-01, -7.8718e-01],\n",
       "           ...,\n",
       "           [-9.7399e-01,  1.0642e+00, -9.2709e-01,  ..., -7.7265e-02,\n",
       "             7.3179e-01, -1.5435e+00],\n",
       "           [ 4.8661e-01,  7.4481e-01, -1.9153e+00,  ...,  8.2334e-01,\n",
       "            -1.0202e+00, -1.1861e+00],\n",
       "           [-3.3717e-01,  3.2428e-02, -1.1029e+00,  ...,  2.5630e-01,\n",
       "            -8.7439e-01, -6.8859e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 1.0470e+00, -1.1376e+00,  3.7594e-01,  ...,  5.1962e-01,\n",
       "            -7.9801e-04,  1.1721e+00],\n",
       "           [ 6.0128e-01,  1.1026e+00,  5.7258e-01,  ..., -6.7035e-02,\n",
       "            -2.7566e-01,  1.0364e+00],\n",
       "           [ 1.4931e-01,  2.8937e-01, -5.5937e-01,  ..., -2.0638e+00,\n",
       "             1.0917e+00, -3.1998e-01],\n",
       "           ...,\n",
       "           [ 8.0331e-01, -1.2112e+00, -2.3301e-01,  ...,  1.8160e+00,\n",
       "             4.4196e-01,  1.1233e+00],\n",
       "           [ 4.3903e-01,  3.8640e-01, -1.3505e+00,  ..., -1.4502e+00,\n",
       "            -3.8037e-01, -9.0469e-01],\n",
       "           [-1.2848e-01,  9.6249e-01, -7.9826e-01,  ...,  2.0873e+00,\n",
       "            -1.0861e+00,  1.3552e-01]],\n",
       "\n",
       "          [[ 8.3272e-01,  2.7515e-01,  5.1050e-01,  ...,  8.7932e-01,\n",
       "            -1.7399e+00, -7.1398e-01],\n",
       "           [ 2.8458e-01, -7.1219e-01, -1.5971e+00,  ..., -6.9333e-01,\n",
       "             1.3830e-01,  7.0498e-02],\n",
       "           [ 5.9867e-03, -2.7485e+00,  1.6671e+00,  ..., -5.3634e-01,\n",
       "            -2.8695e-01, -1.9801e+00],\n",
       "           ...,\n",
       "           [ 2.3409e-01, -1.3375e-01,  8.2133e-02,  ..., -1.6168e+00,\n",
       "            -5.3064e-01,  3.1487e-01],\n",
       "           [ 1.2394e+00, -1.0283e+00, -6.4684e-01,  ...,  2.2465e-01,\n",
       "            -1.4254e-01,  6.8168e-02],\n",
       "           [ 2.2542e+00, -1.4220e+00, -1.4059e+00,  ...,  5.0841e-01,\n",
       "             3.1760e-01,  4.8973e-01]]],\n",
       "\n",
       "\n",
       "         [[[-1.7306e+00, -1.9263e-01,  1.3957e+00,  ...,  1.6861e-01,\n",
       "             1.0719e-01, -2.3292e+00],\n",
       "           [-8.7811e-01,  7.0346e-01, -1.4233e+00,  ...,  3.7113e-01,\n",
       "            -6.2858e-01,  1.5901e+00],\n",
       "           [ 7.2901e-01,  3.3794e-01, -4.3725e-01,  ..., -4.3168e-01,\n",
       "            -2.9096e-02, -4.8676e-01],\n",
       "           ...,\n",
       "           [-5.6549e-01, -1.3373e+00,  3.3280e-01,  ...,  1.0287e+00,\n",
       "            -9.4849e-01,  8.5820e-01],\n",
       "           [ 3.0754e-01,  2.1076e+00,  1.3577e+00,  ..., -1.1588e+00,\n",
       "            -8.9285e-01,  1.2460e+00],\n",
       "           [-1.7675e+00, -4.7610e-01, -2.3008e-01,  ..., -4.0121e-01,\n",
       "             1.1506e+00, -6.1076e-01]],\n",
       "\n",
       "          [[ 4.0868e-01, -5.7575e-01,  7.1485e-01,  ..., -2.5084e-01,\n",
       "             4.1277e-01,  2.9359e-01],\n",
       "           [-4.8995e-01, -6.9610e-02, -3.3717e-01,  ...,  6.0493e-01,\n",
       "            -3.3103e-01, -8.2546e-01],\n",
       "           [-1.5606e+00, -1.4616e-01,  1.4201e+00,  ...,  3.7792e-01,\n",
       "             2.7422e+00,  1.5502e-01],\n",
       "           ...,\n",
       "           [ 1.7461e-01, -8.5538e-01,  2.9386e-01,  ..., -1.3933e-01,\n",
       "             1.4615e+00, -6.0606e-01],\n",
       "           [-1.2504e+00,  4.3451e-01,  1.4294e+00,  ..., -5.9630e-01,\n",
       "            -6.1598e-01,  1.1107e+00],\n",
       "           [-8.0985e-01,  3.9255e-01,  2.8625e-01,  ..., -3.9829e-01,\n",
       "            -8.6487e-03, -1.7792e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 6.5561e-01, -6.3798e-01,  9.5054e-02,  ...,  5.9321e-01,\n",
       "            -8.2862e-01,  8.7262e-01],\n",
       "           [ 7.6474e-01,  1.7085e+00,  1.3898e+00,  ...,  9.4169e-01,\n",
       "             7.9823e-01, -2.7105e-01],\n",
       "           [ 2.2113e+00,  5.2136e-01,  5.6693e-01,  ..., -1.9357e-01,\n",
       "            -1.5641e+00,  1.6641e+00],\n",
       "           ...,\n",
       "           [-7.6470e-01, -6.9056e-01, -3.5065e-01,  ...,  5.5815e-01,\n",
       "             1.0917e+00,  6.5871e-01],\n",
       "           [-3.8751e-01, -1.1738e+00,  1.0708e+00,  ...,  1.0521e+00,\n",
       "             1.2135e-01,  1.0151e+00],\n",
       "           [ 1.7359e+00, -6.8561e-01,  3.7620e-02,  ...,  2.9211e-01,\n",
       "            -1.3193e-01, -6.3321e-01]],\n",
       "\n",
       "          [[-2.5121e+00, -2.7355e-01,  5.7982e-02,  ..., -1.0397e-01,\n",
       "            -1.1710e+00, -4.4862e-03],\n",
       "           [-1.3388e+00,  1.7445e+00, -1.1481e+00,  ..., -3.7681e-01,\n",
       "             8.1060e-01,  1.2352e+00],\n",
       "           [-1.4446e+00,  4.9919e-01,  1.7886e+00,  ..., -8.1327e-01,\n",
       "             1.4763e+00, -5.1104e-02],\n",
       "           ...,\n",
       "           [ 1.5034e+00, -1.5467e-01,  6.2833e-01,  ...,  5.5622e-01,\n",
       "             3.4065e-01,  1.3447e+00],\n",
       "           [-9.8125e-01, -5.1696e-02,  1.6823e+00,  ..., -1.2312e+00,\n",
       "            -4.9612e-01,  8.0256e-01],\n",
       "           [-5.0524e-01,  1.6915e+00,  4.6659e-01,  ..., -1.6396e+00,\n",
       "             1.6720e+00, -1.3409e+00]]],\n",
       "\n",
       "\n",
       "         [[[-1.9608e+00,  7.1898e-01, -6.7212e-01,  ..., -4.2391e-02,\n",
       "             4.4697e-01,  6.4969e-01],\n",
       "           [ 1.1683e+00,  1.8207e+00,  9.9728e-01,  ...,  1.0711e-01,\n",
       "            -2.0180e+00, -7.6075e-01],\n",
       "           [-3.6364e-01,  5.6483e-01,  8.3468e-01,  ...,  1.2368e+00,\n",
       "            -4.0043e-01,  4.4950e-01],\n",
       "           ...,\n",
       "           [ 2.3493e+00,  2.1981e+00, -2.4053e-01,  ...,  5.9003e-01,\n",
       "            -1.6526e+00, -1.0042e+00],\n",
       "           [-1.2274e-01, -9.1543e-01, -4.7474e-01,  ..., -4.8558e-01,\n",
       "            -5.7748e-01, -1.5955e-01],\n",
       "           [-3.1494e-01, -1.6156e+00, -2.9480e-01,  ...,  1.7300e-01,\n",
       "             1.0927e+00,  2.4622e-02]],\n",
       "\n",
       "          [[-9.0106e-01, -1.0541e+00,  5.1815e-01,  ..., -1.8501e-02,\n",
       "            -5.9150e-01, -1.4515e+00],\n",
       "           [-1.6396e+00,  1.2021e+00,  2.1667e-01,  ...,  5.2864e-01,\n",
       "             5.5122e-01, -7.8777e-01],\n",
       "           [ 7.1862e-01, -1.1906e-01, -5.3096e-01,  ..., -8.9417e-01,\n",
       "            -9.7159e-01,  6.6730e-01],\n",
       "           ...,\n",
       "           [ 4.1543e-01, -1.5478e+00, -3.3512e-01,  ..., -1.0430e+00,\n",
       "             1.4767e+00, -7.1609e-01],\n",
       "           [-6.7018e-01,  2.4860e-01, -2.7600e-01,  ...,  3.0134e-01,\n",
       "             7.8821e-01, -1.3910e+00],\n",
       "           [-7.3235e-01,  2.5259e-01, -1.6741e+00,  ..., -1.1479e+00,\n",
       "             6.7086e-03,  4.1598e-01]]],\n",
       "\n",
       "\n",
       "         [[[-7.1891e-02, -1.0723e+00, -9.3533e-02,  ...,  1.1922e+00,\n",
       "             8.6662e-01,  8.3842e-01],\n",
       "           [-1.4736e+00,  3.5646e-01, -5.0574e-01,  ...,  1.1761e-01,\n",
       "            -2.6620e-01, -7.7545e-01],\n",
       "           [-1.7367e-01, -1.0346e-01, -1.2900e+00,  ..., -3.6545e-01,\n",
       "            -1.0343e+00, -4.8209e-01],\n",
       "           ...,\n",
       "           [-7.1374e-01,  5.6660e-01, -3.2033e-01,  ...,  1.2585e-01,\n",
       "             8.4022e-01, -1.1519e+00],\n",
       "           [-1.1603e+00, -9.1228e-01, -9.8553e-01,  ..., -1.4759e-01,\n",
       "             1.6954e+00, -2.8371e+00],\n",
       "           [ 4.1932e-01,  6.7907e-01, -5.0769e-01,  ..., -9.1366e-01,\n",
       "             1.3547e+00, -4.3583e-01]],\n",
       "\n",
       "          [[ 4.8211e-01,  3.8207e-01, -3.2982e-01,  ...,  8.9713e-01,\n",
       "             5.1337e-01, -5.5598e-01],\n",
       "           [ 2.4752e-02,  3.1283e-01, -1.7347e+00,  ..., -9.9587e-03,\n",
       "             9.3776e-01, -2.1665e-01],\n",
       "           [-7.3061e-01, -2.2173e+00, -2.6512e-01,  ...,  2.1481e-01,\n",
       "            -8.1361e-01,  4.8120e-01],\n",
       "           ...,\n",
       "           [-5.7843e-01,  1.3829e+00, -1.7854e+00,  ..., -1.5605e+00,\n",
       "            -1.7450e+00,  1.2450e+00],\n",
       "           [-1.3020e-01,  3.7426e-02,  1.3780e+00,  ...,  2.8409e-01,\n",
       "             2.1110e+00, -2.7563e+00],\n",
       "           [-8.0251e-01,  1.8754e+00, -1.1409e+00,  ..., -2.0404e+00,\n",
       "            -9.4066e-02, -8.9949e-02]]]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_tensor = torch.randn(8, 3, 2, 256, 256)\n",
    "video_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55e59332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.2127e+00,  8.8635e-02,  4.0829e-02,  ..., -3.6335e-01,\n",
       "           -9.0285e-01, -2.1998e+00],\n",
       "          [-1.2676e+00, -1.7008e+00, -5.0671e-01,  ...,  5.0088e-01,\n",
       "            1.1970e-01,  1.2176e-01],\n",
       "          [-2.9037e+00, -1.1764e+00, -1.4681e+00,  ...,  1.5804e-01,\n",
       "            9.2999e-01,  1.4859e+00],\n",
       "          ...,\n",
       "          [-7.8579e-01, -1.5541e+00,  2.6316e+00,  ..., -4.9008e-01,\n",
       "           -1.8607e+00,  2.9692e-01],\n",
       "          [-8.2628e-02, -1.7121e-01,  1.4565e+00,  ...,  1.8449e-01,\n",
       "            3.3877e-02, -8.9256e-01],\n",
       "          [-1.7836e+00,  1.7822e+00,  3.1866e-01,  ..., -1.6228e+00,\n",
       "            6.8477e-01,  1.4123e-01]],\n",
       "\n",
       "         [[ 3.5952e-01,  1.7189e-01,  2.0150e-01,  ...,  8.3542e-02,\n",
       "           -1.8534e+00, -1.8006e-01],\n",
       "          [ 2.5150e-02,  1.0918e+00, -3.4624e-01,  ..., -1.8278e+00,\n",
       "           -4.6559e-01,  3.0786e-01],\n",
       "          [-1.9133e+00,  1.5482e+00, -1.0784e+00,  ...,  7.3744e-01,\n",
       "            4.0254e-01, -7.8718e-01],\n",
       "          ...,\n",
       "          [-9.7399e-01,  1.0642e+00, -9.2709e-01,  ..., -7.7265e-02,\n",
       "            7.3179e-01, -1.5435e+00],\n",
       "          [ 4.8661e-01,  7.4481e-01, -1.9153e+00,  ...,  8.2334e-01,\n",
       "           -1.0202e+00, -1.1861e+00],\n",
       "          [-3.3717e-01,  3.2428e-02, -1.1029e+00,  ...,  2.5630e-01,\n",
       "           -8.7439e-01, -6.8859e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0470e+00, -1.1376e+00,  3.7594e-01,  ...,  5.1962e-01,\n",
       "           -7.9801e-04,  1.1721e+00],\n",
       "          [ 6.0128e-01,  1.1026e+00,  5.7258e-01,  ..., -6.7035e-02,\n",
       "           -2.7566e-01,  1.0364e+00],\n",
       "          [ 1.4931e-01,  2.8937e-01, -5.5937e-01,  ..., -2.0638e+00,\n",
       "            1.0917e+00, -3.1998e-01],\n",
       "          ...,\n",
       "          [ 8.0331e-01, -1.2112e+00, -2.3301e-01,  ...,  1.8160e+00,\n",
       "            4.4196e-01,  1.1233e+00],\n",
       "          [ 4.3903e-01,  3.8640e-01, -1.3505e+00,  ..., -1.4502e+00,\n",
       "           -3.8037e-01, -9.0469e-01],\n",
       "          [-1.2848e-01,  9.6249e-01, -7.9826e-01,  ...,  2.0873e+00,\n",
       "           -1.0861e+00,  1.3552e-01]],\n",
       "\n",
       "         [[ 8.3272e-01,  2.7515e-01,  5.1050e-01,  ...,  8.7932e-01,\n",
       "           -1.7399e+00, -7.1398e-01],\n",
       "          [ 2.8458e-01, -7.1219e-01, -1.5971e+00,  ..., -6.9333e-01,\n",
       "            1.3830e-01,  7.0498e-02],\n",
       "          [ 5.9867e-03, -2.7485e+00,  1.6671e+00,  ..., -5.3634e-01,\n",
       "           -2.8695e-01, -1.9801e+00],\n",
       "          ...,\n",
       "          [ 2.3409e-01, -1.3375e-01,  8.2133e-02,  ..., -1.6168e+00,\n",
       "           -5.3064e-01,  3.1487e-01],\n",
       "          [ 1.2394e+00, -1.0283e+00, -6.4684e-01,  ...,  2.2465e-01,\n",
       "           -1.4254e-01,  6.8168e-02],\n",
       "          [ 2.2542e+00, -1.4220e+00, -1.4059e+00,  ...,  5.0841e-01,\n",
       "            3.1760e-01,  4.8973e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.7306e+00, -1.9263e-01,  1.3957e+00,  ...,  1.6861e-01,\n",
       "            1.0719e-01, -2.3292e+00],\n",
       "          [-8.7811e-01,  7.0346e-01, -1.4233e+00,  ...,  3.7113e-01,\n",
       "           -6.2858e-01,  1.5901e+00],\n",
       "          [ 7.2901e-01,  3.3794e-01, -4.3725e-01,  ..., -4.3168e-01,\n",
       "           -2.9096e-02, -4.8676e-01],\n",
       "          ...,\n",
       "          [-5.6549e-01, -1.3373e+00,  3.3280e-01,  ...,  1.0287e+00,\n",
       "           -9.4849e-01,  8.5820e-01],\n",
       "          [ 3.0754e-01,  2.1076e+00,  1.3577e+00,  ..., -1.1588e+00,\n",
       "           -8.9285e-01,  1.2460e+00],\n",
       "          [-1.7675e+00, -4.7610e-01, -2.3008e-01,  ..., -4.0121e-01,\n",
       "            1.1506e+00, -6.1076e-01]],\n",
       "\n",
       "         [[ 4.0868e-01, -5.7575e-01,  7.1485e-01,  ..., -2.5084e-01,\n",
       "            4.1277e-01,  2.9359e-01],\n",
       "          [-4.8995e-01, -6.9610e-02, -3.3717e-01,  ...,  6.0493e-01,\n",
       "           -3.3103e-01, -8.2546e-01],\n",
       "          [-1.5606e+00, -1.4616e-01,  1.4201e+00,  ...,  3.7792e-01,\n",
       "            2.7422e+00,  1.5502e-01],\n",
       "          ...,\n",
       "          [ 1.7461e-01, -8.5538e-01,  2.9386e-01,  ..., -1.3933e-01,\n",
       "            1.4615e+00, -6.0606e-01],\n",
       "          [-1.2504e+00,  4.3451e-01,  1.4294e+00,  ..., -5.9630e-01,\n",
       "           -6.1598e-01,  1.1107e+00],\n",
       "          [-8.0985e-01,  3.9255e-01,  2.8625e-01,  ..., -3.9829e-01,\n",
       "           -8.6487e-03, -1.7792e-01]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -2 index \n",
    "print(len(video_tensor[-2]))\n",
    "v_tensor = video_tensor[-2]\n",
    "v_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f608f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 7, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "t = torch.randn(2, 3, 8, 256, 256)\n",
    "t = t[:, :, 1:]\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e4c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 2, 256, 256])\n",
      "torch.Size([1, 3, 2, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "video = torch.randn(2, 3, 8, 256, 256)\n",
    "\n",
    "\n",
    "transpose_video = video.transpose(0, 2)\n",
    "print(transpose_video.shape)\n",
    "tensor = torch.zeros_like(transpose_video[:1])\n",
    "print(tensor.shape)\n",
    "tensor = torch.cat([tensor] * (3 - 1) + [tensor],  dim=0)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7e5f037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 2, 256, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = transpose_video[:, :50, :, :, :]\n",
    "one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae23da37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5296, -1.5951,  0.7634],\n",
       "        [ 1.1182,  0.5858, -1.0306],\n",
       "        [ 2.6409, -0.1344, -0.0119]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(3, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8c6ea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5296, -1.5951,  0.7634]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_one = t[:1,]\n",
    "t_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfe4a8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = (1, 1, 1,)\n",
    "type(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93093926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "168b748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> torch.Size([2, 3, 8, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm3d(in_channels)\n",
    "        self.conv = nn.Conv3d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=3)\n",
    "        self.norm2 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = torch.nn.functional.pad(x, pad=(1, 1, 1, 1, 2, 0), mode='constant')\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        print(\">>>\", x.shape)\n",
    "        return x \n",
    "    \n",
    "\n",
    "x = torch.randn(2, 3, 8, 256, 256)\n",
    "out = SimpleModel(in_channels=3,\n",
    "                  out_channels=3)\n",
    "out = out(x)\n",
    "# out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981d1f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577fde37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.tensor([[1, 2, 3, 4], [1, 2, 3, 4]])\n",
    "t.stride(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e90ea2e",
   "metadata": {},
   "source": [
    "## 18. contiguous tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b5741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.randn(2, 3, 8, 256, 256)\n",
    "print(x.is_contiguous())\n",
    "y = x.T\n",
    "print(y.is_contiguous())\n",
    "\n",
    "y = y.contiguous()\n",
    "y.is_contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edaf8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "if n < 3:\n",
    "    print(n*2)\n",
    "\n",
    "else:\n",
    "    print(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83c94a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.43\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "class SmoothedValue(object):\n",
    "\n",
    "  def __init__(self,\n",
    "              window_size: int = 20,\n",
    "              fmt: str = None):\n",
    "    super().__init__()\n",
    "    self.window_size = window_size \n",
    "    self.fmt = fmt \n",
    "    self.deque = deque(maxlen=window_size)\n",
    "\n",
    "\n",
    "\n",
    "  def update(self, value):\n",
    "    self.deque.append(value)\n",
    "\n",
    "\n",
    "  @property\n",
    "  def value(self):\n",
    "    return self.deque[-1]\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.fmt.format(\n",
    "      value=self.value\n",
    "    )\n",
    "  \n",
    " \n",
    " \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "smo = SmoothedValue(window_size=1,\n",
    "                    fmt='{value:.2f}')\n",
    "\n",
    "smo.update(3.43)\n",
    "print(smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd8ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7393869161605835\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def update(value):\n",
    "\n",
    "    for key, value in value.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            value = value.item()\n",
    "        \n",
    "        if isinstance(value, (float, int)):\n",
    "            \n",
    "\n",
    "t = torch.randn(1)\n",
    "out = update(value={'lr': 3.2, 'lr': 3.9, 'lr': t})\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6318d6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.5270)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(1)\n",
    "t.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c129a80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=63)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "from datetime import timedelta\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "matho = 333**444\n",
    "\n",
    "end_time = time.time()\n",
    "calculate_time = end_time - start_time\n",
    "timedelta(seconds=calculate_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3daca0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1= len(str(2000))\n",
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "600cc2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2000)\n",
    "str(len(str(len(range(2000)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3ea065e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterable = range(2000)\n",
    "\n",
    "len(iterable) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "237631ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2, 3, 4]'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_str = [2, 3, 4]\n",
    "str(list_str).format(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0495c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
